{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook For Final Results Figures and Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "from matplotlib import rcParams\n",
    "import csv\n",
    "import collections\n",
    "import time\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn.model_selection import train_test_split, cross_validate # Import train_test_split function\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm #Import svm model\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OrdinalEncoder, LabelEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['1D_All_ReplaysData_PvP.csv', '1D_All_ReplaysData_PvT.csv', '1D_All_ReplaysData_PvZ.csv', '1D_All_ReplaysData_TvT.csv', '1D_All_ReplaysData_TvZ.csv', '1D_All_ReplaysData_ZvZ.csv', \"StarCraft_Combined_Dataset.csv\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Models Accuracy Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6658 - accuracy: 0.6712\n",
      "{'File': '1D_All_ReplaysData_PvP.csv', 'Percentile': 0.1, 'RandomForest': 0.6730974124809741, 'LogisticRegression': 0.7198630136986301, 'SVM': 0.6677321156773212, 'KNN': 0.6564307458143075, 'Neural Network': 0.6712328791618347}\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.8311 - accuracy: 0.6438\n",
      "{'File': '1D_All_ReplaysData_PvP.csv', 'Percentile': 0.2, 'RandomForest': 0.7033105022831051, 'LogisticRegression': 0.7060121765601218, 'SVM': 0.598896499238965, 'KNN': 0.6369482496194825, 'Neural Network': 0.6438356041908264}\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.1670 - accuracy: 0.6712\n",
      "{'File': '1D_All_ReplaysData_PvP.csv', 'Percentile': 0.3, 'RandomForest': 0.7169710806697107, 'LogisticRegression': 0.7223744292237442, 'SVM': 0.5878614916286148, 'KNN': 0.5961567732115678, 'Neural Network': 0.6712328791618347}\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.0856 - accuracy: 0.7123\n",
      "{'File': '1D_All_ReplaysData_PvP.csv', 'Percentile': 0.4, 'RandomForest': 0.7279299847792998, 'LogisticRegression': 0.7499619482496195, 'SVM': 0.5631659056316591, 'KNN': 0.5600076103500761, 'Neural Network': 0.7123287916183472}\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.4566 - accuracy: 0.6849\n",
      "{'File': '1D_All_ReplaysData_PvP.csv', 'Percentile': 0.5, 'RandomForest': 0.7607686453576864, 'LogisticRegression': 0.7470700152207002, 'SVM': 0.568531202435312, 'KNN': 0.5961948249619483, 'Neural Network': 0.6849315166473389}\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.4206 - accuracy: 0.7260\n",
      "{'File': '1D_All_ReplaysData_PvP.csv', 'Percentile': 0.6, 'RandomForest': 0.7471080669710807, 'LogisticRegression': 0.7747716894977169, 'SVM': 0.5906012176560121, 'KNN': 0.6290334855403349, 'Neural Network': 0.7260273694992065}\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.4868 - accuracy: 0.6712\n",
      "{'File': '1D_All_ReplaysData_PvP.csv', 'Percentile': 0.7, 'RandomForest': 0.7884322678843227, 'LogisticRegression': 0.7939878234398783, 'SVM': 0.629033485540335, 'KNN': 0.681316590563166, 'Neural Network': 0.6712328791618347}\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.0669 - accuracy: 0.7397\n",
      "{'File': '1D_All_ReplaysData_PvP.csv', 'Percentile': 0.8, 'RandomForest': 0.8213470319634704, 'LogisticRegression': 0.8158295281582953, 'SVM': 0.6867199391171994, 'KNN': 0.7500380517503805, 'Neural Network': 0.7397260069847107}\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.0964 - accuracy: 0.7534\n",
      "{'File': '1D_All_ReplaysData_PvP.csv', 'Percentile': 0.9, 'RandomForest': 0.8735540334855403, 'LogisticRegression': 0.8762937595129376, 'SVM': 0.7554414003044141, 'KNN': 0.8268645357686453, 'Neural Network': 0.7534246444702148}\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.8693 - accuracy: 0.8219\n",
      "{'File': '1D_All_ReplaysData_PvP.csv', 'Percentile': 1.0, 'RandomForest': 0.9423135464231354, 'LogisticRegression': 0.925875190258752, 'SVM': 0.8433789954337898, 'KNN': 0.879185692541857, 'Neural Network': 0.8219178318977356}\n",
      "1D_All_ReplaysData_PvP.csv  Done!\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6789 - accuracy: 0.6667\n",
      "{'File': '1D_All_ReplaysData_PvT.csv', 'Percentile': 0.1, 'RandomForest': 0.7221632773356912, 'LogisticRegression': 0.7203949307397584, 'SVM': 0.6191570881226054, 'KNN': 0.6776156793398173, 'Neural Network': 0.6666666865348816}\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8812 - accuracy: 0.7179\n",
      "{'File': '1D_All_ReplaysData_PvT.csv', 'Percentile': 0.2, 'RandomForest': 0.7393604479811375, 'LogisticRegression': 0.7342469790745653, 'SVM': 0.5882699675803125, 'KNN': 0.6638373121131742, 'Neural Network': 0.7179487347602844}\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1422 - accuracy: 0.7607\n",
      "{'File': '1D_All_ReplaysData_PvT.csv', 'Percentile': 0.3, 'RandomForest': 0.7427939876215739, 'LogisticRegression': 0.7633657530209255, 'SVM': 0.557412319481285, 'KNN': 0.6451370468611847, 'Neural Network': 0.7606837749481201}\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1077 - accuracy: 0.7009\n",
      "{'File': '1D_All_ReplaysData_PvT.csv', 'Percentile': 0.4, 'RandomForest': 0.7514883583849101, 'LogisticRegression': 0.7633804892425583, 'SVM': 0.5488358384910109, 'KNN': 0.6382404951370468, 'Neural Network': 0.7008547186851501}\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.4426 - accuracy: 0.7094\n",
      "{'File': '1D_All_ReplaysData_PvT.csv', 'Percentile': 0.5, 'RandomForest': 0.7531830238726791, 'LogisticRegression': 0.787444739168877, 'SVM': 0.5505599764220455, 'KNN': 0.6502505157677572, 'Neural Network': 0.7094017267227173}\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.7946 - accuracy: 0.6581\n",
      "{'File': '1D_All_ReplaysData_PvT.csv', 'Percentile': 0.6, 'RandomForest': 0.7411877394636014, 'LogisticRegression': 0.8011788977306218, 'SVM': 0.5608458591217212, 'KNN': 0.6244031830238728, 'Neural Network': 0.6581196784973145}\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.5286 - accuracy: 0.7265\n",
      "{'File': '1D_All_ReplaysData_PvT.csv', 'Percentile': 0.7, 'RandomForest': 0.7943412908930151, 'LogisticRegression': 0.8217359269083409, 'SVM': 0.5608458591217212, 'KNN': 0.6519304450338933, 'Neural Network': 0.7264957427978516}\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.4404 - accuracy: 0.7094\n",
      "{'File': '1D_All_ReplaysData_PvT.csv', 'Percentile': 0.8, 'RandomForest': 0.8200117889773061, 'LogisticRegression': 0.843958149130563, 'SVM': 0.5711170055997642, 'KNN': 0.7117889773062187, 'Neural Network': 0.7094017267227173}\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.2617 - accuracy: 0.7521\n",
      "{'File': '1D_All_ReplaysData_PvT.csv', 'Percentile': 0.9, 'RandomForest': 0.8577070439139405, 'LogisticRegression': 0.862864721485411, 'SVM': 0.6002357795461244, 'KNN': 0.7753168287651045, 'Neural Network': 0.752136766910553}\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8510 - accuracy: 0.7863\n",
      "{'File': '1D_All_ReplaysData_PvT.csv', 'Percentile': 1.0, 'RandomForest': 0.9159740642499263, 'LogisticRegression': 0.9434718538166813, 'SVM': 0.7409224874742116, 'KNN': 0.8679929266136164, 'Neural Network': 0.7863247990608215}\n",
      "1D_All_ReplaysData_PvT.csv  Done!\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7815 - accuracy: 0.6282\n",
      "{'File': '1D_All_ReplaysData_PvZ.csv', 'Percentile': 0.1, 'RandomForest': 0.49996669996669996, 'LogisticRegression': 0.5336996336996337, 'SVM': 0.4974025974025974, 'KNN': 0.5308691308691309, 'Neural Network': 0.6282051205635071}\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.2992 - accuracy: 0.5000\n",
      "{'File': '1D_All_ReplaysData_PvZ.csv', 'Percentile': 0.2, 'RandomForest': 0.5001665001665001, 'LogisticRegression': 0.4871128871128871, 'SVM': 0.4482184482184482, 'KNN': 0.4922077922077922, 'Neural Network': 0.5}\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.6498 - accuracy: 0.5513\n",
      "{'File': '1D_All_ReplaysData_PvZ.csv', 'Percentile': 0.3, 'RandomForest': 0.47918747918747917, 'LogisticRegression': 0.5206793206793207, 'SVM': 0.4429237429237429, 'KNN': 0.504995004995005, 'Neural Network': 0.5512820482254028}\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.7189 - accuracy: 0.5513\n",
      "{'File': '1D_All_ReplaysData_PvZ.csv', 'Percentile': 0.4, 'RandomForest': 0.5026640026640026, 'LogisticRegression': 0.4973026973026974, 'SVM': 0.4404262404262404, 'KNN': 0.5077922077922077, 'Neural Network': 0.5512820482254028}\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.9400 - accuracy: 0.5000\n",
      "{'File': '1D_All_ReplaysData_PvZ.csv', 'Percentile': 0.5, 'RandomForest': 0.5207792207792208, 'LogisticRegression': 0.49996669996669996, 'SVM': 0.46117216117216114, 'KNN': 0.5025974025974026, 'Neural Network': 0.5}\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 2.0101 - accuracy: 0.5385\n",
      "{'File': '1D_All_ReplaysData_PvZ.csv', 'Percentile': 0.6, 'RandomForest': 0.5104895104895104, 'LogisticRegression': 0.4869130869130869, 'SVM': 0.4793872793872794, 'KNN': 0.5259074259074259, 'Neural Network': 0.5384615659713745}\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.6591 - accuracy: 0.5769\n",
      "{'File': '1D_All_ReplaysData_PvZ.csv', 'Percentile': 0.7, 'RandomForest': 0.5234099234099233, 'LogisticRegression': 0.4921411921411921, 'SVM': 0.4740925740925741, 'KNN': 0.5362637362637362, 'Neural Network': 0.5769230723381042}\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.8724 - accuracy: 0.6026\n",
      "{'File': '1D_All_ReplaysData_PvZ.csv', 'Percentile': 0.8, 'RandomForest': 0.48444888444888445, 'LogisticRegression': 0.47932067932067934, 'SVM': 0.468964368964369, 'KNN': 0.5207126207126207, 'Neural Network': 0.6025640964508057}\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 2.0662 - accuracy: 0.5641\n",
      "{'File': '1D_All_ReplaysData_PvZ.csv', 'Percentile': 0.9, 'RandomForest': 0.5597402597402598, 'LogisticRegression': 0.47668997668997665, 'SVM': 0.4793872793872794, 'KNN': 0.49217449217449216, 'Neural Network': 0.5641025900840759}\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.5963 - accuracy: 0.6795\n",
      "{'File': '1D_All_ReplaysData_PvZ.csv', 'Percentile': 1.0, 'RandomForest': 0.7877455877455879, 'LogisticRegression': 0.7773226773226772, 'SVM': 0.5623376623376624, 'KNN': 0.6114219114219115, 'Neural Network': 0.6794871687889099}\n",
      "1D_All_ReplaysData_PvZ.csv  Done!\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6086 - accuracy: 0.7143\n",
      "{'File': '1D_All_ReplaysData_TvT.csv', 'Percentile': 0.1, 'RandomForest': 0.6016404647983595, 'LogisticRegression': 0.6874914559125086, 'SVM': 0.6039986329460014, 'KNN': 0.6718728639781271, 'Neural Network': 0.7142857313156128}\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.7839 - accuracy: 0.7403\n",
      "{'File': '1D_All_ReplaysData_TvT.csv', 'Percentile': 0.2, 'RandomForest': 0.6536226930963773, 'LogisticRegression': 0.6978468899521532, 'SVM': 0.5856801093643199, 'KNN': 0.6142857142857142, 'Neural Network': 0.7402597665786743}\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.5650 - accuracy: 0.6494\n",
      "{'File': '1D_All_ReplaysData_TvT.csv', 'Percentile': 0.3, 'RandomForest': 0.6820915926179084, 'LogisticRegression': 0.7004784688995215, 'SVM': 0.5753930280246069, 'KNN': 0.6091592617908407, 'Neural Network': 0.649350643157959}\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.8988 - accuracy: 0.6883\n",
      "{'File': '1D_All_ReplaysData_TvT.csv', 'Percentile': 0.4, 'RandomForest': 0.6822282980177716, 'LogisticRegression': 0.7290840738209159, 'SVM': 0.5934723171565277, 'KNN': 0.6040328092959671, 'Neural Network': 0.6883116960525513}\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.7838 - accuracy: 0.6364\n",
      "{'File': '1D_All_ReplaysData_TvT.csv', 'Percentile': 0.5, 'RandomForest': 0.7082365003417634, 'LogisticRegression': 0.7342447026657554, 'SVM': 0.6117224880382774, 'KNN': 0.5935406698564594, 'Neural Network': 0.6363636255264282}\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.4788 - accuracy: 0.6623\n",
      "{'File': '1D_All_ReplaysData_TvT.csv', 'Percentile': 0.6, 'RandomForest': 0.6797676008202325, 'LogisticRegression': 0.7421052631578948, 'SVM': 0.6144224196855775, 'KNN': 0.6613807245386193, 'Neural Network': 0.6623376607894897}\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.7872 - accuracy: 0.6883\n",
      "{'File': '1D_All_ReplaysData_TvT.csv', 'Percentile': 0.7, 'RandomForest': 0.7473342447026659, 'LogisticRegression': 0.7784347231715653, 'SVM': 0.658714969241285, 'KNN': 0.6665755297334245, 'Neural Network': 0.6883116960525513}\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.7508 - accuracy: 0.6883\n",
      "{'File': '1D_All_ReplaysData_TvT.csv', 'Percentile': 0.8, 'RandomForest': 0.7784347231715654, 'LogisticRegression': 0.8174299384825702, 'SVM': 0.7029733424470267, 'KNN': 0.7393028024606971, 'Neural Network': 0.6883116960525513}\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1975 - accuracy: 0.8052\n",
      "{'File': '1D_All_ReplaysData_TvT.csv', 'Percentile': 0.9, 'RandomForest': 0.8098427887901571, 'LogisticRegression': 0.8514012303485987, 'SVM': 0.7471633629528366, 'KNN': 0.7733082706766917, 'Neural Network': 0.8051947951316833}\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6304 - accuracy: 0.8052\n",
      "{'File': '1D_All_ReplaysData_TvT.csv', 'Percentile': 1.0, 'RandomForest': 0.8750854408749145, 'LogisticRegression': 0.9139781271360219, 'SVM': 0.8462064251537935, 'KNN': 0.8201640464798361, 'Neural Network': 0.8051947951316833}\n",
      "1D_All_ReplaysData_TvT.csv  Done!\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.9744 - accuracy: 0.5429\n",
      "{'File': '1D_All_ReplaysData_TvZ.csv', 'Percentile': 0.1, 'RandomForest': 0.5461283643892341, 'LogisticRegression': 0.5029813664596273, 'SVM': 0.5026086956521739, 'KNN': 0.5341614906832298, 'Neural Network': 0.5428571701049805}\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.1634 - accuracy: 0.5286\n",
      "{'File': '1D_All_ReplaysData_TvZ.csv', 'Percentile': 0.2, 'RandomForest': 0.5289026915113871, 'LogisticRegression': 0.5142857142857142, 'SVM': 0.5458385093167701, 'KNN': 0.5340786749482401, 'Neural Network': 0.5285714268684387}\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.6748 - accuracy: 0.5000\n",
      "{'File': '1D_All_ReplaysData_TvZ.csv', 'Percentile': 0.3, 'RandomForest': 0.5228571428571429, 'LogisticRegression': 0.5604554865424431, 'SVM': 0.5257971014492754, 'KNN': 0.4796687370600414, 'Neural Network': 0.5}\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 2.3579 - accuracy: 0.4714\n",
      "{'File': '1D_All_ReplaysData_TvZ.csv', 'Percentile': 0.4, 'RandomForest': 0.5372670807453416, 'LogisticRegression': 0.5830641821946171, 'SVM': 0.5141200828157351, 'KNN': 0.5199585921325053, 'Neural Network': 0.4714285731315613}\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 2.2056 - accuracy: 0.5571\n",
      "{'File': '1D_All_ReplaysData_TvZ.csv', 'Percentile': 0.5, 'RandomForest': 0.5832712215320911, 'LogisticRegression': 0.5887370600414079, 'SVM': 0.5226086956521738, 'KNN': 0.5655900621118012, 'Neural Network': 0.5571428537368774}\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 2.1293 - accuracy: 0.5286\n",
      "{'File': '1D_All_ReplaysData_TvZ.csv', 'Percentile': 0.6, 'RandomForest': 0.5572256728778467, 'LogisticRegression': 0.5657142857142856, 'SVM': 0.5140372670807454, 'KNN': 0.5571014492753623, 'Neural Network': 0.5285714268684387}\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 2.2587 - accuracy: 0.5286\n",
      "{'File': '1D_All_ReplaysData_TvZ.csv', 'Percentile': 0.7, 'RandomForest': 0.5544927536231883, 'LogisticRegression': 0.548488612836439, 'SVM': 0.5171014492753624, 'KNN': 0.5598343685300207, 'Neural Network': 0.5285714268684387}\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 2.4308 - accuracy: 0.5571\n",
      "{'File': '1D_All_ReplaysData_TvZ.csv', 'Percentile': 0.8, 'RandomForest': 0.5717184265010352, 'LogisticRegression': 0.562857142857143, 'SVM': 0.5055486542443065, 'KNN': 0.5281573498964802, 'Neural Network': 0.5571428537368774}\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.9869 - accuracy: 0.6143\n",
      "{'File': '1D_All_ReplaysData_TvZ.csv', 'Percentile': 0.9, 'RandomForest': 0.563271221532091, 'LogisticRegression': 0.5571428571428572, 'SVM': 0.525672877846791, 'KNN': 0.5683229813664596, 'Neural Network': 0.6142857074737549}\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 2.0796 - accuracy: 0.6714\n",
      "{'File': '1D_All_ReplaysData_TvZ.csv', 'Percentile': 1.0, 'RandomForest': 0.7987577639751552, 'LogisticRegression': 0.8072049689440994, 'SVM': 0.6605383022774327, 'KNN': 0.6603726708074534, 'Neural Network': 0.6714285612106323}\n",
      "1D_All_ReplaysData_TvZ.csv  Done!\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.9816 - accuracy: 0.5588\n",
      "{'File': '1D_All_ReplaysData_ZvZ.csv', 'Percentile': 0.1, 'RandomForest': 0.5707664884135473, 'LogisticRegression': 0.5053475935828877, 'SVM': 0.5588235294117647, 'KNN': 0.6176470588235293, 'Neural Network': 0.5588235259056091}\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.9267 - accuracy: 0.5882\n",
      "{'File': '1D_All_ReplaysData_ZvZ.csv', 'Percentile': 0.2, 'RandomForest': 0.6363636363636364, 'LogisticRegression': 0.6183600713012478, 'SVM': 0.5818181818181818, 'KNN': 0.5941176470588235, 'Neural Network': 0.5882353186607361}\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 1.2903 - accuracy: 0.5882\n",
      "{'File': '1D_All_ReplaysData_ZvZ.csv', 'Percentile': 0.3, 'RandomForest': 0.6249554367201425, 'LogisticRegression': 0.5948306595365419, 'SVM': 0.5762923351158645, 'KNN': 0.6292335115864528, 'Neural Network': 0.5882353186607361}\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 1.3349 - accuracy: 0.6176\n",
      "{'File': '1D_All_ReplaysData_ZvZ.csv', 'Percentile': 0.4, 'RandomForest': 0.618716577540107, 'LogisticRegression': 0.6124777183600714, 'SVM': 0.6237076648841354, 'KNN': 0.6354723707664884, 'Neural Network': 0.6176470518112183}\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.5733 - accuracy: 0.6176\n",
      "{'File': '1D_All_ReplaysData_ZvZ.csv', 'Percentile': 0.5, 'RandomForest': 0.6903743315508022, 'LogisticRegression': 0.6010695187165775, 'SVM': 0.564349376114082, 'KNN': 0.6415329768270945, 'Neural Network': 0.6176470518112183}\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.4046 - accuracy: 0.5882\n",
      "{'File': '1D_All_ReplaysData_ZvZ.csv', 'Percentile': 0.6, 'RandomForest': 0.6607843137254902, 'LogisticRegression': 0.571301247771836, 'SVM': 0.5880570409982175, 'KNN': 0.6181818181818182, 'Neural Network': 0.5882353186607361}\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.2634 - accuracy: 0.6176\n",
      "{'File': '1D_All_ReplaysData_ZvZ.csv', 'Percentile': 0.7, 'RandomForest': 0.6729055258467024, 'LogisticRegression': 0.6007130124777184, 'SVM': 0.5711229946524063, 'KNN': 0.635650623885918, 'Neural Network': 0.6176470518112183}\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.0718 - accuracy: 0.6471\n",
      "{'File': '1D_All_ReplaysData_ZvZ.csv', 'Percentile': 0.8, 'RandomForest': 0.6595365418894831, 'LogisticRegression': 0.6484848484848484, 'SVM': 0.5709447415329768, 'KNN': 0.6354723707664884, 'Neural Network': 0.6470588445663452}\n",
      "2/2 [==============================] - 0s 998us/step - loss: 1.1531 - accuracy: 0.6765\n",
      "{'File': '1D_All_ReplaysData_ZvZ.csv', 'Percentile': 0.9, 'RandomForest': 0.7319073083778966, 'LogisticRegression': 0.6598930481283423, 'SVM': 0.6185383244206774, 'KNN': 0.6354723707664884, 'Neural Network': 0.6764705777168274}\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.9201 - accuracy: 0.7059\n",
      "{'File': '1D_All_ReplaysData_ZvZ.csv', 'Percentile': 1.0, 'RandomForest': 0.7795008912655972, 'LogisticRegression': 0.7982174688057041, 'SVM': 0.695187165775401, 'KNN': 0.7611408199643492, 'Neural Network': 0.7058823704719543}\n",
      "1D_All_ReplaysData_ZvZ.csv  Done!\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.7371 - accuracy: 0.6577\n",
      "{'File': 'StarCraft_Combined_Dataset.csv', 'Percentile': 0.1, 'RandomForest': 0.6341017846931712, 'LogisticRegression': 0.6529097822052348, 'SVM': 0.60724009590594, 'KNN': 0.6126001946208405, 'Neural Network': 0.6577181220054626}\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.1999 - accuracy: 0.6532\n",
      "{'File': 'StarCraft_Combined_Dataset.csv', 'Percentile': 0.2, 'RandomForest': 0.641717077477152, 'LogisticRegression': 0.6694726176503046, 'SVM': 0.5808178088101043, 'KNN': 0.5794514501259016, 'Neural Network': 0.6532438397407532}\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.3825 - accuracy: 0.6577\n",
      "{'File': 'StarCraft_Combined_Dataset.csv', 'Percentile': 0.3, 'RandomForest': 0.6493133094571684, 'LogisticRegression': 0.6640894453306047, 'SVM': 0.5570810886728664, 'KNN': 0.5615473360018459, 'Neural Network': 0.6577181220054626}\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.3567 - accuracy: 0.6532\n",
      "{'File': 'StarCraft_Combined_Dataset.csv', 'Percentile': 0.4, 'RandomForest': 0.6645308534224175, 'LogisticRegression': 0.6824460027487685, 'SVM': 0.5588878522486732, 'KNN': 0.566014586531034, 'Neural Network': 0.6532438397407532}\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.6648 - accuracy: 0.6600\n",
      "{'File': 'StarCraft_Combined_Dataset.csv', 'Percentile': 0.5, 'RandomForest': 0.68244499954856, 'LogisticRegression': 0.7008085793681845, 'SVM': 0.562014827299084, 'KNN': 0.5718431797433814, 'Neural Network': 0.6599552631378174}\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.4709 - accuracy: 0.7226\n",
      "{'File': 'StarCraft_Combined_Dataset.csv', 'Percentile': 0.6, 'RandomForest': 0.6855810034008487, 'LogisticRegression': 0.7084228689519567, 'SVM': 0.570523971468986, 'KNN': 0.5924549312306258, 'Neural Network': 0.7225950956344604}\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.4788 - accuracy: 0.7226\n",
      "{'File': 'StarCraft_Combined_Dataset.csv', 'Percentile': 0.7, 'RandomForest': 0.7079644064565966, 'LogisticRegression': 0.7267804295703293, 'SVM': 0.58754225980879, 'KNN': 0.6036285751547437, 'Neural Network': 0.7225950956344604}\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.1615 - accuracy: 0.7673\n",
      "{'File': 'StarCraft_Combined_Dataset.csv', 'Percentile': 0.8, 'RandomForest': 0.72094581715673, 'LogisticRegression': 0.7420100119380825, 'SVM': 0.6220172349795849, 'KNN': 0.6228980447627933, 'Neural Network': 0.7673377990722656}\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.2665 - accuracy: 0.7830\n",
      "{'File': 'StarCraft_Combined_Dataset.csv', 'Percentile': 0.9, 'RandomForest': 0.7500416328086595, 'LogisticRegression': 0.764394418194039, 'SVM': 0.6658871801045334, 'KNN': 0.6802098694836529, 'Neural Network': 0.7829977869987488}\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.9392 - accuracy: 0.8300\n",
      "{'File': 'StarCraft_Combined_Dataset.csv', 'Percentile': 1.0, 'RandomForest': 0.8781653474583923, 'LogisticRegression': 0.8709974819674763, 'SVM': 0.7961798136054011, 'KNN': 0.7437926987088812, 'Neural Network': 0.8299776315689087}\n",
      "StarCraft_Combined_Dataset.csv  Done!\n"
     ]
    }
   ],
   "source": [
    "# Create df for adding performance of different models\n",
    "df = pd.DataFrame(columns=['File', 'Model', 'Score', 'Percentile'])\n",
    "df_list = []  # Initialize an empty list to store DataFrames to concatenate later.\n",
    "\n",
    "for file in files:\n",
    "    # Load the data\n",
    "    data = pd.read_csv('../'+ file)\n",
    "\n",
    "    # Assuming combined_data is your DataFrame\n",
    "    data = data.drop(data[data['Winner'] == 0].index)\n",
    "    \n",
    "    data = data.drop(data[data['Winner'] > 2].index)\n",
    "    # Assuming df is your DataFrame and 'ReplayID' is the column to be encoded\n",
    "    label_encoder = LabelEncoder()\n",
    "    # convert 1 to 0 and 2 to 1\n",
    "    data['Winner'] = data['Winner'].replace(1, 0)\n",
    "    data['Winner'] = data['Winner'].replace(2, 1)\n",
    "\n",
    "    label_encoders = {}\n",
    "    for column in ['ReplayID', 'Player1_Race', 'Player2_Race', 'MapName']:\n",
    "        label_encoders[column] = LabelEncoder()\n",
    "        data[column] = label_encoders[column].fit_transform(data[column])\n",
    "\n",
    "\n",
    "\n",
    "    for per in range(1,11, 1):\n",
    "        percentile_80_grouped = data.groupby('ReplayID')['Frame'].quantile(per/10)\n",
    "\n",
    "        def find_nearest_row(group):\n",
    "            nearest_index = (group['Frame'] - percentile_80_grouped[group.name]).abs().idxmin()\n",
    "            return group.loc[[nearest_index]]\n",
    "\n",
    "        # Apply the function to each group of 'ReplayID' and concatenate the results\n",
    "        nearest_rows = data.groupby('ReplayID', group_keys=False).apply(find_nearest_row)\n",
    "        # Reset the index if needed\n",
    "        nearest_rows.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        # Standardize the data.\n",
    "        scaler = StandardScaler()\n",
    "        nearest_rows[nearest_rows.columns.drop(['Winner'])] = scaler.fit_transform(nearest_rows[nearest_rows.columns.drop(['Winner'])])\n",
    "\n",
    "        # Define features (X) and target variable (y)\n",
    "        X = nearest_rows.drop(['Winner'], axis=1)\n",
    "        y = nearest_rows['Winner']\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=42) \n",
    "\n",
    "        # Dictionary to hold scores for the models\n",
    "        scores_dict = {'File': file, 'Percentile': per/10}\n",
    "                \n",
    "        # Build the models and evaluate them\n",
    "        models = {\n",
    "            'RandomForest': RandomForestClassifier(bootstrap=False, criterion='entropy', max_depth=12, max_features=23, min_samples_split=30, random_state=63),\n",
    "            'LogisticRegression': LogisticRegression(solver='liblinear', max_iter=1000, C=0.1, penalty='l1'),\n",
    "            'SVM': svm.LinearSVC(C=0.00001, random_state=42, dual=False, max_iter=1000),\n",
    "            'KNN': KNeighborsClassifier(n_jobs=-1, n_neighbors=17, weights='distance'),\n",
    "            \"Neural Network\": tf.keras.models.Sequential([\n",
    "                tf.keras.layers.Dense(250, activation='sigmoid', input_shape=(X_train.shape[1],)),\n",
    "                tf.keras.layers.Dropout(0.2),\n",
    "                tf.keras.layers.Dense(125, activation='sigmoid'),\n",
    "                tf.keras.layers.Dropout(0.2),\n",
    "                tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "            ])\n",
    "        }\n",
    "\n",
    "        for model_name, model in models.items():\n",
    "            if model_name == \"Neural Network\":\n",
    "                # Compile the model.\n",
    "                early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "                model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "                # Train the model.\n",
    "                model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, verbose=0)\n",
    "\n",
    "                # Evaluate the model.\n",
    "                loss, accuracy = model.evaluate(X_test, y_test)\n",
    "                score = accuracy\n",
    "            else:\n",
    "                # Train and score the model\n",
    "                # model.fit(X_train, y_train)\n",
    "                # score = model.score(X_test, y_test)\n",
    "\n",
    "                cv_scores = cross_val_score(model, X, y, cv=5)  # You can adjust the number of folds (cv parameter) as needed\n",
    "                score = cv_scores.mean()\n",
    "\n",
    "            scores_dict[model_name] = score\n",
    "\n",
    "        print(scores_dict)\n",
    "        # Append the scores_dict as a DataFrame to df_list\n",
    "        df_list.append(pd.DataFrame([scores_dict]))\n",
    "    print(file, \" Done!\")\n",
    "\n",
    "df = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ReplayID</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Frame</th>\n",
       "      <th>MapName</th>\n",
       "      <th>MapWidth</th>\n",
       "      <th>MapHeight</th>\n",
       "      <th>Player1_EAPM</th>\n",
       "      <th>Player1_ECmdCount</th>\n",
       "      <th>Player1_Race</th>\n",
       "      <th>Player2_EAPM</th>\n",
       "      <th>...</th>\n",
       "      <th>Player2_Leg Enhancements_Level</th>\n",
       "      <th>Player2_Protoss Air Armor_Level</th>\n",
       "      <th>Player2_Protoss Air Weapons_Level</th>\n",
       "      <th>Player2_Protoss Ground Armor_Level</th>\n",
       "      <th>Player2_Protoss Ground Weapons_Level</th>\n",
       "      <th>Player2_Protoss Plasma Shields_Level</th>\n",
       "      <th>Player2_Reaver Capacity_Level</th>\n",
       "      <th>Player2_Scarab Damage_Level</th>\n",
       "      <th>Player2_Sensor Array_Level</th>\n",
       "      <th>Player2_Singularity Charge_Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>193</td>\n",
       "      <td>-0.684519</td>\n",
       "      <td>-0.122456</td>\n",
       "      <td>-0.818624</td>\n",
       "      <td>0.513611</td>\n",
       "      <td>0.48941</td>\n",
       "      <td>-1.161004</td>\n",
       "      <td>-0.996638</td>\n",
       "      <td>-0.081847</td>\n",
       "      <td>-1.737556</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.815498</td>\n",
       "      <td>-0.068024</td>\n",
       "      <td>-0.151082</td>\n",
       "      <td>-0.431580</td>\n",
       "      <td>-0.641940</td>\n",
       "      <td>-0.275886</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.135606</td>\n",
       "      <td>-0.068577</td>\n",
       "      <td>0.769263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>-0.533382</td>\n",
       "      <td>0.056131</td>\n",
       "      <td>0.888199</td>\n",
       "      <td>0.513611</td>\n",
       "      <td>0.48941</td>\n",
       "      <td>-0.055273</td>\n",
       "      <td>-0.576683</td>\n",
       "      <td>-0.081847</td>\n",
       "      <td>-0.645620</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.815498</td>\n",
       "      <td>-0.068024</td>\n",
       "      <td>-0.151082</td>\n",
       "      <td>-0.431580</td>\n",
       "      <td>-0.641940</td>\n",
       "      <td>-0.275886</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.135606</td>\n",
       "      <td>-0.068577</td>\n",
       "      <td>0.769263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>-0.007826</td>\n",
       "      <td>0.681184</td>\n",
       "      <td>-1.550119</td>\n",
       "      <td>0.513611</td>\n",
       "      <td>0.48941</td>\n",
       "      <td>0.635808</td>\n",
       "      <td>0.272616</td>\n",
       "      <td>-0.081847</td>\n",
       "      <td>-1.305860</td>\n",
       "      <td>...</td>\n",
       "      <td>1.226244</td>\n",
       "      <td>-0.068024</td>\n",
       "      <td>-0.151082</td>\n",
       "      <td>1.923429</td>\n",
       "      <td>1.172029</td>\n",
       "      <td>-0.275886</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.135606</td>\n",
       "      <td>-0.068577</td>\n",
       "      <td>0.769263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>347</td>\n",
       "      <td>-1.477967</td>\n",
       "      <td>-1.070340</td>\n",
       "      <td>-1.174993</td>\n",
       "      <td>0.513611</td>\n",
       "      <td>0.48941</td>\n",
       "      <td>-1.548010</td>\n",
       "      <td>-1.698970</td>\n",
       "      <td>-0.081847</td>\n",
       "      <td>-0.747195</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.815498</td>\n",
       "      <td>-0.068024</td>\n",
       "      <td>-0.151082</td>\n",
       "      <td>-0.431580</td>\n",
       "      <td>-0.641940</td>\n",
       "      <td>-0.275886</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.135606</td>\n",
       "      <td>-0.068577</td>\n",
       "      <td>-1.299946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>57</td>\n",
       "      <td>1.076904</td>\n",
       "      <td>1.752705</td>\n",
       "      <td>-1.174993</td>\n",
       "      <td>0.513611</td>\n",
       "      <td>0.48941</td>\n",
       "      <td>-1.852086</td>\n",
       "      <td>0.068596</td>\n",
       "      <td>-0.081847</td>\n",
       "      <td>-0.569438</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.815498</td>\n",
       "      <td>-0.068024</td>\n",
       "      <td>-0.151082</td>\n",
       "      <td>-0.431580</td>\n",
       "      <td>-0.641940</td>\n",
       "      <td>-0.275886</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.135606</td>\n",
       "      <td>-0.068577</td>\n",
       "      <td>-1.299946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>202</td>\n",
       "      <td>-1.352234</td>\n",
       "      <td>-0.919228</td>\n",
       "      <td>-1.512606</td>\n",
       "      <td>0.513611</td>\n",
       "      <td>0.48941</td>\n",
       "      <td>0.884598</td>\n",
       "      <td>-1.395288</td>\n",
       "      <td>-0.081847</td>\n",
       "      <td>0.217771</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.815498</td>\n",
       "      <td>-0.068024</td>\n",
       "      <td>-0.151082</td>\n",
       "      <td>-0.431580</td>\n",
       "      <td>-0.641940</td>\n",
       "      <td>-0.275886</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.135606</td>\n",
       "      <td>-0.068577</td>\n",
       "      <td>-1.299946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>82</td>\n",
       "      <td>-1.339391</td>\n",
       "      <td>-0.905490</td>\n",
       "      <td>0.981980</td>\n",
       "      <td>0.513611</td>\n",
       "      <td>0.48941</td>\n",
       "      <td>-1.935016</td>\n",
       "      <td>-1.623140</td>\n",
       "      <td>-0.081847</td>\n",
       "      <td>0.014620</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.815498</td>\n",
       "      <td>-0.068024</td>\n",
       "      <td>-0.151082</td>\n",
       "      <td>-0.431580</td>\n",
       "      <td>-0.641940</td>\n",
       "      <td>-0.275886</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.135606</td>\n",
       "      <td>-0.068577</td>\n",
       "      <td>-1.299946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>94</td>\n",
       "      <td>-0.191171</td>\n",
       "      <td>0.468254</td>\n",
       "      <td>1.394618</td>\n",
       "      <td>0.513611</td>\n",
       "      <td>0.48941</td>\n",
       "      <td>-0.442279</td>\n",
       "      <td>-0.330054</td>\n",
       "      <td>-0.081847</td>\n",
       "      <td>-0.112349</td>\n",
       "      <td>...</td>\n",
       "      <td>1.226244</td>\n",
       "      <td>-0.068024</td>\n",
       "      <td>-0.151082</td>\n",
       "      <td>-0.431580</td>\n",
       "      <td>1.172029</td>\n",
       "      <td>-0.275886</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.135606</td>\n",
       "      <td>-0.068577</td>\n",
       "      <td>0.769263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>192</td>\n",
       "      <td>-0.625659</td>\n",
       "      <td>-0.053769</td>\n",
       "      <td>1.169543</td>\n",
       "      <td>0.513611</td>\n",
       "      <td>0.48941</td>\n",
       "      <td>-0.027630</td>\n",
       "      <td>-0.668401</td>\n",
       "      <td>-0.081847</td>\n",
       "      <td>0.344741</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.815498</td>\n",
       "      <td>-0.068024</td>\n",
       "      <td>-0.151082</td>\n",
       "      <td>-0.431580</td>\n",
       "      <td>-0.641940</td>\n",
       "      <td>-0.275886</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.135606</td>\n",
       "      <td>-0.068577</td>\n",
       "      <td>0.769263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>305</td>\n",
       "      <td>-0.003156</td>\n",
       "      <td>0.688053</td>\n",
       "      <td>1.469643</td>\n",
       "      <td>0.513611</td>\n",
       "      <td>0.48941</td>\n",
       "      <td>-0.138203</td>\n",
       "      <td>-0.014095</td>\n",
       "      <td>-0.081847</td>\n",
       "      <td>0.598679</td>\n",
       "      <td>...</td>\n",
       "      <td>1.226244</td>\n",
       "      <td>-0.068024</td>\n",
       "      <td>-0.151082</td>\n",
       "      <td>-0.431580</td>\n",
       "      <td>-0.641940</td>\n",
       "      <td>-0.275886</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.135606</td>\n",
       "      <td>-0.068577</td>\n",
       "      <td>0.769263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73 rows Ã— 160 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ReplayID  Duration     Frame   MapName  MapWidth  MapHeight  \\\n",
       "193       193 -0.684519 -0.122456 -0.818624  0.513611    0.48941   \n",
       "33         33 -0.533382  0.056131  0.888199  0.513611    0.48941   \n",
       "15         15 -0.007826  0.681184 -1.550119  0.513611    0.48941   \n",
       "347       347 -1.477967 -1.070340 -1.174993  0.513611    0.48941   \n",
       "57         57  1.076904  1.752705 -1.174993  0.513611    0.48941   \n",
       "..        ...       ...       ...       ...       ...        ...   \n",
       "202       202 -1.352234 -0.919228 -1.512606  0.513611    0.48941   \n",
       "82         82 -1.339391 -0.905490  0.981980  0.513611    0.48941   \n",
       "94         94 -0.191171  0.468254  1.394618  0.513611    0.48941   \n",
       "192       192 -0.625659 -0.053769  1.169543  0.513611    0.48941   \n",
       "305       305 -0.003156  0.688053  1.469643  0.513611    0.48941   \n",
       "\n",
       "     Player1_EAPM  Player1_ECmdCount  Player1_Race  Player2_EAPM  ...  \\\n",
       "193     -1.161004          -0.996638     -0.081847     -1.737556  ...   \n",
       "33      -0.055273          -0.576683     -0.081847     -0.645620  ...   \n",
       "15       0.635808           0.272616     -0.081847     -1.305860  ...   \n",
       "347     -1.548010          -1.698970     -0.081847     -0.747195  ...   \n",
       "57      -1.852086           0.068596     -0.081847     -0.569438  ...   \n",
       "..            ...                ...           ...           ...  ...   \n",
       "202      0.884598          -1.395288     -0.081847      0.217771  ...   \n",
       "82      -1.935016          -1.623140     -0.081847      0.014620  ...   \n",
       "94      -0.442279          -0.330054     -0.081847     -0.112349  ...   \n",
       "192     -0.027630          -0.668401     -0.081847      0.344741  ...   \n",
       "305     -0.138203          -0.014095     -0.081847      0.598679  ...   \n",
       "\n",
       "     Player2_Leg Enhancements_Level  Player2_Protoss Air Armor_Level  \\\n",
       "193                       -0.815498                        -0.068024   \n",
       "33                        -0.815498                        -0.068024   \n",
       "15                         1.226244                        -0.068024   \n",
       "347                       -0.815498                        -0.068024   \n",
       "57                        -0.815498                        -0.068024   \n",
       "..                              ...                              ...   \n",
       "202                       -0.815498                        -0.068024   \n",
       "82                        -0.815498                        -0.068024   \n",
       "94                         1.226244                        -0.068024   \n",
       "192                       -0.815498                        -0.068024   \n",
       "305                        1.226244                        -0.068024   \n",
       "\n",
       "     Player2_Protoss Air Weapons_Level  Player2_Protoss Ground Armor_Level  \\\n",
       "193                          -0.151082                           -0.431580   \n",
       "33                           -0.151082                           -0.431580   \n",
       "15                           -0.151082                            1.923429   \n",
       "347                          -0.151082                           -0.431580   \n",
       "57                           -0.151082                           -0.431580   \n",
       "..                                 ...                                 ...   \n",
       "202                          -0.151082                           -0.431580   \n",
       "82                           -0.151082                           -0.431580   \n",
       "94                           -0.151082                           -0.431580   \n",
       "192                          -0.151082                           -0.431580   \n",
       "305                          -0.151082                           -0.431580   \n",
       "\n",
       "     Player2_Protoss Ground Weapons_Level  \\\n",
       "193                             -0.641940   \n",
       "33                              -0.641940   \n",
       "15                               1.172029   \n",
       "347                             -0.641940   \n",
       "57                              -0.641940   \n",
       "..                                    ...   \n",
       "202                             -0.641940   \n",
       "82                              -0.641940   \n",
       "94                               1.172029   \n",
       "192                             -0.641940   \n",
       "305                             -0.641940   \n",
       "\n",
       "     Player2_Protoss Plasma Shields_Level  Player2_Reaver Capacity_Level  \\\n",
       "193                             -0.275886                            0.0   \n",
       "33                              -0.275886                            0.0   \n",
       "15                              -0.275886                            0.0   \n",
       "347                             -0.275886                            0.0   \n",
       "57                              -0.275886                            0.0   \n",
       "..                                    ...                            ...   \n",
       "202                             -0.275886                            0.0   \n",
       "82                              -0.275886                            0.0   \n",
       "94                              -0.275886                            0.0   \n",
       "192                             -0.275886                            0.0   \n",
       "305                             -0.275886                            0.0   \n",
       "\n",
       "     Player2_Scarab Damage_Level  Player2_Sensor Array_Level  \\\n",
       "193                    -0.135606                   -0.068577   \n",
       "33                     -0.135606                   -0.068577   \n",
       "15                     -0.135606                   -0.068577   \n",
       "347                    -0.135606                   -0.068577   \n",
       "57                     -0.135606                   -0.068577   \n",
       "..                           ...                         ...   \n",
       "202                    -0.135606                   -0.068577   \n",
       "82                     -0.135606                   -0.068577   \n",
       "94                     -0.135606                   -0.068577   \n",
       "192                    -0.135606                   -0.068577   \n",
       "305                    -0.135606                   -0.068577   \n",
       "\n",
       "     Player2_Singularity Charge_Level  \n",
       "193                          0.769263  \n",
       "33                           0.769263  \n",
       "15                           0.769263  \n",
       "347                         -1.299946  \n",
       "57                          -1.299946  \n",
       "..                                ...  \n",
       "202                         -1.299946  \n",
       "82                          -1.299946  \n",
       "94                           0.769263  \n",
       "192                          0.769263  \n",
       "305                          0.769263  \n",
       "\n",
       "[73 rows x 160 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Final_Results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Model</th>\n",
       "      <th>Score</th>\n",
       "      <th>Percentile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1D_All_ReplaysData_PvP.csv</td>\n",
       "      <td>(DecisionTreeClassifier(criterion='entropy', m...</td>\n",
       "      <td>0.684932</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1D_All_ReplaysData_PvP.csv</td>\n",
       "      <td>LogisticRegression(C=0.1, max_iter=1000, penal...</td>\n",
       "      <td>0.698630</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1D_All_ReplaysData_PvP.csv</td>\n",
       "      <td>LinearSVC(C=1e-05, dual='auto', random_state=42)</td>\n",
       "      <td>0.589041</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1D_All_ReplaysData_PvP.csv</td>\n",
       "      <td>KNeighborsClassifier(n_jobs=-1, n_neighbors=17...</td>\n",
       "      <td>0.438356</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1D_All_ReplaysData_PvT.csv</td>\n",
       "      <td>(DecisionTreeClassifier(criterion='entropy', m...</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1D_All_ReplaysData_PvT.csv</td>\n",
       "      <td>LogisticRegression(C=0.1, max_iter=1000, penal...</td>\n",
       "      <td>0.632479</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1D_All_ReplaysData_PvT.csv</td>\n",
       "      <td>LinearSVC(C=1e-05, dual='auto', random_state=42)</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1D_All_ReplaysData_PvT.csv</td>\n",
       "      <td>KNeighborsClassifier(n_jobs=-1, n_neighbors=17...</td>\n",
       "      <td>0.504274</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1D_All_ReplaysData_PvZ.csv</td>\n",
       "      <td>(DecisionTreeClassifier(criterion='entropy', m...</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1D_All_ReplaysData_PvZ.csv</td>\n",
       "      <td>LogisticRegression(C=0.1, max_iter=1000, penal...</td>\n",
       "      <td>0.551282</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1D_All_ReplaysData_PvZ.csv</td>\n",
       "      <td>LinearSVC(C=1e-05, dual='auto', random_state=42)</td>\n",
       "      <td>0.551282</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1D_All_ReplaysData_PvZ.csv</td>\n",
       "      <td>KNeighborsClassifier(n_jobs=-1, n_neighbors=17...</td>\n",
       "      <td>0.397436</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1D_All_ReplaysData_TvT.csv</td>\n",
       "      <td>(DecisionTreeClassifier(criterion='entropy', m...</td>\n",
       "      <td>0.623377</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1D_All_ReplaysData_TvT.csv</td>\n",
       "      <td>LogisticRegression(C=0.1, max_iter=1000, penal...</td>\n",
       "      <td>0.662338</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1D_All_ReplaysData_TvT.csv</td>\n",
       "      <td>LinearSVC(C=1e-05, dual='auto', random_state=42)</td>\n",
       "      <td>0.480519</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1D_All_ReplaysData_TvT.csv</td>\n",
       "      <td>KNeighborsClassifier(n_jobs=-1, n_neighbors=17...</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1D_All_ReplaysData_TvZ.csv</td>\n",
       "      <td>(DecisionTreeClassifier(criterion='entropy', m...</td>\n",
       "      <td>0.557143</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1D_All_ReplaysData_TvZ.csv</td>\n",
       "      <td>LogisticRegression(C=0.1, max_iter=1000, penal...</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1D_All_ReplaysData_TvZ.csv</td>\n",
       "      <td>LinearSVC(C=1e-05, dual='auto', random_state=42)</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1D_All_ReplaysData_TvZ.csv</td>\n",
       "      <td>KNeighborsClassifier(n_jobs=-1, n_neighbors=17...</td>\n",
       "      <td>0.485714</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1D_All_ReplaysData_ZvZ.csv</td>\n",
       "      <td>(DecisionTreeClassifier(criterion='entropy', m...</td>\n",
       "      <td>0.617647</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1D_All_ReplaysData_ZvZ.csv</td>\n",
       "      <td>LogisticRegression(C=0.1, max_iter=1000, penal...</td>\n",
       "      <td>0.617647</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1D_All_ReplaysData_ZvZ.csv</td>\n",
       "      <td>LinearSVC(C=1e-05, dual='auto', random_state=42)</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1D_All_ReplaysData_ZvZ.csv</td>\n",
       "      <td>KNeighborsClassifier(n_jobs=-1, n_neighbors=17...</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>StarCraft_Combined_Dataset.csv</td>\n",
       "      <td>(DecisionTreeClassifier(criterion='entropy', m...</td>\n",
       "      <td>0.629464</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>StarCraft_Combined_Dataset.csv</td>\n",
       "      <td>LogisticRegression(C=0.1, max_iter=1000, penal...</td>\n",
       "      <td>0.640625</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>StarCraft_Combined_Dataset.csv</td>\n",
       "      <td>LinearSVC(C=1e-05, dual='auto', random_state=42)</td>\n",
       "      <td>0.595982</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>StarCraft_Combined_Dataset.csv</td>\n",
       "      <td>KNeighborsClassifier(n_jobs=-1, n_neighbors=17...</td>\n",
       "      <td>0.520089</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              File  \\\n",
       "0       1D_All_ReplaysData_PvP.csv   \n",
       "1       1D_All_ReplaysData_PvP.csv   \n",
       "2       1D_All_ReplaysData_PvP.csv   \n",
       "3       1D_All_ReplaysData_PvP.csv   \n",
       "4       1D_All_ReplaysData_PvT.csv   \n",
       "5       1D_All_ReplaysData_PvT.csv   \n",
       "6       1D_All_ReplaysData_PvT.csv   \n",
       "7       1D_All_ReplaysData_PvT.csv   \n",
       "8       1D_All_ReplaysData_PvZ.csv   \n",
       "9       1D_All_ReplaysData_PvZ.csv   \n",
       "10      1D_All_ReplaysData_PvZ.csv   \n",
       "11      1D_All_ReplaysData_PvZ.csv   \n",
       "12      1D_All_ReplaysData_TvT.csv   \n",
       "13      1D_All_ReplaysData_TvT.csv   \n",
       "14      1D_All_ReplaysData_TvT.csv   \n",
       "15      1D_All_ReplaysData_TvT.csv   \n",
       "16      1D_All_ReplaysData_TvZ.csv   \n",
       "17      1D_All_ReplaysData_TvZ.csv   \n",
       "18      1D_All_ReplaysData_TvZ.csv   \n",
       "19      1D_All_ReplaysData_TvZ.csv   \n",
       "20      1D_All_ReplaysData_ZvZ.csv   \n",
       "21      1D_All_ReplaysData_ZvZ.csv   \n",
       "22      1D_All_ReplaysData_ZvZ.csv   \n",
       "23      1D_All_ReplaysData_ZvZ.csv   \n",
       "24  StarCraft_Combined_Dataset.csv   \n",
       "25  StarCraft_Combined_Dataset.csv   \n",
       "26  StarCraft_Combined_Dataset.csv   \n",
       "27  StarCraft_Combined_Dataset.csv   \n",
       "\n",
       "                                                Model     Score  Percentile  \n",
       "0   (DecisionTreeClassifier(criterion='entropy', m...  0.684932           1  \n",
       "1   LogisticRegression(C=0.1, max_iter=1000, penal...  0.698630           1  \n",
       "2    LinearSVC(C=1e-05, dual='auto', random_state=42)  0.589041           1  \n",
       "3   KNeighborsClassifier(n_jobs=-1, n_neighbors=17...  0.438356           1  \n",
       "4   (DecisionTreeClassifier(criterion='entropy', m...  0.615385           1  \n",
       "5   LogisticRegression(C=0.1, max_iter=1000, penal...  0.632479           1  \n",
       "6    LinearSVC(C=1e-05, dual='auto', random_state=42)  0.461538           1  \n",
       "7   KNeighborsClassifier(n_jobs=-1, n_neighbors=17...  0.504274           1  \n",
       "8   (DecisionTreeClassifier(criterion='entropy', m...  0.576923           1  \n",
       "9   LogisticRegression(C=0.1, max_iter=1000, penal...  0.551282           1  \n",
       "10   LinearSVC(C=1e-05, dual='auto', random_state=42)  0.551282           1  \n",
       "11  KNeighborsClassifier(n_jobs=-1, n_neighbors=17...  0.397436           1  \n",
       "12  (DecisionTreeClassifier(criterion='entropy', m...  0.623377           1  \n",
       "13  LogisticRegression(C=0.1, max_iter=1000, penal...  0.662338           1  \n",
       "14   LinearSVC(C=1e-05, dual='auto', random_state=42)  0.480519           1  \n",
       "15  KNeighborsClassifier(n_jobs=-1, n_neighbors=17...  0.454545           1  \n",
       "16  (DecisionTreeClassifier(criterion='entropy', m...  0.557143           1  \n",
       "17  LogisticRegression(C=0.1, max_iter=1000, penal...  0.571429           1  \n",
       "18   LinearSVC(C=1e-05, dual='auto', random_state=42)  0.628571           1  \n",
       "19  KNeighborsClassifier(n_jobs=-1, n_neighbors=17...  0.485714           1  \n",
       "20  (DecisionTreeClassifier(criterion='entropy', m...  0.617647           1  \n",
       "21  LogisticRegression(C=0.1, max_iter=1000, penal...  0.617647           1  \n",
       "22   LinearSVC(C=1e-05, dual='auto', random_state=42)  0.500000           1  \n",
       "23  KNeighborsClassifier(n_jobs=-1, n_neighbors=17...  0.588235           1  \n",
       "24  (DecisionTreeClassifier(criterion='entropy', m...  0.629464           1  \n",
       "25  LogisticRegression(C=0.1, max_iter=1000, penal...  0.640625           1  \n",
       "26   LinearSVC(C=1e-05, dual='auto', random_state=42)  0.595982           1  \n",
       "27  KNeighborsClassifier(n_jobs=-1, n_neighbors=17...  0.520089           1  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ReplayID</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Frame</th>\n",
       "      <th>MapName</th>\n",
       "      <th>MapWidth</th>\n",
       "      <th>MapHeight</th>\n",
       "      <th>Player1_EAPM</th>\n",
       "      <th>Player1_ECmdCount</th>\n",
       "      <th>Player1_Race</th>\n",
       "      <th>Player2_EAPM</th>\n",
       "      <th>...</th>\n",
       "      <th>Player2_Protoss Air Armor_Level</th>\n",
       "      <th>Player2_Protoss Air Weapons_Level</th>\n",
       "      <th>Player2_Protoss Ground Armor_Level</th>\n",
       "      <th>Player2_Protoss Ground Weapons_Level</th>\n",
       "      <th>Player2_Protoss Plasma Shields_Level</th>\n",
       "      <th>Player2_Reaver Capacity_Level</th>\n",
       "      <th>Player2_Scarab Damage_Level</th>\n",
       "      <th>Player2_Sensor Array_Level</th>\n",
       "      <th>Player2_Singularity Charge_Level</th>\n",
       "      <th>Winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GG10042</td>\n",
       "      <td>28603</td>\n",
       "      <td>0</td>\n",
       "      <td>| iCCup | PeaksOfBeakdu</td>\n",
       "      <td>96</td>\n",
       "      <td>128</td>\n",
       "      <td>168</td>\n",
       "      <td>3360</td>\n",
       "      <td>Protoss</td>\n",
       "      <td>187</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GG10042</td>\n",
       "      <td>28603</td>\n",
       "      <td>100</td>\n",
       "      <td>| iCCup | PeaksOfBeakdu</td>\n",
       "      <td>96</td>\n",
       "      <td>128</td>\n",
       "      <td>168</td>\n",
       "      <td>3360</td>\n",
       "      <td>Protoss</td>\n",
       "      <td>187</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GG10042</td>\n",
       "      <td>28603</td>\n",
       "      <td>200</td>\n",
       "      <td>| iCCup | PeaksOfBeakdu</td>\n",
       "      <td>96</td>\n",
       "      <td>128</td>\n",
       "      <td>168</td>\n",
       "      <td>3360</td>\n",
       "      <td>Protoss</td>\n",
       "      <td>187</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GG10042</td>\n",
       "      <td>28603</td>\n",
       "      <td>300</td>\n",
       "      <td>| iCCup | PeaksOfBeakdu</td>\n",
       "      <td>96</td>\n",
       "      <td>128</td>\n",
       "      <td>168</td>\n",
       "      <td>3360</td>\n",
       "      <td>Protoss</td>\n",
       "      <td>187</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GG10042</td>\n",
       "      <td>28603</td>\n",
       "      <td>400</td>\n",
       "      <td>| iCCup | PeaksOfBeakdu</td>\n",
       "      <td>96</td>\n",
       "      <td>128</td>\n",
       "      <td>168</td>\n",
       "      <td>3360</td>\n",
       "      <td>Protoss</td>\n",
       "      <td>187</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143687</th>\n",
       "      <td>TL996</td>\n",
       "      <td>50903</td>\n",
       "      <td>50400</td>\n",
       "      <td>\u0003Monty \u0002Hall\u0006_SE \u00052.1</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>196</td>\n",
       "      <td>6984</td>\n",
       "      <td>Protoss</td>\n",
       "      <td>206</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143688</th>\n",
       "      <td>TL996</td>\n",
       "      <td>50903</td>\n",
       "      <td>50500</td>\n",
       "      <td>\u0003Monty \u0002Hall\u0006_SE \u00052.1</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>196</td>\n",
       "      <td>6984</td>\n",
       "      <td>Protoss</td>\n",
       "      <td>206</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143689</th>\n",
       "      <td>TL996</td>\n",
       "      <td>50903</td>\n",
       "      <td>50600</td>\n",
       "      <td>\u0003Monty \u0002Hall\u0006_SE \u00052.1</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>196</td>\n",
       "      <td>6984</td>\n",
       "      <td>Protoss</td>\n",
       "      <td>206</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143690</th>\n",
       "      <td>TL996</td>\n",
       "      <td>50903</td>\n",
       "      <td>50700</td>\n",
       "      <td>\u0003Monty \u0002Hall\u0006_SE \u00052.1</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>196</td>\n",
       "      <td>6984</td>\n",
       "      <td>Protoss</td>\n",
       "      <td>206</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143691</th>\n",
       "      <td>TL996</td>\n",
       "      <td>50903</td>\n",
       "      <td>50800</td>\n",
       "      <td>\u0003Monty \u0002Hall\u0006_SE \u00052.1</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>196</td>\n",
       "      <td>6984</td>\n",
       "      <td>Protoss</td>\n",
       "      <td>206</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118569 rows Ã— 161 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ReplayID  Duration  Frame                  MapName  MapWidth  \\\n",
       "0       GG10042     28603      0  | iCCup | PeaksOfBeakdu        96   \n",
       "1       GG10042     28603    100  | iCCup | PeaksOfBeakdu        96   \n",
       "2       GG10042     28603    200  | iCCup | PeaksOfBeakdu        96   \n",
       "3       GG10042     28603    300  | iCCup | PeaksOfBeakdu        96   \n",
       "4       GG10042     28603    400  | iCCup | PeaksOfBeakdu        96   \n",
       "...         ...       ...    ...                      ...       ...   \n",
       "143687    TL996     50903  50400    \u0003Monty \u0002Hall\u0006_SE \u00052.1       128   \n",
       "143688    TL996     50903  50500    \u0003Monty \u0002Hall\u0006_SE \u00052.1       128   \n",
       "143689    TL996     50903  50600    \u0003Monty \u0002Hall\u0006_SE \u00052.1       128   \n",
       "143690    TL996     50903  50700    \u0003Monty \u0002Hall\u0006_SE \u00052.1       128   \n",
       "143691    TL996     50903  50800    \u0003Monty \u0002Hall\u0006_SE \u00052.1       128   \n",
       "\n",
       "        MapHeight  Player1_EAPM  Player1_ECmdCount Player1_Race  Player2_EAPM  \\\n",
       "0             128           168               3360      Protoss           187   \n",
       "1             128           168               3360      Protoss           187   \n",
       "2             128           168               3360      Protoss           187   \n",
       "3             128           168               3360      Protoss           187   \n",
       "4             128           168               3360      Protoss           187   \n",
       "...           ...           ...                ...          ...           ...   \n",
       "143687        128           196               6984      Protoss           206   \n",
       "143688        128           196               6984      Protoss           206   \n",
       "143689        128           196               6984      Protoss           206   \n",
       "143690        128           196               6984      Protoss           206   \n",
       "143691        128           196               6984      Protoss           206   \n",
       "\n",
       "        ...  Player2_Protoss Air Armor_Level  \\\n",
       "0       ...                                0   \n",
       "1       ...                                0   \n",
       "2       ...                                0   \n",
       "3       ...                                0   \n",
       "4       ...                                0   \n",
       "...     ...                              ...   \n",
       "143687  ...                                0   \n",
       "143688  ...                                0   \n",
       "143689  ...                                0   \n",
       "143690  ...                                0   \n",
       "143691  ...                                0   \n",
       "\n",
       "       Player2_Protoss Air Weapons_Level  Player2_Protoss Ground Armor_Level  \\\n",
       "0                                      0                                   0   \n",
       "1                                      0                                   0   \n",
       "2                                      0                                   0   \n",
       "3                                      0                                   0   \n",
       "4                                      0                                   0   \n",
       "...                                  ...                                 ...   \n",
       "143687                                 0                                   0   \n",
       "143688                                 0                                   0   \n",
       "143689                                 0                                   0   \n",
       "143690                                 0                                   0   \n",
       "143691                                 0                                   0   \n",
       "\n",
       "        Player2_Protoss Ground Weapons_Level  \\\n",
       "0                                          0   \n",
       "1                                          0   \n",
       "2                                          0   \n",
       "3                                          0   \n",
       "4                                          0   \n",
       "...                                      ...   \n",
       "143687                                     2   \n",
       "143688                                     2   \n",
       "143689                                     2   \n",
       "143690                                     2   \n",
       "143691                                     2   \n",
       "\n",
       "        Player2_Protoss Plasma Shields_Level  Player2_Reaver Capacity_Level  \\\n",
       "0                                          0                              0   \n",
       "1                                          0                              0   \n",
       "2                                          0                              0   \n",
       "3                                          0                              0   \n",
       "4                                          0                              0   \n",
       "...                                      ...                            ...   \n",
       "143687                                     0                              0   \n",
       "143688                                     0                              0   \n",
       "143689                                     0                              0   \n",
       "143690                                     0                              0   \n",
       "143691                                     0                              0   \n",
       "\n",
       "        Player2_Scarab Damage_Level  Player2_Sensor Array_Level  \\\n",
       "0                                 0                           0   \n",
       "1                                 0                           0   \n",
       "2                                 0                           0   \n",
       "3                                 0                           0   \n",
       "4                                 0                           0   \n",
       "...                             ...                         ...   \n",
       "143687                            0                           0   \n",
       "143688                            0                           0   \n",
       "143689                            0                           0   \n",
       "143690                            0                           0   \n",
       "143691                            0                           0   \n",
       "\n",
       "        Player2_Singularity Charge_Level  Winner  \n",
       "0                                      0       1  \n",
       "1                                      0       1  \n",
       "2                                      0       1  \n",
       "3                                      0       1  \n",
       "4                                      0       1  \n",
       "...                                  ...     ...  \n",
       "143687                                 1       0  \n",
       "143688                                 1       0  \n",
       "143689                                 1       0  \n",
       "143690                                 1       0  \n",
       "143691                                 1       0  \n",
       "\n",
       "[118569 rows x 161 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start by reading the full dataset to identify top correlating features with the 'Winner' column.\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the LSTM model\n",
    "def build_model(input_shape):\n",
    "    model = Sequential([\n",
    "        LSTM(60,return_sequences=True,input_shape=input_shape),\n",
    "        Dropout(0.2),\n",
    "        LSTM(50),\n",
    "        Dropout(0.2),\n",
    "        Dense(1, activation='sigmoid') \n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['1D_All_ReplaysData_PvP.csv', '1D_All_ReplaysData_PvT.csv', '1D_All_ReplaysData_PvZ.csv', '1D_All_ReplaysData_TvT.csv', '1D_All_ReplaysData_TvZ.csv', '1D_All_ReplaysData_ZvZ.csv', \"StarCraft_Combined_Dataset.csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhin\\anaconda3\\envs\\DevelopmentEnv\\lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\abhin\\anaconda3\\envs\\DevelopmentEnv\\lib\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "19/19 [==============================] - 4s 68ms/step - loss: 0.6967 - accuracy: 0.5488 - val_loss: 0.6798 - val_accuracy: 0.5758\n",
      "Epoch 2/100\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 0.6775 - accuracy: 0.5892 - val_loss: 0.6843 - val_accuracy: 0.5758\n",
      "Epoch 3/100\n",
      "19/19 [==============================] - 1s 39ms/step - loss: 0.6780 - accuracy: 0.5960 - val_loss: 0.6793 - val_accuracy: 0.5758\n",
      "Epoch 4/100\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 0.6523 - accuracy: 0.6229 - val_loss: 0.6730 - val_accuracy: 0.6061\n",
      "Epoch 5/100\n",
      "19/19 [==============================] - 1s 39ms/step - loss: 0.6625 - accuracy: 0.6296 - val_loss: 0.6727 - val_accuracy: 0.6364\n",
      "Epoch 6/100\n",
      "19/19 [==============================] - 1s 39ms/step - loss: 0.6491 - accuracy: 0.6364 - val_loss: 0.6700 - val_accuracy: 0.6061\n",
      "Epoch 7/100\n",
      "19/19 [==============================] - 1s 38ms/step - loss: 0.6549 - accuracy: 0.6566 - val_loss: 0.6664 - val_accuracy: 0.6364\n",
      "Epoch 8/100\n",
      "19/19 [==============================] - 1s 38ms/step - loss: 0.6452 - accuracy: 0.6633 - val_loss: 0.6924 - val_accuracy: 0.5758\n",
      "Epoch 9/100\n",
      "19/19 [==============================] - 1s 38ms/step - loss: 0.6215 - accuracy: 0.6734 - val_loss: 0.7191 - val_accuracy: 0.5455\n",
      "Epoch 10/100\n",
      "19/19 [==============================] - 1s 38ms/step - loss: 0.6163 - accuracy: 0.6633 - val_loss: 0.7632 - val_accuracy: 0.5152\n",
      "Epoch 11/100\n",
      "19/19 [==============================] - 1s 38ms/step - loss: 0.6164 - accuracy: 0.6768 - val_loss: 0.8067 - val_accuracy: 0.4242\n",
      "Epoch 12/100\n",
      "19/19 [==============================] - 1s 38ms/step - loss: 0.5944 - accuracy: 0.6936 - val_loss: 0.8135 - val_accuracy: 0.4848\n",
      "Epoch 13/100\n",
      "19/19 [==============================] - 1s 38ms/step - loss: 0.5780 - accuracy: 0.6835 - val_loss: 0.8333 - val_accuracy: 0.3939\n",
      "Epoch 14/100\n",
      "19/19 [==============================] - 1s 38ms/step - loss: 0.5678 - accuracy: 0.7104 - val_loss: 0.9112 - val_accuracy: 0.4242\n",
      "Epoch 15/100\n",
      "19/19 [==============================] - 1s 38ms/step - loss: 0.5730 - accuracy: 0.7003 - val_loss: 0.8442 - val_accuracy: 0.4848\n",
      "Epoch 16/100\n",
      "19/19 [==============================] - 1s 39ms/step - loss: 0.5706 - accuracy: 0.7037 - val_loss: 0.9584 - val_accuracy: 0.4545\n",
      "Epoch 17/100\n",
      "19/19 [==============================] - 1s 39ms/step - loss: 0.5391 - accuracy: 0.7273 - val_loss: 0.9065 - val_accuracy: 0.4545\n",
      "3/3 - 0s - loss: 0.7063 - accuracy: 0.6024 - 91ms/epoch - 30ms/step\n",
      "{'File': '1D_All_ReplaysData_PvP.csv', 'LSTM': 0.6024096608161926}\n",
      "1D_All_ReplaysData_PvP.csv  Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhin\\anaconda3\\envs\\DevelopmentEnv\\lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\abhin\\anaconda3\\envs\\DevelopmentEnv\\lib\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "34/34 [==============================] - 4s 54ms/step - loss: 0.6774 - accuracy: 0.5989 - val_loss: 0.6539 - val_accuracy: 0.6271\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 0.6615 - accuracy: 0.6215 - val_loss: 0.6591 - val_accuracy: 0.6780\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 0.6622 - accuracy: 0.6139 - val_loss: 0.6540 - val_accuracy: 0.6271\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 0.6619 - accuracy: 0.6384 - val_loss: 0.6640 - val_accuracy: 0.5932\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 1s 40ms/step - loss: 0.6506 - accuracy: 0.6290 - val_loss: 0.6613 - val_accuracy: 0.6271\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 1s 40ms/step - loss: 0.6393 - accuracy: 0.6422 - val_loss: 0.6843 - val_accuracy: 0.5932\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 1s 40ms/step - loss: 0.6412 - accuracy: 0.6347 - val_loss: 0.6663 - val_accuracy: 0.6102\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 1s 41ms/step - loss: 0.6372 - accuracy: 0.6347 - val_loss: 0.6905 - val_accuracy: 0.6271\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 1s 41ms/step - loss: 0.6459 - accuracy: 0.6328 - val_loss: 0.6817 - val_accuracy: 0.5932\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 1s 41ms/step - loss: 0.6263 - accuracy: 0.6516 - val_loss: 0.6685 - val_accuracy: 0.6102\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 1s 41ms/step - loss: 0.6233 - accuracy: 0.6648 - val_loss: 0.6836 - val_accuracy: 0.6102\n",
      "5/5 - 0s - loss: 0.6713 - accuracy: 0.6284 - 219ms/epoch - 44ms/step\n",
      "{'File': '1D_All_ReplaysData_PvT.csv', 'LSTM': 0.6283783912658691}\n",
      "1D_All_ReplaysData_PvT.csv  Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhin\\anaconda3\\envs\\DevelopmentEnv\\lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\abhin\\anaconda3\\envs\\DevelopmentEnv\\lib\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "22/22 [==============================] - 4s 66ms/step - loss: 0.6918 - accuracy: 0.4957 - val_loss: 0.6493 - val_accuracy: 0.6410\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.6562 - accuracy: 0.6282 - val_loss: 0.6283 - val_accuracy: 0.6410\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 1s 41ms/step - loss: 0.6517 - accuracy: 0.6254 - val_loss: 0.6257 - val_accuracy: 0.6410\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 1s 41ms/step - loss: 0.6410 - accuracy: 0.6398 - val_loss: 0.6351 - val_accuracy: 0.5897\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 1s 41ms/step - loss: 0.6371 - accuracy: 0.6455 - val_loss: 0.6107 - val_accuracy: 0.5897\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 1s 43ms/step - loss: 0.6275 - accuracy: 0.6657 - val_loss: 0.6324 - val_accuracy: 0.5641\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 1s 43ms/step - loss: 0.6129 - accuracy: 0.6772 - val_loss: 0.6929 - val_accuracy: 0.5897\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 1s 43ms/step - loss: 0.6067 - accuracy: 0.6657 - val_loss: 0.6178 - val_accuracy: 0.6410\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 1s 41ms/step - loss: 0.6206 - accuracy: 0.6571 - val_loss: 0.6362 - val_accuracy: 0.6154\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.6124 - accuracy: 0.6715 - val_loss: 0.6114 - val_accuracy: 0.6154\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.6061 - accuracy: 0.6686 - val_loss: 0.6017 - val_accuracy: 0.6154\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.6009 - accuracy: 0.6859 - val_loss: 0.6542 - val_accuracy: 0.6154\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.5996 - accuracy: 0.6744 - val_loss: 0.6684 - val_accuracy: 0.5897\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.5973 - accuracy: 0.6801 - val_loss: 0.6706 - val_accuracy: 0.5897\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.5813 - accuracy: 0.6888 - val_loss: 0.7261 - val_accuracy: 0.6154\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.5862 - accuracy: 0.6916 - val_loss: 0.7423 - val_accuracy: 0.5128\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.5824 - accuracy: 0.6916 - val_loss: 0.6944 - val_accuracy: 0.5897\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.5839 - accuracy: 0.6916 - val_loss: 0.6774 - val_accuracy: 0.5897\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.5834 - accuracy: 0.6830 - val_loss: 0.6869 - val_accuracy: 0.5897\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.5578 - accuracy: 0.7147 - val_loss: 0.7118 - val_accuracy: 0.6154\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 1s 41ms/step - loss: 0.5511 - accuracy: 0.7147 - val_loss: 0.7396 - val_accuracy: 0.5897\n",
      "4/4 - 0s - loss: 0.7487 - accuracy: 0.4948 - 149ms/epoch - 37ms/step\n",
      "{'File': '1D_All_ReplaysData_PvZ.csv', 'LSTM': 0.49484536051750183}\n",
      "1D_All_ReplaysData_PvZ.csv  Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhin\\anaconda3\\envs\\DevelopmentEnv\\lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\abhin\\anaconda3\\envs\\DevelopmentEnv\\lib\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "20/20 [==============================] - 3s 59ms/step - loss: 0.6902 - accuracy: 0.5562 - val_loss: 0.7478 - val_accuracy: 0.4167\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.6686 - accuracy: 0.5938 - val_loss: 0.7407 - val_accuracy: 0.4444\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.6685 - accuracy: 0.5906 - val_loss: 0.7477 - val_accuracy: 0.4722\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.6563 - accuracy: 0.6187 - val_loss: 0.7708 - val_accuracy: 0.3889\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.6509 - accuracy: 0.5906 - val_loss: 0.7616 - val_accuracy: 0.4167\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.6333 - accuracy: 0.6469 - val_loss: 0.7973 - val_accuracy: 0.4444\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.6279 - accuracy: 0.6281 - val_loss: 0.8226 - val_accuracy: 0.4167\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.6222 - accuracy: 0.6281 - val_loss: 0.8454 - val_accuracy: 0.3889\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.6003 - accuracy: 0.6594 - val_loss: 0.9468 - val_accuracy: 0.3889\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.6003 - accuracy: 0.6687 - val_loss: 0.8291 - val_accuracy: 0.4722\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.5796 - accuracy: 0.7031 - val_loss: 0.9312 - val_accuracy: 0.4444\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.5773 - accuracy: 0.7063 - val_loss: 0.9860 - val_accuracy: 0.4167\n",
      "3/3 - 0s - loss: 0.6766 - accuracy: 0.5955 - 132ms/epoch - 44ms/step\n",
      "{'File': '1D_All_ReplaysData_TvT.csv', 'LSTM': 0.5955055952072144}\n",
      "1D_All_ReplaysData_TvT.csv  Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhin\\anaconda3\\envs\\DevelopmentEnv\\lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\abhin\\anaconda3\\envs\\DevelopmentEnv\\lib\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21/21 [==============================] - 4s 73ms/step - loss: 0.6799 - accuracy: 0.6108 - val_loss: 0.5402 - val_accuracy: 0.8158\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 0.6467 - accuracy: 0.6497 - val_loss: 0.5301 - val_accuracy: 0.8421\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 0.6420 - accuracy: 0.6617 - val_loss: 0.5332 - val_accuracy: 0.8421\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 0.6279 - accuracy: 0.6707 - val_loss: 0.5247 - val_accuracy: 0.7895\n",
      "Epoch 5/100\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.6285 - accuracy: 0.6647 - val_loss: 0.5350 - val_accuracy: 0.8421\n",
      "Epoch 6/100\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.6247 - accuracy: 0.6737 - val_loss: 0.5385 - val_accuracy: 0.8421\n",
      "Epoch 7/100\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.6193 - accuracy: 0.6617 - val_loss: 0.5601 - val_accuracy: 0.8421\n",
      "Epoch 8/100\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 0.6110 - accuracy: 0.6766 - val_loss: 0.5501 - val_accuracy: 0.8158\n",
      "Epoch 9/100\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 0.6049 - accuracy: 0.6737 - val_loss: 0.5963 - val_accuracy: 0.7368\n",
      "Epoch 10/100\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 0.5927 - accuracy: 0.6647 - val_loss: 0.5871 - val_accuracy: 0.7368\n",
      "Epoch 11/100\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 0.5956 - accuracy: 0.6617 - val_loss: 0.6600 - val_accuracy: 0.5263\n",
      "Epoch 12/100\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.6042 - accuracy: 0.6707 - val_loss: 0.5573 - val_accuracy: 0.7632\n",
      "Epoch 13/100\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 0.5739 - accuracy: 0.6946 - val_loss: 0.6032 - val_accuracy: 0.7368\n",
      "Epoch 14/100\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.5624 - accuracy: 0.7186 - val_loss: 0.6305 - val_accuracy: 0.6579\n",
      "3/3 - 0s - loss: 0.6587 - accuracy: 0.6383 - 168ms/epoch - 56ms/step\n",
      "{'File': '1D_All_ReplaysData_TvZ.csv', 'LSTM': 0.6382978558540344}\n",
      "1D_All_ReplaysData_TvZ.csv  Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhin\\anaconda3\\envs\\DevelopmentEnv\\lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\abhin\\anaconda3\\envs\\DevelopmentEnv\\lib\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 4s 121ms/step - loss: 0.6980 - accuracy: 0.4874 - val_loss: 0.7007 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 44ms/step - loss: 0.6773 - accuracy: 0.5714 - val_loss: 0.7004 - val_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 42ms/step - loss: 0.6657 - accuracy: 0.6555 - val_loss: 0.6980 - val_accuracy: 0.5000\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 45ms/step - loss: 0.6668 - accuracy: 0.5966 - val_loss: 0.7076 - val_accuracy: 0.5714\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 43ms/step - loss: 0.6494 - accuracy: 0.6891 - val_loss: 0.7137 - val_accuracy: 0.5714\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 45ms/step - loss: 0.6356 - accuracy: 0.6975 - val_loss: 0.6804 - val_accuracy: 0.5000\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 44ms/step - loss: 0.6350 - accuracy: 0.6218 - val_loss: 0.7000 - val_accuracy: 0.5714\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 42ms/step - loss: 0.6273 - accuracy: 0.6471 - val_loss: 0.7073 - val_accuracy: 0.5714\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 42ms/step - loss: 0.6053 - accuracy: 0.6471 - val_loss: 0.7061 - val_accuracy: 0.5000\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 39ms/step - loss: 0.6088 - accuracy: 0.6723 - val_loss: 0.7208 - val_accuracy: 0.5000\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 43ms/step - loss: 0.5930 - accuracy: 0.6807 - val_loss: 0.7086 - val_accuracy: 0.5714\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 44ms/step - loss: 0.5825 - accuracy: 0.6891 - val_loss: 0.7339 - val_accuracy: 0.5000\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 41ms/step - loss: 0.5889 - accuracy: 0.6723 - val_loss: 0.8242 - val_accuracy: 0.5000\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 40ms/step - loss: 0.6104 - accuracy: 0.6723 - val_loss: 0.8436 - val_accuracy: 0.5000\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 39ms/step - loss: 0.5832 - accuracy: 0.7059 - val_loss: 0.7488 - val_accuracy: 0.5000\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 40ms/step - loss: 0.5685 - accuracy: 0.6975 - val_loss: 0.7267 - val_accuracy: 0.5000\n",
      "2/2 - 0s - loss: 0.7906 - accuracy: 0.4412 - 72ms/epoch - 36ms/step\n",
      "{'File': '1D_All_ReplaysData_ZvZ.csv', 'LSTM': 0.44117647409439087}\n",
      "1D_All_ReplaysData_ZvZ.csv  Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhin\\anaconda3\\envs\\DevelopmentEnv\\lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\abhin\\anaconda3\\envs\\DevelopmentEnv\\lib\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "122/122 [==============================] - 6s 33ms/step - loss: 0.6730 - accuracy: 0.6060 - val_loss: 0.6837 - val_accuracy: 0.5991\n",
      "Epoch 2/100\n",
      "122/122 [==============================] - 3s 29ms/step - loss: 0.6668 - accuracy: 0.6189 - val_loss: 0.6846 - val_accuracy: 0.5899\n",
      "Epoch 3/100\n",
      "122/122 [==============================] - 3s 28ms/step - loss: 0.6650 - accuracy: 0.6137 - val_loss: 0.6826 - val_accuracy: 0.5945\n",
      "Epoch 4/100\n",
      "122/122 [==============================] - 3s 28ms/step - loss: 0.6636 - accuracy: 0.6240 - val_loss: 0.6868 - val_accuracy: 0.5945\n",
      "Epoch 5/100\n",
      "122/122 [==============================] - 4s 29ms/step - loss: 0.6601 - accuracy: 0.6209 - val_loss: 0.6854 - val_accuracy: 0.6037\n",
      "Epoch 6/100\n",
      "122/122 [==============================] - 3s 28ms/step - loss: 0.6597 - accuracy: 0.6250 - val_loss: 0.6863 - val_accuracy: 0.5991\n",
      "Epoch 7/100\n",
      "122/122 [==============================] - 3s 28ms/step - loss: 0.6563 - accuracy: 0.6281 - val_loss: 0.6777 - val_accuracy: 0.5945\n",
      "Epoch 8/100\n",
      "122/122 [==============================] - 3s 29ms/step - loss: 0.6564 - accuracy: 0.6311 - val_loss: 0.6845 - val_accuracy: 0.6037\n",
      "Epoch 9/100\n",
      "122/122 [==============================] - 3s 28ms/step - loss: 0.6511 - accuracy: 0.6270 - val_loss: 0.6989 - val_accuracy: 0.5899\n",
      "Epoch 10/100\n",
      "122/122 [==============================] - 3s 28ms/step - loss: 0.6532 - accuracy: 0.6255 - val_loss: 0.6996 - val_accuracy: 0.5853\n",
      "Epoch 11/100\n",
      "122/122 [==============================] - 4s 29ms/step - loss: 0.6507 - accuracy: 0.6276 - val_loss: 0.6907 - val_accuracy: 0.6083\n",
      "Epoch 12/100\n",
      "122/122 [==============================] - 3s 28ms/step - loss: 0.6445 - accuracy: 0.6311 - val_loss: 0.6997 - val_accuracy: 0.5622\n",
      "Epoch 13/100\n",
      "122/122 [==============================] - 4s 29ms/step - loss: 0.6436 - accuracy: 0.6429 - val_loss: 0.7245 - val_accuracy: 0.5899\n",
      "Epoch 14/100\n",
      "122/122 [==============================] - 4s 30ms/step - loss: 0.6419 - accuracy: 0.6373 - val_loss: 0.7203 - val_accuracy: 0.5760\n",
      "Epoch 15/100\n",
      "122/122 [==============================] - 4s 30ms/step - loss: 0.6380 - accuracy: 0.6445 - val_loss: 0.7089 - val_accuracy: 0.5853\n",
      "Epoch 16/100\n",
      "122/122 [==============================] - 4s 29ms/step - loss: 0.6311 - accuracy: 0.6522 - val_loss: 0.7168 - val_accuracy: 0.5576\n",
      "Epoch 17/100\n",
      "122/122 [==============================] - 4s 29ms/step - loss: 0.6318 - accuracy: 0.6552 - val_loss: 0.7171 - val_accuracy: 0.5576\n",
      "17/17 - 1s - loss: 0.6791 - accuracy: 0.5985 - 1s/epoch - 61ms/step\n",
      "{'File': 'StarCraft_Combined_Dataset.csv', 'LSTM': 0.5985267162322998}\n",
      "StarCraft_Combined_Dataset.csv  Done!\n"
     ]
    }
   ],
   "source": [
    "# Create df for adding performance of different models\n",
    "df = pd.DataFrame(columns=['File', 'Model', 'Score', 'Percentile'])\n",
    "df_list = []  # Initialize an empty list to store DataFrames to concatenate later.\n",
    "\n",
    "for file in files:\n",
    "    # Load the dataset\n",
    "    file_path = '../'+ file\n",
    "    data = pd.read_csv(file_path)\n",
    "    # data.drop(columns=[\"Player1_Race\",\"Player2_Race\"],axis=1,inplace=True)\n",
    "    # label encode player races\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoders = {}\n",
    "\n",
    "    for column in ['ReplayID', 'Player1_Race', 'Player2_Race', 'MapName']:\n",
    "        label_encoders[column] = LabelEncoder()\n",
    "        data[column] = label_encoders[column].fit_transform(data[column])\n",
    "\n",
    "\n",
    "    # Drop columns with non-numeric data (except for 'Player1_Race' and 'Player2_Race', which we'll one-hot encode)\n",
    "    data_numeric = data.select_dtypes(include=[np.number])\n",
    "\n",
    "    # Calculate correlations with the 'Winner' column\n",
    "    correlations = data_numeric.corrwith(data_numeric['Winner']).sort_values(ascending=False)\n",
    "\n",
    "    # Select top 5 correlating features (excluding 'Winner' itself)\n",
    "    top_features = correlations.index[1:10]  # Excluding 'Winner' which is at the top\n",
    "\n",
    "    # Function to filter groups with at least 120 rows\n",
    "    def filter_groups(group):\n",
    "        if len(group) >= 120:\n",
    "            return group.iloc[:120]  # Return only the first 120 rows\n",
    "\n",
    "    # Group by 'replayID', apply the filter function\n",
    "    filtered_groups = data.groupby('ReplayID').apply(filter_groups).reset_index(drop=True)\n",
    "    # Add races back for one-hot encoding\n",
    "    features_to_use = list(top_features) + [\"ReplayID\"]\n",
    "    X = filtered_groups[features_to_use]\n",
    "    y = filtered_groups['Winner']\n",
    "\n",
    "    # Convert 1 to 0 and 2 to 1\n",
    "    y_encoded = y.apply(lambda x: 0 if x == 1 else 1)\n",
    "    y_encoded = y_encoded[X.index]\n",
    "\n",
    "    # Preprocess the dataset\n",
    "    numeric_features = top_features\n",
    "    # categorical_features = ['Player1_Race', 'Player2_Race']\n",
    "\n",
    "    # Assuming filtered_groups is your DataFrame from the previous step\n",
    "    unique_replay_ids = filtered_groups['ReplayID'].unique()\n",
    "\n",
    "    # Split the unique replay IDs into train and test sets\n",
    "    train_replay_ids, test_replay_ids = train_test_split(unique_replay_ids, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Use the replay IDs to separate the original filtered_groups into train and test DataFrames\n",
    "    train_X_data = X[X['ReplayID'].isin(train_replay_ids)]\n",
    "    test_X_data = X[X['ReplayID'].isin(test_replay_ids)]\n",
    "    train_y_data = y_encoded[X['ReplayID'].isin(train_replay_ids)]\n",
    "    test_y_data = y_encoded[X['ReplayID'].isin(test_replay_ids)]\n",
    "\n",
    "    # Create a column transformer for preprocessing\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numeric_features)\n",
    "            ]\n",
    "    )\n",
    "    \n",
    "    # Final Preprocessing\n",
    "\n",
    "    # Preprocess the data\n",
    "    preprocessor.fit(filtered_groups)\n",
    "    X_train_processed = preprocessor.transform(train_X_data)\n",
    "    X_test_processed = preprocessor.transform(test_X_data)\n",
    "\n",
    "    # Reshape data for LSTM input\n",
    "    feature_columns = [col for col in train_X_data.columns if col not in ['ReplayID', 'Winner']]\n",
    "    X_train_reshaped = X_train_processed.reshape(-1, 120, len(feature_columns))\n",
    "    X_test_reshaped = X_test_processed.reshape(-1, 120, len(feature_columns))\n",
    "\n",
    "    # Create a mapping from ReplayID to label\n",
    "    replay_id_to_label_map = {replay_id: label for replay_id, label in zip(X['ReplayID'], y_encoded)}\n",
    "\n",
    "    # Now, extract the labels for the training and testing ReplayIDs in the correct order\n",
    "    train_y_data = np.array([replay_id_to_label_map[replay_id] for replay_id in train_replay_ids])\n",
    "    test_y_data = np.array([replay_id_to_label_map[replay_id] for replay_id in test_replay_ids])\n",
    "    \n",
    "    # Dictionary to hold scores for the models\n",
    "    scores_dict = {'File': file}\n",
    "    \n",
    "    input_shape = (X_train_reshaped.shape[1], X_train_reshaped.shape[2])\n",
    "    # Build the models and evaluate them\n",
    "    models = {\n",
    "            \"LSTM\": build_model((X_train_reshaped.shape[1], X_train_reshaped.shape[2]))\n",
    "            }\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        if model_name == \"LSTM\":\n",
    "            # Build and train the model\n",
    "            early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "            history = model.fit(X_train_reshaped, train_y_data, epochs=100, batch_size=16, validation_split=0.1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "            # Evaluate the model\n",
    "            test_loss, test_acc = model.evaluate(X_test_reshaped, test_y_data, verbose=2)\n",
    "            # print(f'Test accuracy: {test_acc}, Test loss: {test_loss}')\n",
    "            # Evaluate the model.\n",
    "            score = test_acc\n",
    "        scores_dict[model_name] = score\n",
    "\n",
    "    print(scores_dict)\n",
    "    # Append the scores_dict as a DataFrame to df_list\n",
    "    df_list.append(pd.DataFrame([scores_dict]))\n",
    "    print(file, \" Done!\")\n",
    "\n",
    "df = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>LSTM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1D_All_ReplaysData_PvP.csv</td>\n",
       "      <td>0.602410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1D_All_ReplaysData_PvT.csv</td>\n",
       "      <td>0.628378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1D_All_ReplaysData_PvZ.csv</td>\n",
       "      <td>0.494845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1D_All_ReplaysData_TvT.csv</td>\n",
       "      <td>0.595506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1D_All_ReplaysData_TvZ.csv</td>\n",
       "      <td>0.638298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1D_All_ReplaysData_ZvZ.csv</td>\n",
       "      <td>0.441176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>StarCraft_Combined_Dataset.csv</td>\n",
       "      <td>0.598527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             File      LSTM\n",
       "0      1D_All_ReplaysData_PvP.csv  0.602410\n",
       "1      1D_All_ReplaysData_PvT.csv  0.628378\n",
       "2      1D_All_ReplaysData_PvZ.csv  0.494845\n",
       "3      1D_All_ReplaysData_TvT.csv  0.595506\n",
       "4      1D_All_ReplaysData_TvZ.csv  0.638298\n",
       "5      1D_All_ReplaysData_ZvZ.csv  0.441176\n",
       "6  StarCraft_Combined_Dataset.csv  0.598527"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>LSTM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1D_All_ReplaysData_PvP.csv</td>\n",
       "      <td>0.590361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1D_All_ReplaysData_PvT.csv</td>\n",
       "      <td>0.628378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1D_All_ReplaysData_PvZ.csv</td>\n",
       "      <td>0.536082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1D_All_ReplaysData_TvT.csv</td>\n",
       "      <td>0.595506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1D_All_ReplaysData_TvZ.csv</td>\n",
       "      <td>0.627660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1D_All_ReplaysData_ZvZ.csv</td>\n",
       "      <td>0.264706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>StarCraft_Combined_Dataset.csv</td>\n",
       "      <td>0.589319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             File      LSTM\n",
       "0      1D_All_ReplaysData_PvP.csv  0.590361\n",
       "1      1D_All_ReplaysData_PvT.csv  0.628378\n",
       "2      1D_All_ReplaysData_PvZ.csv  0.536082\n",
       "3      1D_All_ReplaysData_TvT.csv  0.595506\n",
       "4      1D_All_ReplaysData_TvZ.csv  0.627660\n",
       "5      1D_All_ReplaysData_ZvZ.csv  0.264706\n",
       "6  StarCraft_Combined_Dataset.csv  0.589319"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('LSTM_Results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouped Bar Chart for all metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['1D_All_ReplaysData_PvP.csv', '1D_All_ReplaysData_PvT.csv', '1D_All_ReplaysData_PvZ.csv', '1D_All_ReplaysData_TvT.csv', '1D_All_ReplaysData_TvZ.csv', '1D_All_ReplaysData_ZvZ.csv', \"StarCraft_Combined_Dataset.csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store DataFrames to concatenate later.\n",
    "df_list = []\n",
    "\n",
    "for file in files:\n",
    "    data = pd.read_csv('../Processed Datasets/' + file)\n",
    "    data = data[data['Winner'].isin([1, 2])]\n",
    "    data['Winner'] = data['Winner'].replace(1, 0)\n",
    "    data['Winner'] = data['Winner'].replace(2, 1)\n",
    "\n",
    "    label_encoders = {}\n",
    "    for column in ['ReplayID', 'Player1_Race', 'Player2_Race', 'MapName']:\n",
    "        label_encoders[column] = LabelEncoder()\n",
    "        data[column] = label_encoders[column].fit_transform(data[column])\n",
    "\n",
    "    for per in range(1, 11):\n",
    "        percentile_80_grouped = data.groupby('ReplayID')['Frame'].quantile(per / 10)\n",
    "        def find_nearest_row(group):\n",
    "            nearest_index = (group['Frame'] - percentile_80_grouped[group.name]).abs().idxmin()\n",
    "            return group.loc[[nearest_index]]\n",
    "        nearest_rows = data.groupby('ReplayID', group_keys=False).apply(find_nearest_row)\n",
    "        nearest_rows.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        nearest_rows[nearest_rows.columns.drop(['Winner'])] = scaler.fit_transform(nearest_rows[nearest_rows.columns.drop(['Winner'])])\n",
    "\n",
    "        X = nearest_rows.drop('Winner', axis=1)\n",
    "        y = nearest_rows['Winner']\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        models = {\n",
    "            'RandomForest': RandomForestClassifier(bootstrap=False, criterion='entropy', max_depth=12, max_features=23, min_samples_split=30, random_state=63),\n",
    "            'LogisticRegression': LogisticRegression(solver='liblinear', max_iter=1000, C=0.1, penalty='l1'),\n",
    "            'SVM': svm.LinearSVC(C=0.00001, random_state=42, dual=False, max_iter=1000),\n",
    "            'KNN': KNeighborsClassifier(n_jobs=-1, n_neighbors=17, weights='distance'),\n",
    "        }\n",
    "\n",
    "        # Dictionary to hold scores for the models\n",
    "        scores_dict = {'File': file, 'Percentile': per / 10}\n",
    "\n",
    "        for model_name, model in models.items():\n",
    "            metrics = ['accuracy', 'precision', 'recall', 'f1']\n",
    "            scores = cross_validate(model, X, y, cv=5, scoring=metrics)\n",
    "            for metric in metrics:\n",
    "                scores_dict[f'{model_name}_{metric}'] = scores['test_' + metric].mean()\n",
    "            roc = cross_validate(model, X, y, cv=5, scoring=\"roc_auc\")\n",
    "            scores_dict[f'{model_name}_roc'] = roc['test_' + 'score'].mean()\n",
    "            \n",
    "\n",
    "        # Append the scores_dict as a DataFrame to df_list\n",
    "        df_list.append(pd.DataFrame([scores_dict]))\n",
    "\n",
    "df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Pivot the DataFrame for plotting\n",
    "df_long = pd.melt(df, id_vars=['File', 'Percentile'], var_name='Model_Metric', value_name='Score')\n",
    "\n",
    "# Split the 'Model_Metric' into separate 'Model' and 'Metric' columns\n",
    "df_long[['Model', 'Metric']] = df_long['Model_Metric'].str.rsplit('_', n=1, expand=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long_copy = df_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhin\\AppData\\Local\\Temp\\ipykernel_31476\\1184288324.py:3: FutureWarning: \n",
      "\n",
      "The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.\n",
      "\n",
      "  plot = sns.barplot(x='Metric', y='Score', hue='Model', data=df_long,  ci=None)\n",
      "c:\\Users\\abhin\\anaconda3\\envs\\DevelopmentEnv\\lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "c:\\Users\\abhin\\anaconda3\\envs\\DevelopmentEnv\\lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "c:\\Users\\abhin\\anaconda3\\envs\\DevelopmentEnv\\lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "c:\\Users\\abhin\\anaconda3\\envs\\DevelopmentEnv\\lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Image size of 693971x418 pixels is too large. It must be less than 2^16 in each direction.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\abhin\\anaconda3\\envs\\DevelopmentEnv\\lib\\site-packages\\IPython\\core\\formatters.py:340\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 340\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprinter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;66;03m# Finally look for special method names\u001b[39;00m\n\u001b[0;32m    342\u001b[0m method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n",
      "File \u001b[1;32mc:\\Users\\abhin\\anaconda3\\envs\\DevelopmentEnv\\lib\\site-packages\\IPython\\core\\pylabtools.py:152\u001b[0m, in \u001b[0;36mprint_figure\u001b[1;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_bases\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FigureCanvasBase\n\u001b[0;32m    150\u001b[0m     FigureCanvasBase(fig)\n\u001b[1;32m--> 152\u001b[0m fig\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mprint_figure(bytes_io, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    153\u001b[0m data \u001b[38;5;241m=\u001b[39m bytes_io\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fmt \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msvg\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\abhin\\anaconda3\\envs\\DevelopmentEnv\\lib\\site-packages\\matplotlib\\backend_bases.py:2366\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[0;32m   2362\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   2363\u001b[0m     \u001b[38;5;66;03m# _get_renderer may change the figure dpi (as vector formats\u001b[39;00m\n\u001b[0;32m   2364\u001b[0m     \u001b[38;5;66;03m# force the figure dpi to 72), so we need to set it again here.\u001b[39;00m\n\u001b[0;32m   2365\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m cbook\u001b[38;5;241m.\u001b[39m_setattr_cm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure, dpi\u001b[38;5;241m=\u001b[39mdpi):\n\u001b[1;32m-> 2366\u001b[0m         result \u001b[38;5;241m=\u001b[39m print_method(\n\u001b[0;32m   2367\u001b[0m             filename,\n\u001b[0;32m   2368\u001b[0m             facecolor\u001b[38;5;241m=\u001b[39mfacecolor,\n\u001b[0;32m   2369\u001b[0m             edgecolor\u001b[38;5;241m=\u001b[39medgecolor,\n\u001b[0;32m   2370\u001b[0m             orientation\u001b[38;5;241m=\u001b[39morientation,\n\u001b[0;32m   2371\u001b[0m             bbox_inches_restore\u001b[38;5;241m=\u001b[39m_bbox_inches_restore,\n\u001b[0;32m   2372\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2373\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   2374\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches \u001b[38;5;129;01mand\u001b[39;00m restore_bbox:\n",
      "File \u001b[1;32mc:\\Users\\abhin\\anaconda3\\envs\\DevelopmentEnv\\lib\\site-packages\\matplotlib\\backend_bases.py:2232\u001b[0m, in \u001b[0;36mFigureCanvasBase._switch_canvas_and_return_print_method.<locals>.<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   2228\u001b[0m     optional_kws \u001b[38;5;241m=\u001b[39m {  \u001b[38;5;66;03m# Passed by print_figure for other renderers.\u001b[39;00m\n\u001b[0;32m   2229\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdpi\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medgecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morientation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2230\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbbox_inches_restore\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m   2231\u001b[0m     skip \u001b[38;5;241m=\u001b[39m optional_kws \u001b[38;5;241m-\u001b[39m {\u001b[38;5;241m*\u001b[39minspect\u001b[38;5;241m.\u001b[39msignature(meth)\u001b[38;5;241m.\u001b[39mparameters}\n\u001b[1;32m-> 2232\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mwraps(meth)(\u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: meth(\n\u001b[0;32m   2233\u001b[0m         \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m skip}))\n\u001b[0;32m   2234\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Let third-parties do as they see fit.\u001b[39;00m\n\u001b[0;32m   2235\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m meth\n",
      "File \u001b[1;32mc:\\Users\\abhin\\anaconda3\\envs\\DevelopmentEnv\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:509\u001b[0m, in \u001b[0;36mFigureCanvasAgg.print_png\u001b[1;34m(self, filename_or_obj, metadata, pil_kwargs)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprint_png\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename_or_obj, \u001b[38;5;241m*\u001b[39m, metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, pil_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    463\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \u001b[38;5;124;03m    Write the figure to a PNG file.\u001b[39;00m\n\u001b[0;32m    465\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;124;03m        *metadata*, including the default 'Software' key.\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 509\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_print_pil\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpng\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\abhin\\anaconda3\\envs\\DevelopmentEnv\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:457\u001b[0m, in \u001b[0;36mFigureCanvasAgg._print_pil\u001b[1;34m(self, filename_or_obj, fmt, pil_kwargs, metadata)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_print_pil\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename_or_obj, fmt, pil_kwargs, metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    453\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;124;03m    Draw the canvas, then save it using `.image.imsave` (to which\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;124;03m    *pil_kwargs* and *metadata* are forwarded).\u001b[39;00m\n\u001b[0;32m    456\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 457\u001b[0m     \u001b[43mFigureCanvasAgg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    458\u001b[0m     mpl\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mimsave(\n\u001b[0;32m    459\u001b[0m         filename_or_obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer_rgba(), \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39mfmt, origin\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupper\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    460\u001b[0m         dpi\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39mdpi, metadata\u001b[38;5;241m=\u001b[39mmetadata, pil_kwargs\u001b[38;5;241m=\u001b[39mpil_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\abhin\\anaconda3\\envs\\DevelopmentEnv\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:394\u001b[0m, in \u001b[0;36mFigureCanvasAgg.draw\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdraw\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    393\u001b[0m     \u001b[38;5;66;03m# docstring inherited\u001b[39;00m\n\u001b[1;32m--> 394\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrenderer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_renderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    395\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrenderer\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m    396\u001b[0m     \u001b[38;5;66;03m# Acquire a lock on the shared font cache.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\abhin\\anaconda3\\envs\\DevelopmentEnv\\lib\\site-packages\\matplotlib\\_api\\deprecation.py:384\u001b[0m, in \u001b[0;36mdelete_parameter.<locals>.wrapper\u001b[1;34m(*inner_args, **inner_kwargs)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    380\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39minner_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minner_kwargs):\n\u001b[0;32m    381\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(inner_args) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m name_idx \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m inner_kwargs:\n\u001b[0;32m    382\u001b[0m         \u001b[38;5;66;03m# Early return in the simple, non-deprecated case (much faster than\u001b[39;00m\n\u001b[0;32m    383\u001b[0m         \u001b[38;5;66;03m# calling bind()).\u001b[39;00m\n\u001b[1;32m--> 384\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39minner_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minner_kwargs)\n\u001b[0;32m    385\u001b[0m     arguments \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39minner_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minner_kwargs)\u001b[38;5;241m.\u001b[39marguments\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_varargs \u001b[38;5;129;01mand\u001b[39;00m arguments\u001b[38;5;241m.\u001b[39mget(name):\n",
      "File \u001b[1;32mc:\\Users\\abhin\\anaconda3\\envs\\DevelopmentEnv\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:411\u001b[0m, in \u001b[0;36mFigureCanvasAgg.get_renderer\u001b[1;34m(self, cleared)\u001b[0m\n\u001b[0;32m    409\u001b[0m reuse_renderer \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lastKey \u001b[38;5;241m==\u001b[39m key)\n\u001b[0;32m    410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m reuse_renderer:\n\u001b[1;32m--> 411\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrenderer \u001b[38;5;241m=\u001b[39m \u001b[43mRendererAgg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdpi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    412\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lastKey \u001b[38;5;241m=\u001b[39m key\n\u001b[0;32m    413\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m cleared:\n",
      "File \u001b[1;32mc:\\Users\\abhin\\anaconda3\\envs\\DevelopmentEnv\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:84\u001b[0m, in \u001b[0;36mRendererAgg.__init__\u001b[1;34m(self, width, height, dpi)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;241m=\u001b[39m width\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheight \u001b[38;5;241m=\u001b[39m height\n\u001b[1;32m---> 84\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_renderer \u001b[38;5;241m=\u001b[39m \u001b[43m_RendererAgg\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mheight\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdpi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filter_renderers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_methods()\n",
      "\u001b[1;31mValueError\u001b[0m: Image size of 693971x418 pixels is too large. It must be less than 2^16 in each direction."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting\n",
    "plt.figure(figsize=(15, 8))\n",
    "plot = sns.barplot(x='Metric', y='Score', hue='Model', data=df_long,  ci=None)\n",
    "# Add labels on top of each bar\n",
    "for p in plot.patches:\n",
    "    plot.annotate(format(p.get_height(), '.2f'),  # format the value\n",
    "                (p.get_x() + p.get_width() / 2., p.get_height()),  # position\n",
    "                ha='center', va='center',\n",
    "                xytext=(0, 10),  # 10 points vertical offset\n",
    "                textcoords='offset points')\n",
    "plt.title('Performance Metrics for Different Models')\n",
    "plt.xlabel('Metric')\n",
    "plt.ylabel('Score')\n",
    "plt.legend(title='Model', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "# Manually setting the x-ticks\n",
    "plot.set_xticks(range(len(['Accuracy', 'Precision', 'Recall', 'F1 Score', 'AU-ROC'])))\n",
    "plot.set_xticklabels(['Accuracy', 'Precision', 'Recall', 'F1 Score', 'AU-ROC'])\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# print values on top\n",
    "for index, row in df_long.iterrows():\n",
    "    plt.text(row.name, row.Score, round(row.Score, 2), color='black', ha=\"center\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7321 - accuracy: 0.4784 - val_loss: 0.7036 - val_accuracy: 0.4237\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.5431 - val_loss: 0.7403 - val_accuracy: 0.4068\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6848 - accuracy: 0.5345 - val_loss: 0.6899 - val_accuracy: 0.5085\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6711 - accuracy: 0.5733 - val_loss: 0.6743 - val_accuracy: 0.5932\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6575 - accuracy: 0.6250 - val_loss: 0.7454 - val_accuracy: 0.4237\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6484 - accuracy: 0.6250 - val_loss: 0.6721 - val_accuracy: 0.5932\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6325 - accuracy: 0.6638 - val_loss: 0.7000 - val_accuracy: 0.5424\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6143 - accuracy: 0.6810 - val_loss: 0.7093 - val_accuracy: 0.5254\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6002 - accuracy: 0.7241 - val_loss: 0.7089 - val_accuracy: 0.5254\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 5s 333ms/step - loss: 0.6931 - accuracy: 0.5388 - val_loss: 0.6963 - val_accuracy: 0.4068\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 2s 306ms/step - loss: 0.6916 - accuracy: 0.5388 - val_loss: 0.7050 - val_accuracy: 0.4068\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 2s 261ms/step - loss: 0.6906 - accuracy: 0.5388 - val_loss: 0.7141 - val_accuracy: 0.4068\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 2s 275ms/step - loss: 0.6898 - accuracy: 0.5388 - val_loss: 0.7125 - val_accuracy: 0.4068\n",
      "3/3 [==============================] - 1s 47ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7163 - accuracy: 0.5000 - val_loss: 0.7245 - val_accuracy: 0.4068\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6870 - accuracy: 0.5560 - val_loss: 0.7015 - val_accuracy: 0.4915\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.7003 - accuracy: 0.5259 - val_loss: 0.6906 - val_accuracy: 0.5424\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6809 - accuracy: 0.5776 - val_loss: 0.8010 - val_accuracy: 0.4068\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6693 - accuracy: 0.5819 - val_loss: 0.6901 - val_accuracy: 0.5424\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6733 - accuracy: 0.5819 - val_loss: 0.7073 - val_accuracy: 0.5763\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6530 - accuracy: 0.5560 - val_loss: 0.7271 - val_accuracy: 0.5254\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6236 - accuracy: 0.6595 - val_loss: 0.7083 - val_accuracy: 0.5932\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 5s 314ms/step - loss: 0.6928 - accuracy: 0.5216 - val_loss: 0.6978 - val_accuracy: 0.4068\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 2s 243ms/step - loss: 0.6910 - accuracy: 0.5388 - val_loss: 0.7007 - val_accuracy: 0.4068\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 2s 231ms/step - loss: 0.6905 - accuracy: 0.5388 - val_loss: 0.7055 - val_accuracy: 0.4068\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 2s 238ms/step - loss: 0.6894 - accuracy: 0.5388 - val_loss: 0.7115 - val_accuracy: 0.4068\n",
      "WARNING:tensorflow:5 out of the last 28 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002ABEBD99DC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 1s 43ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8151 - accuracy: 0.5172 - val_loss: 0.8376 - val_accuracy: 0.4068\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.7160 - accuracy: 0.5388 - val_loss: 0.7261 - val_accuracy: 0.3898\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6918 - accuracy: 0.5474 - val_loss: 0.6929 - val_accuracy: 0.5763\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6907 - accuracy: 0.5086 - val_loss: 0.7378 - val_accuracy: 0.4068\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6585 - accuracy: 0.6293 - val_loss: 0.7278 - val_accuracy: 0.4576\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6492 - accuracy: 0.6293 - val_loss: 0.7149 - val_accuracy: 0.4746\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002ABEC65E9D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 5s 292ms/step - loss: 0.6932 - accuracy: 0.5302 - val_loss: 0.7012 - val_accuracy: 0.4068\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 2s 215ms/step - loss: 0.6908 - accuracy: 0.5388 - val_loss: 0.7075 - val_accuracy: 0.4068\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 2s 211ms/step - loss: 0.6902 - accuracy: 0.5388 - val_loss: 0.7127 - val_accuracy: 0.4068\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 2s 215ms/step - loss: 0.6896 - accuracy: 0.5388 - val_loss: 0.7162 - val_accuracy: 0.4068\n",
      "3/3 [==============================] - 1s 41ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.7325 - accuracy: 0.4957 - val_loss: 0.7130 - val_accuracy: 0.4068\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6876 - accuracy: 0.5603 - val_loss: 0.7611 - val_accuracy: 0.4068\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6802 - accuracy: 0.5603 - val_loss: 0.7138 - val_accuracy: 0.3898\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6554 - accuracy: 0.5560 - val_loss: 0.7075 - val_accuracy: 0.4407\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6631 - accuracy: 0.6207 - val_loss: 0.7752 - val_accuracy: 0.4068\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6648 - accuracy: 0.6034 - val_loss: 0.7483 - val_accuracy: 0.4068\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6297 - accuracy: 0.6638 - val_loss: 0.7260 - val_accuracy: 0.5085\n",
      "3/3 [==============================] - 0s 1000us/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 4s 287ms/step - loss: 0.6940 - accuracy: 0.5000 - val_loss: 0.7011 - val_accuracy: 0.3220\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 2s 221ms/step - loss: 0.6924 - accuracy: 0.5259 - val_loss: 0.7000 - val_accuracy: 0.4068\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 2s 210ms/step - loss: 0.6906 - accuracy: 0.5388 - val_loss: 0.7039 - val_accuracy: 0.4068\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 2s 212ms/step - loss: 0.6893 - accuracy: 0.5388 - val_loss: 0.7102 - val_accuracy: 0.4068\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 2s 212ms/step - loss: 0.6902 - accuracy: 0.5388 - val_loss: 0.7130 - val_accuracy: 0.4068\n",
      "3/3 [==============================] - 1s 43ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.7913 - accuracy: 0.4526 - val_loss: 0.8272 - val_accuracy: 0.4068\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.7119 - accuracy: 0.5517 - val_loss: 0.7250 - val_accuracy: 0.4237\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6762 - accuracy: 0.5733 - val_loss: 0.7184 - val_accuracy: 0.4407\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6766 - accuracy: 0.5905 - val_loss: 0.7728 - val_accuracy: 0.3729\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6591 - accuracy: 0.5862 - val_loss: 0.7146 - val_accuracy: 0.4746\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6446 - accuracy: 0.6207 - val_loss: 0.7012 - val_accuracy: 0.5424\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6172 - accuracy: 0.6681 - val_loss: 0.7717 - val_accuracy: 0.4068\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6134 - accuracy: 0.6897 - val_loss: 0.7559 - val_accuracy: 0.4746\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5946 - accuracy: 0.7284 - val_loss: 0.7444 - val_accuracy: 0.4915\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 5s 302ms/step - loss: 0.6925 - accuracy: 0.5603 - val_loss: 0.6976 - val_accuracy: 0.4068\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 2s 228ms/step - loss: 0.6926 - accuracy: 0.5388 - val_loss: 0.7016 - val_accuracy: 0.4068\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 2s 233ms/step - loss: 0.6915 - accuracy: 0.5431 - val_loss: 0.7105 - val_accuracy: 0.4068\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 2s 230ms/step - loss: 0.6887 - accuracy: 0.5388 - val_loss: 0.7086 - val_accuracy: 0.4068\n",
      "3/3 [==============================] - 1s 44ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7312 - accuracy: 0.5129 - val_loss: 0.8412 - val_accuracy: 0.4068\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.7290 - accuracy: 0.5172 - val_loss: 0.7034 - val_accuracy: 0.4576\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6633 - accuracy: 0.5991 - val_loss: 0.7094 - val_accuracy: 0.5085\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6610 - accuracy: 0.5862 - val_loss: 0.7559 - val_accuracy: 0.4237\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6631 - accuracy: 0.5776 - val_loss: 0.7073 - val_accuracy: 0.4915\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 5s 306ms/step - loss: 0.6936 - accuracy: 0.4828 - val_loss: 0.6968 - val_accuracy: 0.3898\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 2s 234ms/step - loss: 0.6905 - accuracy: 0.5474 - val_loss: 0.7068 - val_accuracy: 0.4068\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 2s 240ms/step - loss: 0.6906 - accuracy: 0.5431 - val_loss: 0.7137 - val_accuracy: 0.4068\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 2s 229ms/step - loss: 0.6917 - accuracy: 0.5388 - val_loss: 0.7120 - val_accuracy: 0.4068\n",
      "3/3 [==============================] - 1s 46ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8715 - accuracy: 0.4353 - val_loss: 0.8305 - val_accuracy: 0.4068\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.7226 - accuracy: 0.5388 - val_loss: 0.7724 - val_accuracy: 0.4068\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6761 - accuracy: 0.5302 - val_loss: 0.6906 - val_accuracy: 0.5593\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6729 - accuracy: 0.5776 - val_loss: 0.7451 - val_accuracy: 0.4407\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6399 - accuracy: 0.6293 - val_loss: 0.7530 - val_accuracy: 0.4068\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6268 - accuracy: 0.6422 - val_loss: 0.7102 - val_accuracy: 0.5254\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 5s 327ms/step - loss: 0.6952 - accuracy: 0.4871 - val_loss: 0.6924 - val_accuracy: 0.4915\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 2s 279ms/step - loss: 0.6927 - accuracy: 0.5129 - val_loss: 0.7063 - val_accuracy: 0.4068\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 2s 242ms/step - loss: 0.6910 - accuracy: 0.5345 - val_loss: 0.7121 - val_accuracy: 0.4068\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 2s 239ms/step - loss: 0.6902 - accuracy: 0.5388 - val_loss: 0.7158 - val_accuracy: 0.4068\n",
      "3/3 [==============================] - 1s 51ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6910 - accuracy: 0.5776 - val_loss: 0.7208 - val_accuracy: 0.4068\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6507 - accuracy: 0.6336 - val_loss: 0.7939 - val_accuracy: 0.4068\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6436 - accuracy: 0.5862 - val_loss: 0.7734 - val_accuracy: 0.4068\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6304 - accuracy: 0.6379 - val_loss: 0.7063 - val_accuracy: 0.5932\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5854 - accuracy: 0.7026 - val_loss: 0.7881 - val_accuracy: 0.4407\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5448 - accuracy: 0.7026 - val_loss: 0.7571 - val_accuracy: 0.5763\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5013 - accuracy: 0.8190 - val_loss: 0.7461 - val_accuracy: 0.6780\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 5s 308ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.7087 - val_accuracy: 0.3559\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 2s 237ms/step - loss: 0.6910 - accuracy: 0.5216 - val_loss: 0.7190 - val_accuracy: 0.3729\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 2s 236ms/step - loss: 0.6885 - accuracy: 0.5560 - val_loss: 0.7369 - val_accuracy: 0.3390\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 2s 238ms/step - loss: 0.6905 - accuracy: 0.5862 - val_loss: 0.7423 - val_accuracy: 0.3559\n",
      "3/3 [==============================] - 1s 46ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7056 - accuracy: 0.5388 - val_loss: 0.6691 - val_accuracy: 0.6271\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6450 - accuracy: 0.6250 - val_loss: 0.7151 - val_accuracy: 0.4746\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6380 - accuracy: 0.6034 - val_loss: 0.7319 - val_accuracy: 0.5424\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5828 - accuracy: 0.7328 - val_loss: 0.6613 - val_accuracy: 0.6441\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5277 - accuracy: 0.7974 - val_loss: 0.6575 - val_accuracy: 0.7288\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.4917 - accuracy: 0.7802 - val_loss: 0.6424 - val_accuracy: 0.7627\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4285 - accuracy: 0.8491 - val_loss: 0.6118 - val_accuracy: 0.7797\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4013 - accuracy: 0.8621 - val_loss: 0.6250 - val_accuracy: 0.7797\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3479 - accuracy: 0.9009 - val_loss: 0.6258 - val_accuracy: 0.8136\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2941 - accuracy: 0.9181 - val_loss: 0.6033 - val_accuracy: 0.7966\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2754 - accuracy: 0.9267 - val_loss: 0.6433 - val_accuracy: 0.8136\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.2728 - accuracy: 0.9052 - val_loss: 0.6440 - val_accuracy: 0.7797\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2509 - accuracy: 0.9138 - val_loss: 0.6369 - val_accuracy: 0.7627\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 5s 306ms/step - loss: 0.6943 - accuracy: 0.4828 - val_loss: 0.7010 - val_accuracy: 0.3898\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 2s 232ms/step - loss: 0.6894 - accuracy: 0.5733 - val_loss: 0.7158 - val_accuracy: 0.4068\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 2s 237ms/step - loss: 0.6887 - accuracy: 0.5560 - val_loss: 0.7357 - val_accuracy: 0.3898\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 2s 233ms/step - loss: 0.6873 - accuracy: 0.5603 - val_loss: 0.7583 - val_accuracy: 0.3559\n",
      "3/3 [==============================] - 1s 62ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.7090 - accuracy: 0.5000 - val_loss: 0.7311 - val_accuracy: 0.4068\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6679 - accuracy: 0.6034 - val_loss: 0.6481 - val_accuracy: 0.7288\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5958 - accuracy: 0.7241 - val_loss: 0.6141 - val_accuracy: 0.7288\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5358 - accuracy: 0.7888 - val_loss: 0.5974 - val_accuracy: 0.7797\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4548 - accuracy: 0.8578 - val_loss: 0.5418 - val_accuracy: 0.7966\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3806 - accuracy: 0.8966 - val_loss: 0.5112 - val_accuracy: 0.8136\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3374 - accuracy: 0.8966 - val_loss: 0.4858 - val_accuracy: 0.8136\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.2830 - accuracy: 0.9310 - val_loss: 0.4522 - val_accuracy: 0.8475\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2520 - accuracy: 0.9310 - val_loss: 0.4430 - val_accuracy: 0.8305\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.2171 - accuracy: 0.9353 - val_loss: 0.4410 - val_accuracy: 0.8475\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1932 - accuracy: 0.9397 - val_loss: 0.4318 - val_accuracy: 0.8305\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1723 - accuracy: 0.9526 - val_loss: 0.4405 - val_accuracy: 0.8305\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1718 - accuracy: 0.9353 - val_loss: 0.4607 - val_accuracy: 0.8305\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1620 - accuracy: 0.9440 - val_loss: 0.4571 - val_accuracy: 0.8475\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 5s 304ms/step - loss: 0.6940 - accuracy: 0.4612 - val_loss: 0.7269 - val_accuracy: 0.4068\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 2s 236ms/step - loss: 0.6855 - accuracy: 0.5474 - val_loss: 0.7552 - val_accuracy: 0.3729\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 2s 234ms/step - loss: 0.6861 - accuracy: 0.5647 - val_loss: 0.7893 - val_accuracy: 0.3220\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 2s 234ms/step - loss: 0.6821 - accuracy: 0.5431 - val_loss: 0.7791 - val_accuracy: 0.3220\n",
      "3/3 [==============================] - 1s 45ms/step\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.7102 - accuracy: 0.5242 - val_loss: 0.7067 - val_accuracy: 0.4787\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.7072 - accuracy: 0.5484 - val_loss: 0.6641 - val_accuracy: 0.6277\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.6879 - accuracy: 0.5565 - val_loss: 0.6540 - val_accuracy: 0.6702\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.6608 - accuracy: 0.6210 - val_loss: 0.6460 - val_accuracy: 0.6915\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.6580 - accuracy: 0.5806 - val_loss: 0.6352 - val_accuracy: 0.6809\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.6373 - accuracy: 0.6774 - val_loss: 0.6173 - val_accuracy: 0.7553\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.6139 - accuracy: 0.6667 - val_loss: 0.6023 - val_accuracy: 0.7553\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5939 - accuracy: 0.6935 - val_loss: 0.6080 - val_accuracy: 0.7234\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5637 - accuracy: 0.7419 - val_loss: 0.5799 - val_accuracy: 0.7766\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5507 - accuracy: 0.7339 - val_loss: 0.5655 - val_accuracy: 0.7766\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5505 - accuracy: 0.6882 - val_loss: 0.5563 - val_accuracy: 0.7766\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5323 - accuracy: 0.7366 - val_loss: 0.5668 - val_accuracy: 0.7766\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5299 - accuracy: 0.7312 - val_loss: 0.5810 - val_accuracy: 0.7553\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5120 - accuracy: 0.7581 - val_loss: 0.5670 - val_accuracy: 0.7447\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 9s 501ms/step - loss: 0.6935 - accuracy: 0.4758 - val_loss: 0.6931 - val_accuracy: 0.5213\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 5s 444ms/step - loss: 0.6937 - accuracy: 0.4812 - val_loss: 0.6939 - val_accuracy: 0.4787\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 6s 512ms/step - loss: 0.6933 - accuracy: 0.5054 - val_loss: 0.6938 - val_accuracy: 0.4787\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 6s 490ms/step - loss: 0.6934 - accuracy: 0.4973 - val_loss: 0.6934 - val_accuracy: 0.4787\n",
      "4/4 [==============================] - 1s 110ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhin\\anaconda3\\envs\\DevelopmentEnv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.7667 - accuracy: 0.4570 - val_loss: 0.6811 - val_accuracy: 0.6596\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.6973 - accuracy: 0.5618 - val_loss: 0.6782 - val_accuracy: 0.5106\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.6654 - accuracy: 0.6048 - val_loss: 0.6595 - val_accuracy: 0.6702\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.6761 - accuracy: 0.6022 - val_loss: 0.6486 - val_accuracy: 0.6702\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.6221 - accuracy: 0.6694 - val_loss: 0.6439 - val_accuracy: 0.7021\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.6201 - accuracy: 0.6909 - val_loss: 0.6323 - val_accuracy: 0.7128\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5795 - accuracy: 0.7258 - val_loss: 0.6300 - val_accuracy: 0.6915\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5563 - accuracy: 0.7366 - val_loss: 0.6169 - val_accuracy: 0.7128\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5338 - accuracy: 0.7581 - val_loss: 0.6182 - val_accuracy: 0.6702\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5108 - accuracy: 0.7500 - val_loss: 0.6154 - val_accuracy: 0.6702\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.4920 - accuracy: 0.7903 - val_loss: 0.6143 - val_accuracy: 0.6702\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.4925 - accuracy: 0.7742 - val_loss: 0.6322 - val_accuracy: 0.6809\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.4523 - accuracy: 0.7984 - val_loss: 0.6240 - val_accuracy: 0.6489\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.4388 - accuracy: 0.8091 - val_loss: 0.6360 - val_accuracy: 0.6277\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 9s 581ms/step - loss: 0.6937 - accuracy: 0.4651 - val_loss: 0.6933 - val_accuracy: 0.4787\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 6s 481ms/step - loss: 0.6932 - accuracy: 0.5108 - val_loss: 0.6933 - val_accuracy: 0.4787\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 6s 526ms/step - loss: 0.6926 - accuracy: 0.5188 - val_loss: 0.6928 - val_accuracy: 0.5638\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 5s 435ms/step - loss: 0.6928 - accuracy: 0.4785 - val_loss: 0.6927 - val_accuracy: 0.5638\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 5s 440ms/step - loss: 0.6927 - accuracy: 0.5108 - val_loss: 0.6931 - val_accuracy: 0.4787\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 6s 491ms/step - loss: 0.6915 - accuracy: 0.5134 - val_loss: 0.6932 - val_accuracy: 0.4787\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 6s 545ms/step - loss: 0.6916 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.4787\n",
      "4/4 [==============================] - 1s 213ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhin\\anaconda3\\envs\\DevelopmentEnv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.7342 - accuracy: 0.5161 - val_loss: 0.7075 - val_accuracy: 0.5213\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.7059 - accuracy: 0.5215 - val_loss: 0.6952 - val_accuracy: 0.4787\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6643 - accuracy: 0.5887 - val_loss: 0.6630 - val_accuracy: 0.6064\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.6553 - accuracy: 0.5806 - val_loss: 0.6690 - val_accuracy: 0.5638\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.6195 - accuracy: 0.6640 - val_loss: 0.6448 - val_accuracy: 0.6170\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.6159 - accuracy: 0.6801 - val_loss: 0.6412 - val_accuracy: 0.6915\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5790 - accuracy: 0.6989 - val_loss: 0.6296 - val_accuracy: 0.6809\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5548 - accuracy: 0.7527 - val_loss: 0.6158 - val_accuracy: 0.6596\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5220 - accuracy: 0.7366 - val_loss: 0.6131 - val_accuracy: 0.6809\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5097 - accuracy: 0.7581 - val_loss: 0.5930 - val_accuracy: 0.7128\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.4746 - accuracy: 0.7742 - val_loss: 0.6146 - val_accuracy: 0.6489\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.4752 - accuracy: 0.7849 - val_loss: 0.5980 - val_accuracy: 0.6915\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.4532 - accuracy: 0.8038 - val_loss: 0.5990 - val_accuracy: 0.6596\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 10s 702ms/step - loss: 0.6934 - accuracy: 0.4919 - val_loss: 0.6938 - val_accuracy: 0.4681\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 9s 784ms/step - loss: 0.6925 - accuracy: 0.5054 - val_loss: 0.6934 - val_accuracy: 0.4574\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 7s 543ms/step - loss: 0.6926 - accuracy: 0.5161 - val_loss: 0.6935 - val_accuracy: 0.4681\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 6s 493ms/step - loss: 0.6925 - accuracy: 0.5161 - val_loss: 0.6928 - val_accuracy: 0.4787\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 6s 478ms/step - loss: 0.6929 - accuracy: 0.4973 - val_loss: 0.6919 - val_accuracy: 0.6064\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 6s 475ms/step - loss: 0.6914 - accuracy: 0.5296 - val_loss: 0.6920 - val_accuracy: 0.6064\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 6s 474ms/step - loss: 0.6914 - accuracy: 0.5269 - val_loss: 0.6910 - val_accuracy: 0.6064\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 6s 474ms/step - loss: 0.6916 - accuracy: 0.5269 - val_loss: 0.6905 - val_accuracy: 0.5957\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 6s 479ms/step - loss: 0.6912 - accuracy: 0.5323 - val_loss: 0.6885 - val_accuracy: 0.5957\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 6s 477ms/step - loss: 0.6900 - accuracy: 0.5403 - val_loss: 0.6862 - val_accuracy: 0.5957\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 6s 518ms/step - loss: 0.6902 - accuracy: 0.5376 - val_loss: 0.6874 - val_accuracy: 0.6064\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 6s 542ms/step - loss: 0.6891 - accuracy: 0.5403 - val_loss: 0.6820 - val_accuracy: 0.6170\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 6s 476ms/step - loss: 0.6846 - accuracy: 0.5511 - val_loss: 0.6877 - val_accuracy: 0.6064\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 6s 472ms/step - loss: 0.6874 - accuracy: 0.5538 - val_loss: 0.6867 - val_accuracy: 0.6383\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 6s 471ms/step - loss: 0.6825 - accuracy: 0.5457 - val_loss: 0.7003 - val_accuracy: 0.6170\n",
      "4/4 [==============================] - 2s 114ms/step\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.7114 - accuracy: 0.5081 - val_loss: 0.6829 - val_accuracy: 0.5426\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.6897 - accuracy: 0.5484 - val_loss: 0.6672 - val_accuracy: 0.6489\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.6839 - accuracy: 0.5833 - val_loss: 0.6698 - val_accuracy: 0.6489\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.6541 - accuracy: 0.6022 - val_loss: 0.6751 - val_accuracy: 0.5426\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.6270 - accuracy: 0.6559 - val_loss: 0.6764 - val_accuracy: 0.6064\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 8s 513ms/step - loss: 0.6938 - accuracy: 0.4758 - val_loss: 0.6972 - val_accuracy: 0.4787\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 7s 587ms/step - loss: 0.6933 - accuracy: 0.4866 - val_loss: 0.6942 - val_accuracy: 0.5000\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 6s 521ms/step - loss: 0.6929 - accuracy: 0.5215 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 7s 548ms/step - loss: 0.6926 - accuracy: 0.4892 - val_loss: 0.6928 - val_accuracy: 0.5851\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 6s 505ms/step - loss: 0.6923 - accuracy: 0.5296 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 6s 503ms/step - loss: 0.6929 - accuracy: 0.5161 - val_loss: 0.6920 - val_accuracy: 0.5638\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 6s 494ms/step - loss: 0.6913 - accuracy: 0.5161 - val_loss: 0.6918 - val_accuracy: 0.5000\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 6s 496ms/step - loss: 0.6910 - accuracy: 0.5349 - val_loss: 0.6879 - val_accuracy: 0.5851\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 6s 494ms/step - loss: 0.6912 - accuracy: 0.5161 - val_loss: 0.6881 - val_accuracy: 0.5638\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 6s 483ms/step - loss: 0.6904 - accuracy: 0.5188 - val_loss: 0.6854 - val_accuracy: 0.5638\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 6s 485ms/step - loss: 0.6894 - accuracy: 0.5403 - val_loss: 0.6846 - val_accuracy: 0.5638\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 6s 491ms/step - loss: 0.6889 - accuracy: 0.5054 - val_loss: 0.6818 - val_accuracy: 0.5638\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 6s 480ms/step - loss: 0.6881 - accuracy: 0.5081 - val_loss: 0.6826 - val_accuracy: 0.6277\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 6s 521ms/step - loss: 0.6844 - accuracy: 0.5188 - val_loss: 0.6857 - val_accuracy: 0.5638\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 6s 491ms/step - loss: 0.6964 - accuracy: 0.4973 - val_loss: 0.7241 - val_accuracy: 0.5000\n",
      "4/4 [==============================] - 1s 135ms/step\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.7294 - accuracy: 0.5054 - val_loss: 0.6953 - val_accuracy: 0.5213\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.7074 - accuracy: 0.5296 - val_loss: 0.6922 - val_accuracy: 0.4681\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.6716 - accuracy: 0.6075 - val_loss: 0.6724 - val_accuracy: 0.5638\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.6410 - accuracy: 0.6290 - val_loss: 0.6784 - val_accuracy: 0.6489\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6000 - accuracy: 0.7043 - val_loss: 0.6554 - val_accuracy: 0.6277\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.5690 - accuracy: 0.7285 - val_loss: 0.6664 - val_accuracy: 0.6064\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5510 - accuracy: 0.7366 - val_loss: 0.6534 - val_accuracy: 0.6064\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5024 - accuracy: 0.7930 - val_loss: 0.6468 - val_accuracy: 0.6383\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.4870 - accuracy: 0.7903 - val_loss: 0.6597 - val_accuracy: 0.6277\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.4498 - accuracy: 0.8387 - val_loss: 0.6538 - val_accuracy: 0.6277\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.4254 - accuracy: 0.8280 - val_loss: 0.6648 - val_accuracy: 0.6277\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 10s 576ms/step - loss: 0.6936 - accuracy: 0.4973 - val_loss: 0.6924 - val_accuracy: 0.4574\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 6s 492ms/step - loss: 0.6923 - accuracy: 0.5134 - val_loss: 0.6937 - val_accuracy: 0.3298\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 6s 488ms/step - loss: 0.6918 - accuracy: 0.5269 - val_loss: 0.6942 - val_accuracy: 0.3511\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 6s 503ms/step - loss: 0.6916 - accuracy: 0.5457 - val_loss: 0.6946 - val_accuracy: 0.5319\n",
      "4/4 [==============================] - 1s 118ms/step\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.7194 - accuracy: 0.5403 - val_loss: 0.6906 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.7007 - accuracy: 0.5296 - val_loss: 0.6653 - val_accuracy: 0.6170\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.6668 - accuracy: 0.5995 - val_loss: 0.6705 - val_accuracy: 0.6702\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.6243 - accuracy: 0.6640 - val_loss: 0.6710 - val_accuracy: 0.5745\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.6034 - accuracy: 0.6909 - val_loss: 0.6627 - val_accuracy: 0.6383\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5659 - accuracy: 0.7608 - val_loss: 0.6589 - val_accuracy: 0.6702\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5335 - accuracy: 0.7688 - val_loss: 0.6792 - val_accuracy: 0.6809\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5039 - accuracy: 0.7661 - val_loss: 0.6817 - val_accuracy: 0.6809\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.4680 - accuracy: 0.8065 - val_loss: 0.6985 - val_accuracy: 0.6383\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 10s 590ms/step - loss: 0.6946 - accuracy: 0.4812 - val_loss: 0.6918 - val_accuracy: 0.6170\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 7s 607ms/step - loss: 0.6921 - accuracy: 0.5430 - val_loss: 0.6915 - val_accuracy: 0.5851\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 7s 579ms/step - loss: 0.6923 - accuracy: 0.5296 - val_loss: 0.6911 - val_accuracy: 0.6064\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 7s 580ms/step - loss: 0.6916 - accuracy: 0.5403 - val_loss: 0.6906 - val_accuracy: 0.6170\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 7s 546ms/step - loss: 0.6918 - accuracy: 0.5403 - val_loss: 0.6900 - val_accuracy: 0.5851\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 7s 567ms/step - loss: 0.6914 - accuracy: 0.5484 - val_loss: 0.6893 - val_accuracy: 0.5745\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 6s 505ms/step - loss: 0.6900 - accuracy: 0.5430 - val_loss: 0.6890 - val_accuracy: 0.5745\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 6s 523ms/step - loss: 0.6913 - accuracy: 0.5323 - val_loss: 0.6858 - val_accuracy: 0.5532\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 6s 493ms/step - loss: 0.6903 - accuracy: 0.5349 - val_loss: 0.6905 - val_accuracy: 0.5319\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 6s 504ms/step - loss: 0.6900 - accuracy: 0.5027 - val_loss: 0.6924 - val_accuracy: 0.5532\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 6s 504ms/step - loss: 0.6905 - accuracy: 0.5457 - val_loss: 0.6878 - val_accuracy: 0.5532\n",
      "4/4 [==============================] - 1s 111ms/step\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.7328 - accuracy: 0.5000 - val_loss: 0.6857 - val_accuracy: 0.5319\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.6903 - accuracy: 0.5430 - val_loss: 0.6827 - val_accuracy: 0.4787\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.6579 - accuracy: 0.6129 - val_loss: 0.6541 - val_accuracy: 0.6702\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.6226 - accuracy: 0.6935 - val_loss: 0.6505 - val_accuracy: 0.7340\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5915 - accuracy: 0.7231 - val_loss: 0.6313 - val_accuracy: 0.7447\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5364 - accuracy: 0.7715 - val_loss: 0.6217 - val_accuracy: 0.7021\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5160 - accuracy: 0.7796 - val_loss: 0.6249 - val_accuracy: 0.7340\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.4748 - accuracy: 0.8199 - val_loss: 0.6177 - val_accuracy: 0.7128\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.4325 - accuracy: 0.8468 - val_loss: 0.6164 - val_accuracy: 0.7340\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.4078 - accuracy: 0.8333 - val_loss: 0.6313 - val_accuracy: 0.7447\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.4169 - accuracy: 0.8468 - val_loss: 0.6354 - val_accuracy: 0.7660\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.3703 - accuracy: 0.8575 - val_loss: 0.6203 - val_accuracy: 0.7872\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 9s 608ms/step - loss: 0.6933 - accuracy: 0.5215 - val_loss: 0.6914 - val_accuracy: 0.5745\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 7s 537ms/step - loss: 0.6915 - accuracy: 0.5269 - val_loss: 0.6914 - val_accuracy: 0.5638\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 6s 521ms/step - loss: 0.6891 - accuracy: 0.5215 - val_loss: 0.6934 - val_accuracy: 0.5426\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 6s 529ms/step - loss: 0.6898 - accuracy: 0.5269 - val_loss: 0.6932 - val_accuracy: 0.5745\n",
      "4/4 [==============================] - 2s 116ms/step\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.7102 - accuracy: 0.5269 - val_loss: 0.6834 - val_accuracy: 0.5106\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.6786 - accuracy: 0.5780 - val_loss: 0.6567 - val_accuracy: 0.5957\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.6274 - accuracy: 0.6452 - val_loss: 0.6232 - val_accuracy: 0.7234\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5873 - accuracy: 0.7258 - val_loss: 0.5945 - val_accuracy: 0.7553\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5271 - accuracy: 0.7876 - val_loss: 0.5699 - val_accuracy: 0.7979\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.4793 - accuracy: 0.8226 - val_loss: 0.5471 - val_accuracy: 0.8191\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.4407 - accuracy: 0.8441 - val_loss: 0.5577 - val_accuracy: 0.7872\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.4028 - accuracy: 0.8441 - val_loss: 0.5259 - val_accuracy: 0.8085\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.3729 - accuracy: 0.8710 - val_loss: 0.5304 - val_accuracy: 0.8191\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.3613 - accuracy: 0.8844 - val_loss: 0.5386 - val_accuracy: 0.7979\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.3270 - accuracy: 0.8817 - val_loss: 0.5352 - val_accuracy: 0.8404\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 9s 548ms/step - loss: 0.6932 - accuracy: 0.4785 - val_loss: 0.6938 - val_accuracy: 0.4787\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 6s 499ms/step - loss: 0.6927 - accuracy: 0.4919 - val_loss: 0.6940 - val_accuracy: 0.4681\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 6s 499ms/step - loss: 0.6922 - accuracy: 0.4892 - val_loss: 0.6937 - val_accuracy: 0.4043\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 6s 513ms/step - loss: 0.6922 - accuracy: 0.4892 - val_loss: 0.6895 - val_accuracy: 0.5957\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 6s 506ms/step - loss: 0.6916 - accuracy: 0.5000 - val_loss: 0.6908 - val_accuracy: 0.4787\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 7s 577ms/step - loss: 0.6882 - accuracy: 0.5672 - val_loss: 0.6903 - val_accuracy: 0.5319\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 7s 542ms/step - loss: 0.6879 - accuracy: 0.5403 - val_loss: 0.6893 - val_accuracy: 0.5426\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 6s 517ms/step - loss: 0.6873 - accuracy: 0.5511 - val_loss: 0.6825 - val_accuracy: 0.6170\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 6s 495ms/step - loss: 0.6852 - accuracy: 0.5672 - val_loss: 0.6822 - val_accuracy: 0.5851\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 6s 491ms/step - loss: 0.6845 - accuracy: 0.5484 - val_loss: 0.6821 - val_accuracy: 0.6064\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 6s 489ms/step - loss: 0.6844 - accuracy: 0.5511 - val_loss: 0.6785 - val_accuracy: 0.6489\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 6s 490ms/step - loss: 0.6792 - accuracy: 0.5672 - val_loss: 0.6699 - val_accuracy: 0.6277\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 6s 490ms/step - loss: 0.6750 - accuracy: 0.5806 - val_loss: 0.6726 - val_accuracy: 0.6383\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 6s 493ms/step - loss: 0.6753 - accuracy: 0.5780 - val_loss: 0.6709 - val_accuracy: 0.6489\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 6s 492ms/step - loss: 0.6734 - accuracy: 0.5995 - val_loss: 0.6665 - val_accuracy: 0.6064\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 6s 490ms/step - loss: 0.6761 - accuracy: 0.5833 - val_loss: 0.6813 - val_accuracy: 0.5957\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 6s 493ms/step - loss: 0.6675 - accuracy: 0.6156 - val_loss: 0.6615 - val_accuracy: 0.6596\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 6s 541ms/step - loss: 0.6625 - accuracy: 0.6075 - val_loss: 0.6581 - val_accuracy: 0.6064\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 6s 505ms/step - loss: 0.6610 - accuracy: 0.6156 - val_loss: 0.6680 - val_accuracy: 0.6277\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 6s 490ms/step - loss: 0.6586 - accuracy: 0.6263 - val_loss: 0.6554 - val_accuracy: 0.6596\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 6s 498ms/step - loss: 0.6609 - accuracy: 0.5941 - val_loss: 0.6968 - val_accuracy: 0.5638\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 6s 494ms/step - loss: 0.6837 - accuracy: 0.5591 - val_loss: 0.6778 - val_accuracy: 0.5745\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 6s 493ms/step - loss: 0.6700 - accuracy: 0.6022 - val_loss: 0.6722 - val_accuracy: 0.5957\n",
      "4/4 [==============================] - 1s 143ms/step\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 1s 66ms/step - loss: 0.7100 - accuracy: 0.5296 - val_loss: 0.6534 - val_accuracy: 0.6596\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.6385 - accuracy: 0.6478 - val_loss: 0.6214 - val_accuracy: 0.7234\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5859 - accuracy: 0.6828 - val_loss: 0.5584 - val_accuracy: 0.8404\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5155 - accuracy: 0.7957 - val_loss: 0.5142 - val_accuracy: 0.8617\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.4473 - accuracy: 0.8548 - val_loss: 0.4714 - val_accuracy: 0.8511\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.3970 - accuracy: 0.8548 - val_loss: 0.4358 - val_accuracy: 0.8617\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.3458 - accuracy: 0.8952 - val_loss: 0.4231 - val_accuracy: 0.8404\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.3279 - accuracy: 0.9113 - val_loss: 0.4033 - val_accuracy: 0.8617\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.3077 - accuracy: 0.9059 - val_loss: 0.4188 - val_accuracy: 0.8511\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.2970 - accuracy: 0.9167 - val_loss: 0.3989 - val_accuracy: 0.8404\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.2767 - accuracy: 0.9301 - val_loss: 0.4058 - val_accuracy: 0.8617\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.2621 - accuracy: 0.9220 - val_loss: 0.4115 - val_accuracy: 0.8298\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.2486 - accuracy: 0.9274 - val_loss: 0.4153 - val_accuracy: 0.8298\n",
      "4/4 [==============================] - 0s 0s/step\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 8s 525ms/step - loss: 0.6937 - accuracy: 0.5054 - val_loss: 0.6895 - val_accuracy: 0.6170\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 6s 517ms/step - loss: 0.6929 - accuracy: 0.5161 - val_loss: 0.6879 - val_accuracy: 0.6383\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 6s 481ms/step - loss: 0.6932 - accuracy: 0.5376 - val_loss: 0.6867 - val_accuracy: 0.6170\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 6s 465ms/step - loss: 0.6907 - accuracy: 0.5134 - val_loss: 0.6877 - val_accuracy: 0.5532\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 6s 469ms/step - loss: 0.6920 - accuracy: 0.5323 - val_loss: 0.6897 - val_accuracy: 0.5213\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 6s 486ms/step - loss: 0.6900 - accuracy: 0.5323 - val_loss: 0.6819 - val_accuracy: 0.6489\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 6s 473ms/step - loss: 0.6892 - accuracy: 0.5296 - val_loss: 0.6866 - val_accuracy: 0.5532\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 6s 486ms/step - loss: 0.6898 - accuracy: 0.5457 - val_loss: 0.6814 - val_accuracy: 0.6277\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 6s 477ms/step - loss: 0.6892 - accuracy: 0.5376 - val_loss: 0.6818 - val_accuracy: 0.6064\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 6s 468ms/step - loss: 0.6893 - accuracy: 0.5081 - val_loss: 0.6773 - val_accuracy: 0.5532\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 6s 464ms/step - loss: 0.6877 - accuracy: 0.5188 - val_loss: 0.6850 - val_accuracy: 0.5851\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 6s 470ms/step - loss: 0.6853 - accuracy: 0.5376 - val_loss: 0.6783 - val_accuracy: 0.6383\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 6s 470ms/step - loss: 0.6851 - accuracy: 0.5565 - val_loss: 0.6676 - val_accuracy: 0.6170\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 6s 472ms/step - loss: 0.6790 - accuracy: 0.5726 - val_loss: 0.6682 - val_accuracy: 0.6064\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 6s 473ms/step - loss: 0.6784 - accuracy: 0.5645 - val_loss: 0.6667 - val_accuracy: 0.6064\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 6s 460ms/step - loss: 0.6792 - accuracy: 0.5672 - val_loss: 0.6566 - val_accuracy: 0.6064\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 6s 472ms/step - loss: 0.6789 - accuracy: 0.5699 - val_loss: 0.6795 - val_accuracy: 0.6170\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 6s 493ms/step - loss: 0.6776 - accuracy: 0.5780 - val_loss: 0.6576 - val_accuracy: 0.6170\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 6s 463ms/step - loss: 0.6718 - accuracy: 0.6022 - val_loss: 0.6591 - val_accuracy: 0.6170\n",
      "4/4 [==============================] - 1s 108ms/step\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.6930 - accuracy: 0.5618 - val_loss: 0.6099 - val_accuracy: 0.7872\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5979 - accuracy: 0.7204 - val_loss: 0.5326 - val_accuracy: 0.9255\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.4741 - accuracy: 0.8898 - val_loss: 0.4367 - val_accuracy: 0.9149\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.3793 - accuracy: 0.9113 - val_loss: 0.3469 - val_accuracy: 0.9149\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.2989 - accuracy: 0.9301 - val_loss: 0.3069 - val_accuracy: 0.9255\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.2589 - accuracy: 0.9382 - val_loss: 0.2691 - val_accuracy: 0.9255\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2302 - accuracy: 0.9570 - val_loss: 0.2559 - val_accuracy: 0.9043\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.2166 - accuracy: 0.9435 - val_loss: 0.2457 - val_accuracy: 0.9043\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.2041 - accuracy: 0.9409 - val_loss: 0.2436 - val_accuracy: 0.9149\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1957 - accuracy: 0.9516 - val_loss: 0.2367 - val_accuracy: 0.9043\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1752 - accuracy: 0.9597 - val_loss: 0.2336 - val_accuracy: 0.9149\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1527 - accuracy: 0.9677 - val_loss: 0.2323 - val_accuracy: 0.9043\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1601 - accuracy: 0.9543 - val_loss: 0.2364 - val_accuracy: 0.9043\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1539 - accuracy: 0.9597 - val_loss: 0.2437 - val_accuracy: 0.9043\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1561 - accuracy: 0.9570 - val_loss: 0.2377 - val_accuracy: 0.8936\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 9s 508ms/step - loss: 0.6946 - accuracy: 0.4892 - val_loss: 0.6907 - val_accuracy: 0.5851\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 5s 457ms/step - loss: 0.6928 - accuracy: 0.5027 - val_loss: 0.6902 - val_accuracy: 0.5532\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 6s 473ms/step - loss: 0.6927 - accuracy: 0.5054 - val_loss: 0.6905 - val_accuracy: 0.5532\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 6s 459ms/step - loss: 0.6912 - accuracy: 0.5349 - val_loss: 0.6890 - val_accuracy: 0.6064\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 6s 463ms/step - loss: 0.6923 - accuracy: 0.4812 - val_loss: 0.6882 - val_accuracy: 0.6277\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 5s 453ms/step - loss: 0.6913 - accuracy: 0.5296 - val_loss: 0.6871 - val_accuracy: 0.6064\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 5s 458ms/step - loss: 0.6891 - accuracy: 0.5565 - val_loss: 0.6805 - val_accuracy: 0.6170\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 6s 485ms/step - loss: 0.6891 - accuracy: 0.5565 - val_loss: 0.6803 - val_accuracy: 0.6170\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 6s 495ms/step - loss: 0.6868 - accuracy: 0.5511 - val_loss: 0.6699 - val_accuracy: 0.6489\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 6s 504ms/step - loss: 0.6864 - accuracy: 0.5591 - val_loss: 0.6665 - val_accuracy: 0.6489\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 6s 459ms/step - loss: 0.6799 - accuracy: 0.5645 - val_loss: 0.6667 - val_accuracy: 0.6702\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 6s 465ms/step - loss: 0.6795 - accuracy: 0.5457 - val_loss: 0.6711 - val_accuracy: 0.6064\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 6s 505ms/step - loss: 0.6785 - accuracy: 0.5511 - val_loss: 0.6653 - val_accuracy: 0.6064\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 6s 480ms/step - loss: 0.6835 - accuracy: 0.5726 - val_loss: 0.6520 - val_accuracy: 0.6277\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 6s 502ms/step - loss: 0.6715 - accuracy: 0.5914 - val_loss: 0.6561 - val_accuracy: 0.6383\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 6s 488ms/step - loss: 0.6655 - accuracy: 0.6075 - val_loss: 0.6544 - val_accuracy: 0.5745\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 6s 466ms/step - loss: 0.6530 - accuracy: 0.6129 - val_loss: 0.6560 - val_accuracy: 0.6170\n",
      "4/4 [==============================] - 1s 110ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7205 - accuracy: 0.4797 - val_loss: 0.6923 - val_accuracy: 0.5161\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.7118 - accuracy: 0.5081 - val_loss: 0.6909 - val_accuracy: 0.5645\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.7034 - accuracy: 0.5203 - val_loss: 0.6931 - val_accuracy: 0.5161\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6867 - accuracy: 0.5528 - val_loss: 0.6996 - val_accuracy: 0.5000\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6985 - accuracy: 0.4878 - val_loss: 0.6973 - val_accuracy: 0.5000\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 5s 411ms/step - loss: 0.6935 - accuracy: 0.4878 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 3s 338ms/step - loss: 0.6929 - accuracy: 0.5122 - val_loss: 0.6930 - val_accuracy: 0.5161\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 3s 340ms/step - loss: 0.6925 - accuracy: 0.5244 - val_loss: 0.6928 - val_accuracy: 0.5161\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 3s 351ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6928 - val_accuracy: 0.5161\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 3s 340ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6930 - val_accuracy: 0.5161\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 3s 342ms/step - loss: 0.6931 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5161\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 3s 359ms/step - loss: 0.6948 - accuracy: 0.5163 - val_loss: 0.6921 - val_accuracy: 0.5161\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 3s 343ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6917 - val_accuracy: 0.5161\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 3s 337ms/step - loss: 0.6929 - accuracy: 0.5203 - val_loss: 0.6909 - val_accuracy: 0.5161\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 3s 339ms/step - loss: 0.6925 - accuracy: 0.5122 - val_loss: 0.6895 - val_accuracy: 0.5161\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 3s 342ms/step - loss: 0.6928 - accuracy: 0.4390 - val_loss: 0.6882 - val_accuracy: 0.5161\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 3s 341ms/step - loss: 0.6917 - accuracy: 0.5122 - val_loss: 0.6848 - val_accuracy: 0.5161\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 3s 339ms/step - loss: 0.6901 - accuracy: 0.5163 - val_loss: 1.1390 - val_accuracy: 0.3871\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 3s 341ms/step - loss: 0.8049 - accuracy: 0.4756 - val_loss: 0.6753 - val_accuracy: 0.5000\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 3s 339ms/step - loss: 0.7148 - accuracy: 0.4919 - val_loss: 0.6705 - val_accuracy: 0.5000\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 3s 347ms/step - loss: 0.7010 - accuracy: 0.5244 - val_loss: 0.6879 - val_accuracy: 0.5000\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 3s 338ms/step - loss: 0.6914 - accuracy: 0.4878 - val_loss: 0.6975 - val_accuracy: 0.3387\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 3s 341ms/step - loss: 0.7028 - accuracy: 0.4919 - val_loss: 0.6912 - val_accuracy: 0.5000\n",
      "3/3 [==============================] - 1s 66ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.7136 - accuracy: 0.4797 - val_loss: 0.6993 - val_accuracy: 0.5161\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.7077 - accuracy: 0.5041 - val_loss: 0.6992 - val_accuracy: 0.4839\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.7080 - accuracy: 0.5081 - val_loss: 0.7092 - val_accuracy: 0.4677\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.7027 - accuracy: 0.5041 - val_loss: 0.7082 - val_accuracy: 0.4677\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.5366 - val_loss: 0.7146 - val_accuracy: 0.4839\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 5s 408ms/step - loss: 0.6935 - accuracy: 0.4309 - val_loss: 0.6943 - val_accuracy: 0.4516\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 3s 342ms/step - loss: 0.6934 - accuracy: 0.5244 - val_loss: 0.6942 - val_accuracy: 0.4839\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 3s 346ms/step - loss: 0.6925 - accuracy: 0.5163 - val_loss: 0.6935 - val_accuracy: 0.4839\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 3s 340ms/step - loss: 0.6931 - accuracy: 0.5041 - val_loss: 0.6926 - val_accuracy: 0.5000\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 3s 343ms/step - loss: 0.6928 - accuracy: 0.5081 - val_loss: 0.6916 - val_accuracy: 0.5000\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 3s 336ms/step - loss: 0.6924 - accuracy: 0.4878 - val_loss: 0.6918 - val_accuracy: 0.5000\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 3s 340ms/step - loss: 0.6933 - accuracy: 0.4959 - val_loss: 0.6917 - val_accuracy: 0.5000\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 3s 340ms/step - loss: 0.6937 - accuracy: 0.4837 - val_loss: 0.6905 - val_accuracy: 0.5000\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 3s 340ms/step - loss: 0.6923 - accuracy: 0.4837 - val_loss: 0.6897 - val_accuracy: 0.5484\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 3s 385ms/step - loss: 0.6909 - accuracy: 0.5244 - val_loss: 0.6894 - val_accuracy: 0.5000\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 3s 363ms/step - loss: 0.6910 - accuracy: 0.5285 - val_loss: 0.6880 - val_accuracy: 0.5000\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 3s 362ms/step - loss: 0.6916 - accuracy: 0.5122 - val_loss: 0.6889 - val_accuracy: 0.4839\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 3s 358ms/step - loss: 0.6896 - accuracy: 0.5081 - val_loss: 0.6893 - val_accuracy: 0.4839\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 3s 372ms/step - loss: 0.6877 - accuracy: 0.5122 - val_loss: 0.6947 - val_accuracy: 0.4839\n",
      "3/3 [==============================] - 1s 79ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.7480 - accuracy: 0.5447 - val_loss: 0.7622 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.7452 - accuracy: 0.4553 - val_loss: 0.7036 - val_accuracy: 0.4839\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.7121 - accuracy: 0.5163 - val_loss: 0.7037 - val_accuracy: 0.4677\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6844 - accuracy: 0.5650 - val_loss: 0.7053 - val_accuracy: 0.5000\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.6815 - accuracy: 0.5691 - val_loss: 0.7064 - val_accuracy: 0.5000\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 7s 509ms/step - loss: 0.6936 - accuracy: 0.4959 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 3s 428ms/step - loss: 0.6921 - accuracy: 0.5122 - val_loss: 0.6935 - val_accuracy: 0.5000\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 3s 428ms/step - loss: 0.6922 - accuracy: 0.4837 - val_loss: 0.6936 - val_accuracy: 0.5161\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 3s 417ms/step - loss: 0.6916 - accuracy: 0.5000 - val_loss: 0.6941 - val_accuracy: 0.5161\n",
      "3/3 [==============================] - 1s 89ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7233 - accuracy: 0.4675 - val_loss: 0.6982 - val_accuracy: 0.4516\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.7101 - accuracy: 0.5163 - val_loss: 0.6990 - val_accuracy: 0.4839\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6920 - accuracy: 0.5203 - val_loss: 0.6987 - val_accuracy: 0.4839\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6808 - accuracy: 0.5610 - val_loss: 0.7010 - val_accuracy: 0.4032\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 6s 482ms/step - loss: 0.6950 - accuracy: 0.4268 - val_loss: 0.6928 - val_accuracy: 0.4839\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 3s 412ms/step - loss: 0.6922 - accuracy: 0.5407 - val_loss: 0.6930 - val_accuracy: 0.5484\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 3s 412ms/step - loss: 0.6929 - accuracy: 0.5203 - val_loss: 0.6933 - val_accuracy: 0.5323\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 3s 421ms/step - loss: 0.6918 - accuracy: 0.5366 - val_loss: 0.6935 - val_accuracy: 0.5645\n",
      "3/3 [==============================] - 1s 84ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.7465 - accuracy: 0.4472 - val_loss: 0.7054 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.7018 - accuracy: 0.5447 - val_loss: 0.6959 - val_accuracy: 0.5484\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6961 - accuracy: 0.5244 - val_loss: 0.6933 - val_accuracy: 0.5161\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.7036 - accuracy: 0.5285 - val_loss: 0.6974 - val_accuracy: 0.5161\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6784 - accuracy: 0.5650 - val_loss: 0.6947 - val_accuracy: 0.5161\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6626 - accuracy: 0.5976 - val_loss: 0.6942 - val_accuracy: 0.5484\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 6s 473ms/step - loss: 0.6941 - accuracy: 0.4797 - val_loss: 0.6936 - val_accuracy: 0.5161\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 3s 405ms/step - loss: 0.6930 - accuracy: 0.5528 - val_loss: 0.6941 - val_accuracy: 0.5000\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 3s 406ms/step - loss: 0.6942 - accuracy: 0.5081 - val_loss: 0.6935 - val_accuracy: 0.5000\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 3s 405ms/step - loss: 0.6936 - accuracy: 0.4959 - val_loss: 0.6938 - val_accuracy: 0.5000\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 3s 410ms/step - loss: 0.6921 - accuracy: 0.5244 - val_loss: 0.6935 - val_accuracy: 0.5000\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 3s 405ms/step - loss: 0.6932 - accuracy: 0.5041 - val_loss: 0.6937 - val_accuracy: 0.5000\n",
      "3/3 [==============================] - 1s 83ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.7198 - accuracy: 0.5285 - val_loss: 0.6956 - val_accuracy: 0.5161\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.7026 - accuracy: 0.5000 - val_loss: 0.6989 - val_accuracy: 0.4516\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6993 - accuracy: 0.5610 - val_loss: 0.6982 - val_accuracy: 0.5161\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6636 - accuracy: 0.5650 - val_loss: 0.7037 - val_accuracy: 0.5323\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 6s 497ms/step - loss: 0.6951 - accuracy: 0.4878 - val_loss: 0.6933 - val_accuracy: 0.5484\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 3s 425ms/step - loss: 0.6936 - accuracy: 0.4837 - val_loss: 0.6937 - val_accuracy: 0.5000\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 3s 424ms/step - loss: 0.6939 - accuracy: 0.5081 - val_loss: 0.6946 - val_accuracy: 0.4839\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 3s 425ms/step - loss: 0.6920 - accuracy: 0.5325 - val_loss: 0.6944 - val_accuracy: 0.4677\n",
      "3/3 [==============================] - 1s 86ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8108 - accuracy: 0.4675 - val_loss: 0.7552 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.7427 - accuracy: 0.5163 - val_loss: 0.7262 - val_accuracy: 0.5000\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.7004 - accuracy: 0.5041 - val_loss: 0.7140 - val_accuracy: 0.4516\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6986 - accuracy: 0.5691 - val_loss: 0.7029 - val_accuracy: 0.5645\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6790 - accuracy: 0.5813 - val_loss: 0.7061 - val_accuracy: 0.4516\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6491 - accuracy: 0.6585 - val_loss: 0.7089 - val_accuracy: 0.5161\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6615 - accuracy: 0.6138 - val_loss: 0.7151 - val_accuracy: 0.5161\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 6s 493ms/step - loss: 0.6940 - accuracy: 0.4959 - val_loss: 0.6926 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 3s 426ms/step - loss: 0.6923 - accuracy: 0.5366 - val_loss: 0.6940 - val_accuracy: 0.4677\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 3s 428ms/step - loss: 0.6933 - accuracy: 0.5203 - val_loss: 0.6950 - val_accuracy: 0.4839\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 3s 424ms/step - loss: 0.6923 - accuracy: 0.5163 - val_loss: 0.6950 - val_accuracy: 0.5000\n",
      "3/3 [==============================] - 1s 85ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.7423 - accuracy: 0.5285 - val_loss: 0.7467 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.7431 - accuracy: 0.4959 - val_loss: 0.7230 - val_accuracy: 0.5000\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.7282 - accuracy: 0.4959 - val_loss: 0.7022 - val_accuracy: 0.5000\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6700 - accuracy: 0.5772 - val_loss: 0.7014 - val_accuracy: 0.4516\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6708 - accuracy: 0.5732 - val_loss: 0.7101 - val_accuracy: 0.5000\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6833 - accuracy: 0.5488 - val_loss: 0.7134 - val_accuracy: 0.4677\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6566 - accuracy: 0.6016 - val_loss: 0.7095 - val_accuracy: 0.5000\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 6s 501ms/step - loss: 0.6942 - accuracy: 0.4959 - val_loss: 0.6924 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 3s 424ms/step - loss: 0.6933 - accuracy: 0.5041 - val_loss: 0.6935 - val_accuracy: 0.4839\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 3s 426ms/step - loss: 0.6931 - accuracy: 0.5366 - val_loss: 0.6959 - val_accuracy: 0.4839\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 3s 422ms/step - loss: 0.6930 - accuracy: 0.5163 - val_loss: 0.6968 - val_accuracy: 0.4677\n",
      "3/3 [==============================] - 1s 99ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7210 - accuracy: 0.4431 - val_loss: 0.7042 - val_accuracy: 0.4677\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6994 - accuracy: 0.5447 - val_loss: 0.7030 - val_accuracy: 0.4516\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6856 - accuracy: 0.5813 - val_loss: 0.7093 - val_accuracy: 0.5000\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6768 - accuracy: 0.5813 - val_loss: 0.7125 - val_accuracy: 0.5323\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6752 - accuracy: 0.5772 - val_loss: 0.7066 - val_accuracy: 0.4355\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 6s 486ms/step - loss: 0.6950 - accuracy: 0.4431 - val_loss: 0.6933 - val_accuracy: 0.4839\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 3s 417ms/step - loss: 0.6926 - accuracy: 0.5041 - val_loss: 0.6935 - val_accuracy: 0.4677\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 3s 417ms/step - loss: 0.6920 - accuracy: 0.5285 - val_loss: 0.6938 - val_accuracy: 0.4677\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 3s 415ms/step - loss: 0.6914 - accuracy: 0.5407 - val_loss: 0.6941 - val_accuracy: 0.5161\n",
      "3/3 [==============================] - 1s 98ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.7310 - accuracy: 0.4959 - val_loss: 0.6995 - val_accuracy: 0.4839\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.7037 - accuracy: 0.5081 - val_loss: 0.6826 - val_accuracy: 0.5645\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6819 - accuracy: 0.5772 - val_loss: 0.6775 - val_accuracy: 0.6290\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6604 - accuracy: 0.6016 - val_loss: 0.6702 - val_accuracy: 0.5806\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6365 - accuracy: 0.6545 - val_loss: 0.6665 - val_accuracy: 0.6129\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6211 - accuracy: 0.6789 - val_loss: 0.6599 - val_accuracy: 0.6452\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6010 - accuracy: 0.6829 - val_loss: 0.6529 - val_accuracy: 0.6613\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5884 - accuracy: 0.6911 - val_loss: 0.6481 - val_accuracy: 0.6613\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5393 - accuracy: 0.7602 - val_loss: 0.6433 - val_accuracy: 0.6290\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5422 - accuracy: 0.7764 - val_loss: 0.6211 - val_accuracy: 0.6935\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4620 - accuracy: 0.8089 - val_loss: 0.6072 - val_accuracy: 0.6613\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4517 - accuracy: 0.8252 - val_loss: 0.5959 - val_accuracy: 0.6613\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4499 - accuracy: 0.8374 - val_loss: 0.5928 - val_accuracy: 0.6935\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4072 - accuracy: 0.8130 - val_loss: 0.5845 - val_accuracy: 0.6935\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3898 - accuracy: 0.8577 - val_loss: 0.5773 - val_accuracy: 0.6935\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3476 - accuracy: 0.8780 - val_loss: 0.5621 - val_accuracy: 0.7419\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3523 - accuracy: 0.8699 - val_loss: 0.5710 - val_accuracy: 0.6935\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3303 - accuracy: 0.8740 - val_loss: 0.5743 - val_accuracy: 0.7097\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3211 - accuracy: 0.8659 - val_loss: 0.5753 - val_accuracy: 0.7581\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 7s 542ms/step - loss: 0.6936 - accuracy: 0.4797 - val_loss: 0.6938 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 4s 477ms/step - loss: 0.6927 - accuracy: 0.5569 - val_loss: 0.6935 - val_accuracy: 0.4839\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 4s 480ms/step - loss: 0.6935 - accuracy: 0.4675 - val_loss: 0.6940 - val_accuracy: 0.4516\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 4s 474ms/step - loss: 0.6919 - accuracy: 0.5122 - val_loss: 0.6942 - val_accuracy: 0.4677\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 4s 554ms/step - loss: 0.6911 - accuracy: 0.5488 - val_loss: 0.6944 - val_accuracy: 0.4677\n",
      "3/3 [==============================] - 1s 104ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7641 - accuracy: 0.4694 - val_loss: 0.6868 - val_accuracy: 0.5806\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.7153 - accuracy: 0.5061 - val_loss: 0.6824 - val_accuracy: 0.5323\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.7206 - accuracy: 0.4939 - val_loss: 0.6781 - val_accuracy: 0.5484\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6807 - accuracy: 0.5510 - val_loss: 0.6727 - val_accuracy: 0.5000\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6994 - accuracy: 0.5429 - val_loss: 0.6537 - val_accuracy: 0.5645\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6572 - accuracy: 0.5959 - val_loss: 0.6407 - val_accuracy: 0.7258\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6424 - accuracy: 0.6367 - val_loss: 0.6281 - val_accuracy: 0.7742\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6218 - accuracy: 0.6367 - val_loss: 0.6266 - val_accuracy: 0.6613\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6329 - accuracy: 0.6449 - val_loss: 0.6162 - val_accuracy: 0.6935\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5896 - accuracy: 0.7102 - val_loss: 0.6086 - val_accuracy: 0.6774\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6122 - accuracy: 0.6612 - val_loss: 0.5921 - val_accuracy: 0.7742\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5786 - accuracy: 0.7102 - val_loss: 0.5866 - val_accuracy: 0.7742\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5680 - accuracy: 0.7224 - val_loss: 0.5924 - val_accuracy: 0.6935\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.5445 - accuracy: 0.7673 - val_loss: 0.5801 - val_accuracy: 0.7581\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5393 - accuracy: 0.7184 - val_loss: 0.5803 - val_accuracy: 0.7742\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5416 - accuracy: 0.7102 - val_loss: 0.5800 - val_accuracy: 0.7581\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5425 - accuracy: 0.7143 - val_loss: 0.5859 - val_accuracy: 0.6935\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5021 - accuracy: 0.7714 - val_loss: 0.5934 - val_accuracy: 0.7419\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5368 - accuracy: 0.7143 - val_loss: 0.5904 - val_accuracy: 0.7097\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 6s 478ms/step - loss: 0.6934 - accuracy: 0.5020 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 3s 345ms/step - loss: 0.6928 - accuracy: 0.5102 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 3s 365ms/step - loss: 0.6938 - accuracy: 0.5143 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 3s 357ms/step - loss: 0.6928 - accuracy: 0.5102 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 3s 344ms/step - loss: 0.6932 - accuracy: 0.5102 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 3s 338ms/step - loss: 0.6929 - accuracy: 0.5102 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "3/3 [==============================] - 1s 69ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7113 - accuracy: 0.5265 - val_loss: 0.6865 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6945 - accuracy: 0.5510 - val_loss: 0.6746 - val_accuracy: 0.5645\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6959 - accuracy: 0.5918 - val_loss: 0.6688 - val_accuracy: 0.7419\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6655 - accuracy: 0.6000 - val_loss: 0.6628 - val_accuracy: 0.6935\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6408 - accuracy: 0.6449 - val_loss: 0.6559 - val_accuracy: 0.6935\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6323 - accuracy: 0.6816 - val_loss: 0.6457 - val_accuracy: 0.6452\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6055 - accuracy: 0.6939 - val_loss: 0.6406 - val_accuracy: 0.7258\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5960 - accuracy: 0.6939 - val_loss: 0.6266 - val_accuracy: 0.6774\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5669 - accuracy: 0.7102 - val_loss: 0.6223 - val_accuracy: 0.7742\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5826 - accuracy: 0.6939 - val_loss: 0.6055 - val_accuracy: 0.7581\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5386 - accuracy: 0.7388 - val_loss: 0.6031 - val_accuracy: 0.7903\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5196 - accuracy: 0.7592 - val_loss: 0.5917 - val_accuracy: 0.7581\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5167 - accuracy: 0.7551 - val_loss: 0.5842 - val_accuracy: 0.7581\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4805 - accuracy: 0.7551 - val_loss: 0.5777 - val_accuracy: 0.7258\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4515 - accuracy: 0.8122 - val_loss: 0.5769 - val_accuracy: 0.7258\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4662 - accuracy: 0.7959 - val_loss: 0.5692 - val_accuracy: 0.7097\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4662 - accuracy: 0.7796 - val_loss: 0.5768 - val_accuracy: 0.7097\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4345 - accuracy: 0.7714 - val_loss: 0.5724 - val_accuracy: 0.6935\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4370 - accuracy: 0.8041 - val_loss: 0.5689 - val_accuracy: 0.7097\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4158 - accuracy: 0.8000 - val_loss: 0.5761 - val_accuracy: 0.7097\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3970 - accuracy: 0.8204 - val_loss: 0.5744 - val_accuracy: 0.7097\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4054 - accuracy: 0.8245 - val_loss: 0.5647 - val_accuracy: 0.6935\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3995 - accuracy: 0.8163 - val_loss: 0.5691 - val_accuracy: 0.7097\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3845 - accuracy: 0.8367 - val_loss: 0.5833 - val_accuracy: 0.7097\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3863 - accuracy: 0.8163 - val_loss: 0.6049 - val_accuracy: 0.7419\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 6s 433ms/step - loss: 0.6935 - accuracy: 0.4816 - val_loss: 0.6937 - val_accuracy: 0.4839\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 3s 359ms/step - loss: 0.6929 - accuracy: 0.4857 - val_loss: 0.6941 - val_accuracy: 0.5000\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 3s 359ms/step - loss: 0.6926 - accuracy: 0.5061 - val_loss: 0.6949 - val_accuracy: 0.5000\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 3s 375ms/step - loss: 0.6929 - accuracy: 0.4776 - val_loss: 0.6957 - val_accuracy: 0.5000\n",
      "3/3 [==============================] - 1s 73ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7299 - accuracy: 0.4653 - val_loss: 0.6932 - val_accuracy: 0.5323\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6879 - accuracy: 0.5388 - val_loss: 0.6888 - val_accuracy: 0.5161\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6744 - accuracy: 0.5633 - val_loss: 0.6833 - val_accuracy: 0.4839\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6609 - accuracy: 0.6163 - val_loss: 0.6742 - val_accuracy: 0.5645\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6695 - accuracy: 0.5959 - val_loss: 0.6613 - val_accuracy: 0.7097\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6104 - accuracy: 0.6816 - val_loss: 0.6494 - val_accuracy: 0.7419\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6238 - accuracy: 0.6694 - val_loss: 0.6381 - val_accuracy: 0.6935\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5899 - accuracy: 0.6939 - val_loss: 0.6258 - val_accuracy: 0.7419\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5607 - accuracy: 0.7224 - val_loss: 0.6162 - val_accuracy: 0.7742\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5537 - accuracy: 0.7347 - val_loss: 0.6066 - val_accuracy: 0.7419\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5262 - accuracy: 0.7510 - val_loss: 0.6010 - val_accuracy: 0.7581\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5175 - accuracy: 0.7551 - val_loss: 0.5963 - val_accuracy: 0.7258\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5044 - accuracy: 0.7673 - val_loss: 0.5954 - val_accuracy: 0.7097\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4731 - accuracy: 0.7837 - val_loss: 0.6011 - val_accuracy: 0.6935\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4629 - accuracy: 0.7837 - val_loss: 0.6004 - val_accuracy: 0.6935\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4536 - accuracy: 0.7714 - val_loss: 0.6132 - val_accuracy: 0.6935\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 6s 428ms/step - loss: 0.6915 - accuracy: 0.5306 - val_loss: 0.6922 - val_accuracy: 0.4677\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 3s 358ms/step - loss: 0.6873 - accuracy: 0.5224 - val_loss: 0.6937 - val_accuracy: 0.4677\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 3s 347ms/step - loss: 0.6829 - accuracy: 0.5184 - val_loss: 0.6979 - val_accuracy: 0.4677\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 3s 348ms/step - loss: 0.6834 - accuracy: 0.5224 - val_loss: 0.6970 - val_accuracy: 0.4677\n",
      "3/3 [==============================] - 1s 72ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8210 - accuracy: 0.5061 - val_loss: 0.7351 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.7532 - accuracy: 0.4816 - val_loss: 0.6892 - val_accuracy: 0.5000\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6802 - accuracy: 0.5388 - val_loss: 0.6940 - val_accuracy: 0.5000\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6510 - accuracy: 0.6041 - val_loss: 0.6739 - val_accuracy: 0.5968\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6516 - accuracy: 0.6408 - val_loss: 0.6704 - val_accuracy: 0.5645\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6450 - accuracy: 0.6163 - val_loss: 0.6630 - val_accuracy: 0.6774\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6418 - accuracy: 0.6449 - val_loss: 0.6555 - val_accuracy: 0.7097\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6241 - accuracy: 0.6694 - val_loss: 0.6493 - val_accuracy: 0.7097\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6031 - accuracy: 0.6776 - val_loss: 0.6465 - val_accuracy: 0.6452\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5738 - accuracy: 0.6980 - val_loss: 0.6394 - val_accuracy: 0.7419\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5522 - accuracy: 0.7429 - val_loss: 0.6384 - val_accuracy: 0.6774\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5556 - accuracy: 0.7184 - val_loss: 0.6312 - val_accuracy: 0.7097\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5216 - accuracy: 0.7551 - val_loss: 0.6281 - val_accuracy: 0.7581\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5167 - accuracy: 0.7551 - val_loss: 0.6241 - val_accuracy: 0.7097\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4921 - accuracy: 0.7878 - val_loss: 0.6230 - val_accuracy: 0.7742\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4858 - accuracy: 0.7796 - val_loss: 0.6306 - val_accuracy: 0.7419\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4621 - accuracy: 0.7673 - val_loss: 0.6407 - val_accuracy: 0.7097\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4480 - accuracy: 0.7918 - val_loss: 0.6425 - val_accuracy: 0.7419\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 6s 482ms/step - loss: 0.6935 - accuracy: 0.4857 - val_loss: 0.6926 - val_accuracy: 0.4839\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 3s 344ms/step - loss: 0.6909 - accuracy: 0.5224 - val_loss: 0.6922 - val_accuracy: 0.4677\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 3s 345ms/step - loss: 0.6874 - accuracy: 0.5224 - val_loss: 0.6970 - val_accuracy: 0.4355\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 3s 345ms/step - loss: 0.6880 - accuracy: 0.5592 - val_loss: 0.6982 - val_accuracy: 0.4516\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 3s 344ms/step - loss: 0.6869 - accuracy: 0.5347 - val_loss: 0.6929 - val_accuracy: 0.4516\n",
      "3/3 [==============================] - 1s 62ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.8298 - accuracy: 0.4653 - val_loss: 0.7304 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.7306 - accuracy: 0.4980 - val_loss: 0.6878 - val_accuracy: 0.5161\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6808 - accuracy: 0.5429 - val_loss: 0.6949 - val_accuracy: 0.5000\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6584 - accuracy: 0.5837 - val_loss: 0.6829 - val_accuracy: 0.5161\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6507 - accuracy: 0.6122 - val_loss: 0.6777 - val_accuracy: 0.6129\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6382 - accuracy: 0.6163 - val_loss: 0.6713 - val_accuracy: 0.7097\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6233 - accuracy: 0.6531 - val_loss: 0.6685 - val_accuracy: 0.7903\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5920 - accuracy: 0.6653 - val_loss: 0.6616 - val_accuracy: 0.6129\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5434 - accuracy: 0.7347 - val_loss: 0.6599 - val_accuracy: 0.7742\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5423 - accuracy: 0.7551 - val_loss: 0.6555 - val_accuracy: 0.6129\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5438 - accuracy: 0.7224 - val_loss: 0.6501 - val_accuracy: 0.5968\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5056 - accuracy: 0.7592 - val_loss: 0.6474 - val_accuracy: 0.7097\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4893 - accuracy: 0.7796 - val_loss: 0.6474 - val_accuracy: 0.6129\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4662 - accuracy: 0.7878 - val_loss: 0.6438 - val_accuracy: 0.7258\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4394 - accuracy: 0.7959 - val_loss: 0.6433 - val_accuracy: 0.6935\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4488 - accuracy: 0.7878 - val_loss: 0.6542 - val_accuracy: 0.5806\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4278 - accuracy: 0.8082 - val_loss: 0.6516 - val_accuracy: 0.6935\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3945 - accuracy: 0.8367 - val_loss: 0.6547 - val_accuracy: 0.6935\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 6s 486ms/step - loss: 0.6933 - accuracy: 0.5224 - val_loss: 0.6908 - val_accuracy: 0.4839\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 3s 363ms/step - loss: 0.6906 - accuracy: 0.5347 - val_loss: 0.6903 - val_accuracy: 0.4516\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 3s 348ms/step - loss: 0.6871 - accuracy: 0.5388 - val_loss: 0.6903 - val_accuracy: 0.4032\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 3s 356ms/step - loss: 0.6875 - accuracy: 0.5306 - val_loss: 0.6917 - val_accuracy: 0.4032\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 3s 383ms/step - loss: 0.6877 - accuracy: 0.5388 - val_loss: 0.6940 - val_accuracy: 0.4032\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 3s 344ms/step - loss: 0.6889 - accuracy: 0.5020 - val_loss: 0.6907 - val_accuracy: 0.4194\n",
      "3/3 [==============================] - 1s 67ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6978 - accuracy: 0.5469 - val_loss: 0.7032 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6771 - accuracy: 0.5469 - val_loss: 0.6668 - val_accuracy: 0.6129\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6773 - accuracy: 0.5796 - val_loss: 0.6490 - val_accuracy: 0.6290\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6262 - accuracy: 0.6857 - val_loss: 0.6362 - val_accuracy: 0.6452\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5956 - accuracy: 0.6980 - val_loss: 0.6189 - val_accuracy: 0.7258\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5649 - accuracy: 0.7673 - val_loss: 0.6026 - val_accuracy: 0.7258\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5384 - accuracy: 0.7796 - val_loss: 0.5851 - val_accuracy: 0.7097\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5121 - accuracy: 0.8000 - val_loss: 0.5724 - val_accuracy: 0.7097\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5006 - accuracy: 0.8041 - val_loss: 0.5647 - val_accuracy: 0.7097\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4570 - accuracy: 0.8408 - val_loss: 0.5582 - val_accuracy: 0.7258\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4521 - accuracy: 0.8327 - val_loss: 0.5537 - val_accuracy: 0.7258\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4215 - accuracy: 0.8408 - val_loss: 0.5432 - val_accuracy: 0.7419\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3998 - accuracy: 0.8449 - val_loss: 0.5460 - val_accuracy: 0.7097\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3930 - accuracy: 0.8449 - val_loss: 0.5567 - val_accuracy: 0.7097\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3784 - accuracy: 0.8531 - val_loss: 0.5588 - val_accuracy: 0.7258\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 5s 408ms/step - loss: 0.6937 - accuracy: 0.5020 - val_loss: 0.6909 - val_accuracy: 0.5323\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 3s 357ms/step - loss: 0.6931 - accuracy: 0.4816 - val_loss: 0.6916 - val_accuracy: 0.4355\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 3s 371ms/step - loss: 0.6930 - accuracy: 0.5184 - val_loss: 0.6905 - val_accuracy: 0.4839\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 3s 397ms/step - loss: 0.6925 - accuracy: 0.4612 - val_loss: 0.6906 - val_accuracy: 0.4355\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 3s 398ms/step - loss: 0.6911 - accuracy: 0.5061 - val_loss: 0.6901 - val_accuracy: 0.4194\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 3s 335ms/step - loss: 0.6921 - accuracy: 0.5143 - val_loss: 0.6899 - val_accuracy: 0.4355\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 3s 336ms/step - loss: 0.6910 - accuracy: 0.5224 - val_loss: 0.6898 - val_accuracy: 0.5161\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 3s 342ms/step - loss: 0.6908 - accuracy: 0.5102 - val_loss: 0.6897 - val_accuracy: 0.5161\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 3s 357ms/step - loss: 0.6922 - accuracy: 0.4857 - val_loss: 0.6891 - val_accuracy: 0.4516\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 3s 373ms/step - loss: 0.6910 - accuracy: 0.4816 - val_loss: 0.6901 - val_accuracy: 0.5323\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 3s 365ms/step - loss: 0.6902 - accuracy: 0.5143 - val_loss: 0.6918 - val_accuracy: 0.5161\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 3s 369ms/step - loss: 0.6900 - accuracy: 0.5061 - val_loss: 0.6955 - val_accuracy: 0.4839\n",
      "3/3 [==============================] - 1s 73ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7289 - accuracy: 0.4816 - val_loss: 0.6870 - val_accuracy: 0.5323\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.7116 - accuracy: 0.5184 - val_loss: 0.6734 - val_accuracy: 0.5645\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6430 - accuracy: 0.6122 - val_loss: 0.6613 - val_accuracy: 0.5968\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6380 - accuracy: 0.6286 - val_loss: 0.6393 - val_accuracy: 0.5968\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5901 - accuracy: 0.6694 - val_loss: 0.6216 - val_accuracy: 0.7581\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5651 - accuracy: 0.7224 - val_loss: 0.6049 - val_accuracy: 0.6452\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5320 - accuracy: 0.7755 - val_loss: 0.5854 - val_accuracy: 0.7097\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4771 - accuracy: 0.7959 - val_loss: 0.5686 - val_accuracy: 0.7097\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4347 - accuracy: 0.8286 - val_loss: 0.5527 - val_accuracy: 0.6935\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4238 - accuracy: 0.8367 - val_loss: 0.5400 - val_accuracy: 0.6935\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4111 - accuracy: 0.8367 - val_loss: 0.5236 - val_accuracy: 0.7258\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3948 - accuracy: 0.8531 - val_loss: 0.5419 - val_accuracy: 0.6774\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3747 - accuracy: 0.8531 - val_loss: 0.5310 - val_accuracy: 0.6935\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3324 - accuracy: 0.8735 - val_loss: 0.5294 - val_accuracy: 0.7258\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 6s 441ms/step - loss: 0.6930 - accuracy: 0.5265 - val_loss: 0.6905 - val_accuracy: 0.5323\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 3s 366ms/step - loss: 0.6924 - accuracy: 0.5184 - val_loss: 0.6901 - val_accuracy: 0.4839\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 3s 371ms/step - loss: 0.6922 - accuracy: 0.5061 - val_loss: 0.6895 - val_accuracy: 0.4677\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 3s 375ms/step - loss: 0.6919 - accuracy: 0.4898 - val_loss: 0.6896 - val_accuracy: 0.4839\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 3s 367ms/step - loss: 0.6922 - accuracy: 0.5265 - val_loss: 0.6892 - val_accuracy: 0.5161\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 3s 370ms/step - loss: 0.6904 - accuracy: 0.5388 - val_loss: 0.6894 - val_accuracy: 0.4677\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 3s 377ms/step - loss: 0.6921 - accuracy: 0.4776 - val_loss: 0.6897 - val_accuracy: 0.4677\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 3s 372ms/step - loss: 0.6912 - accuracy: 0.5061 - val_loss: 0.6901 - val_accuracy: 0.5000\n",
      "3/3 [==============================] - 1s 74ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7679 - accuracy: 0.5102 - val_loss: 0.7665 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6972 - accuracy: 0.5347 - val_loss: 0.6544 - val_accuracy: 0.5806\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6585 - accuracy: 0.6122 - val_loss: 0.6294 - val_accuracy: 0.6774\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6075 - accuracy: 0.7061 - val_loss: 0.6003 - val_accuracy: 0.7742\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5590 - accuracy: 0.7551 - val_loss: 0.5683 - val_accuracy: 0.8065\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5456 - accuracy: 0.7429 - val_loss: 0.5410 - val_accuracy: 0.7742\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5102 - accuracy: 0.7837 - val_loss: 0.5122 - val_accuracy: 0.7742\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4648 - accuracy: 0.7918 - val_loss: 0.4884 - val_accuracy: 0.8065\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4246 - accuracy: 0.8408 - val_loss: 0.4809 - val_accuracy: 0.7581\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4007 - accuracy: 0.8327 - val_loss: 0.4515 - val_accuracy: 0.8226\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3577 - accuracy: 0.8735 - val_loss: 0.4453 - val_accuracy: 0.8710\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3335 - accuracy: 0.8653 - val_loss: 0.4384 - val_accuracy: 0.8387\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3298 - accuracy: 0.8857 - val_loss: 0.4308 - val_accuracy: 0.8710\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2843 - accuracy: 0.8939 - val_loss: 0.4385 - val_accuracy: 0.8548\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2867 - accuracy: 0.8939 - val_loss: 0.4367 - val_accuracy: 0.8710\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2727 - accuracy: 0.9061 - val_loss: 0.4546 - val_accuracy: 0.8387\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 5s 427ms/step - loss: 0.6979 - accuracy: 0.4531 - val_loss: 0.6936 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 3s 355ms/step - loss: 0.6943 - accuracy: 0.4490 - val_loss: 0.6916 - val_accuracy: 0.4839\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 3s 359ms/step - loss: 0.6927 - accuracy: 0.4694 - val_loss: 0.6908 - val_accuracy: 0.4839\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 3s 362ms/step - loss: 0.6917 - accuracy: 0.4939 - val_loss: 0.6901 - val_accuracy: 0.4839\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 3s 362ms/step - loss: 0.6907 - accuracy: 0.4898 - val_loss: 0.6898 - val_accuracy: 0.4839\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 3s 356ms/step - loss: 0.6905 - accuracy: 0.5061 - val_loss: 0.6897 - val_accuracy: 0.4839\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 3s 358ms/step - loss: 0.6910 - accuracy: 0.5143 - val_loss: 0.6899 - val_accuracy: 0.4839\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 3s 368ms/step - loss: 0.6901 - accuracy: 0.5306 - val_loss: 0.6900 - val_accuracy: 0.4839\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 3s 362ms/step - loss: 0.6905 - accuracy: 0.5020 - val_loss: 0.6903 - val_accuracy: 0.5000\n",
      "3/3 [==============================] - 1s 71ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7022 - accuracy: 0.5592 - val_loss: 0.6735 - val_accuracy: 0.6129\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6558 - accuracy: 0.6122 - val_loss: 0.6357 - val_accuracy: 0.7903\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6121 - accuracy: 0.6898 - val_loss: 0.5980 - val_accuracy: 0.7742\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5365 - accuracy: 0.8041 - val_loss: 0.5599 - val_accuracy: 0.7419\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5103 - accuracy: 0.8000 - val_loss: 0.5184 - val_accuracy: 0.7581\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4364 - accuracy: 0.8490 - val_loss: 0.4952 - val_accuracy: 0.7903\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3828 - accuracy: 0.8898 - val_loss: 0.4688 - val_accuracy: 0.7742\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3509 - accuracy: 0.8857 - val_loss: 0.4512 - val_accuracy: 0.7742\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3206 - accuracy: 0.8939 - val_loss: 0.4496 - val_accuracy: 0.7742\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3025 - accuracy: 0.8898 - val_loss: 0.4471 - val_accuracy: 0.7742\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2695 - accuracy: 0.9224 - val_loss: 0.4477 - val_accuracy: 0.7742\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2411 - accuracy: 0.9143 - val_loss: 0.4619 - val_accuracy: 0.7742\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2285 - accuracy: 0.9224 - val_loss: 0.4764 - val_accuracy: 0.7742\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 5s 428ms/step - loss: 0.6922 - accuracy: 0.5429 - val_loss: 0.6911 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 3s 357ms/step - loss: 0.6911 - accuracy: 0.5469 - val_loss: 0.6903 - val_accuracy: 0.4516\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 3s 357ms/step - loss: 0.6929 - accuracy: 0.5265 - val_loss: 0.6900 - val_accuracy: 0.5161\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 3s 357ms/step - loss: 0.6906 - accuracy: 0.5224 - val_loss: 0.6898 - val_accuracy: 0.5161\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 3s 339ms/step - loss: 0.6911 - accuracy: 0.5184 - val_loss: 0.6888 - val_accuracy: 0.5000\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 3s 348ms/step - loss: 0.6891 - accuracy: 0.5265 - val_loss: 0.6883 - val_accuracy: 0.5000\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 3s 351ms/step - loss: 0.6870 - accuracy: 0.5306 - val_loss: 0.6867 - val_accuracy: 0.5000\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 3s 360ms/step - loss: 0.6903 - accuracy: 0.5347 - val_loss: 0.6859 - val_accuracy: 0.5645\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 3s 346ms/step - loss: 0.6878 - accuracy: 0.5306 - val_loss: 0.6845 - val_accuracy: 0.4839\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 3s 344ms/step - loss: 0.6874 - accuracy: 0.5265 - val_loss: 0.6870 - val_accuracy: 0.5323\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 3s 342ms/step - loss: 0.6844 - accuracy: 0.5224 - val_loss: 0.6826 - val_accuracy: 0.5484\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 3s 343ms/step - loss: 0.6858 - accuracy: 0.5592 - val_loss: 0.6806 - val_accuracy: 0.5645\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 3s 351ms/step - loss: 0.6860 - accuracy: 0.5143 - val_loss: 0.6857 - val_accuracy: 0.5000\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 3s 351ms/step - loss: 0.6822 - accuracy: 0.5633 - val_loss: 0.6803 - val_accuracy: 0.5484\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 3s 356ms/step - loss: 0.6780 - accuracy: 0.5837 - val_loss: 0.6805 - val_accuracy: 0.5000\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 3s 347ms/step - loss: 0.6760 - accuracy: 0.5755 - val_loss: 0.6865 - val_accuracy: 0.4839\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 3s 356ms/step - loss: 0.6868 - accuracy: 0.5265 - val_loss: 0.6795 - val_accuracy: 0.4677\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 3s 374ms/step - loss: 0.6751 - accuracy: 0.5755 - val_loss: 0.6772 - val_accuracy: 0.6290\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 3s 384ms/step - loss: 0.6729 - accuracy: 0.6041 - val_loss: 0.6773 - val_accuracy: 0.5645\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 3s 376ms/step - loss: 0.6748 - accuracy: 0.5918 - val_loss: 0.6836 - val_accuracy: 0.5645\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 3s 351ms/step - loss: 0.6657 - accuracy: 0.6204 - val_loss: 0.6906 - val_accuracy: 0.5484\n",
      "3/3 [==============================] - 1s 69ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7433 - accuracy: 0.5633 - val_loss: 0.7264 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6917 - accuracy: 0.5551 - val_loss: 0.6161 - val_accuracy: 0.6935\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6201 - accuracy: 0.6816 - val_loss: 0.5963 - val_accuracy: 0.6129\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5253 - accuracy: 0.8041 - val_loss: 0.5254 - val_accuracy: 0.7903\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4626 - accuracy: 0.8327 - val_loss: 0.4729 - val_accuracy: 0.7903\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4001 - accuracy: 0.8776 - val_loss: 0.4201 - val_accuracy: 0.8387\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3427 - accuracy: 0.9061 - val_loss: 0.3800 - val_accuracy: 0.8710\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3056 - accuracy: 0.9224 - val_loss: 0.3584 - val_accuracy: 0.8387\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2582 - accuracy: 0.9306 - val_loss: 0.3292 - val_accuracy: 0.8548\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2330 - accuracy: 0.9429 - val_loss: 0.3123 - val_accuracy: 0.8548\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2087 - accuracy: 0.9306 - val_loss: 0.3012 - val_accuracy: 0.8548\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2014 - accuracy: 0.9551 - val_loss: 0.2962 - val_accuracy: 0.8548\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1875 - accuracy: 0.9306 - val_loss: 0.2930 - val_accuracy: 0.8387\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1532 - accuracy: 0.9673 - val_loss: 0.2926 - val_accuracy: 0.8548\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1485 - accuracy: 0.9592 - val_loss: 0.2920 - val_accuracy: 0.8548\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1458 - accuracy: 0.9633 - val_loss: 0.2900 - val_accuracy: 0.8548\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1288 - accuracy: 0.9673 - val_loss: 0.2930 - val_accuracy: 0.8548\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1253 - accuracy: 0.9673 - val_loss: 0.2946 - val_accuracy: 0.8548\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1163 - accuracy: 0.9673 - val_loss: 0.2955 - val_accuracy: 0.8710\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 6s 421ms/step - loss: 0.6937 - accuracy: 0.5224 - val_loss: 0.6915 - val_accuracy: 0.5806\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 3s 345ms/step - loss: 0.6918 - accuracy: 0.5102 - val_loss: 0.6901 - val_accuracy: 0.5000\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 3s 345ms/step - loss: 0.6902 - accuracy: 0.5592 - val_loss: 0.6889 - val_accuracy: 0.5000\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 3s 351ms/step - loss: 0.6896 - accuracy: 0.5224 - val_loss: 0.6875 - val_accuracy: 0.4677\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 3s 351ms/step - loss: 0.6859 - accuracy: 0.5633 - val_loss: 0.6857 - val_accuracy: 0.4516\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 3s 346ms/step - loss: 0.6860 - accuracy: 0.5796 - val_loss: 0.6832 - val_accuracy: 0.4516\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 3s 348ms/step - loss: 0.6797 - accuracy: 0.6245 - val_loss: 0.6779 - val_accuracy: 0.6452\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 3s 352ms/step - loss: 0.6793 - accuracy: 0.5714 - val_loss: 0.6748 - val_accuracy: 0.5968\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 3s 347ms/step - loss: 0.6763 - accuracy: 0.5755 - val_loss: 0.6702 - val_accuracy: 0.5484\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 3s 350ms/step - loss: 0.6713 - accuracy: 0.6041 - val_loss: 0.6653 - val_accuracy: 0.5968\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 3s 340ms/step - loss: 0.6654 - accuracy: 0.5918 - val_loss: 0.6767 - val_accuracy: 0.5323\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 3s 350ms/step - loss: 0.6612 - accuracy: 0.6245 - val_loss: 0.6614 - val_accuracy: 0.6452\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 3s 350ms/step - loss: 0.6602 - accuracy: 0.6286 - val_loss: 0.6597 - val_accuracy: 0.6613\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 3s 352ms/step - loss: 0.6483 - accuracy: 0.6449 - val_loss: 0.6668 - val_accuracy: 0.5484\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 3s 353ms/step - loss: 0.6630 - accuracy: 0.6204 - val_loss: 0.6668 - val_accuracy: 0.5484\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 3s 344ms/step - loss: 0.6587 - accuracy: 0.6245 - val_loss: 0.6647 - val_accuracy: 0.6129\n",
      "3/3 [==============================] - 1s 68ms/step\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.7264 - accuracy: 0.5450 - val_loss: 0.6503 - val_accuracy: 0.6607\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6945 - accuracy: 0.5541 - val_loss: 0.7311 - val_accuracy: 0.3393\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.7158 - accuracy: 0.5225 - val_loss: 0.6436 - val_accuracy: 0.6607\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6945 - accuracy: 0.5225 - val_loss: 0.7076 - val_accuracy: 0.3750\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6974 - accuracy: 0.4730 - val_loss: 0.6746 - val_accuracy: 0.6250\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6798 - accuracy: 0.5270 - val_loss: 0.6559 - val_accuracy: 0.6607\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 6s 539ms/step - loss: 0.6931 - accuracy: 0.4910 - val_loss: 0.6885 - val_accuracy: 0.6607\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 3s 446ms/step - loss: 0.6915 - accuracy: 0.5360 - val_loss: 0.6826 - val_accuracy: 0.6607\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 3s 447ms/step - loss: 0.6920 - accuracy: 0.5360 - val_loss: 0.6740 - val_accuracy: 0.6607\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 3s 460ms/step - loss: 0.6920 - accuracy: 0.5360 - val_loss: 0.6718 - val_accuracy: 0.6607\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 3s 462ms/step - loss: 0.6913 - accuracy: 0.5360 - val_loss: 0.6762 - val_accuracy: 0.6607\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 3s 457ms/step - loss: 0.6906 - accuracy: 0.5360 - val_loss: 0.6747 - val_accuracy: 0.6607\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 3s 456ms/step - loss: 0.6905 - accuracy: 0.5360 - val_loss: 0.6749 - val_accuracy: 0.6607\n",
      "3/3 [==============================] - 1s 78ms/step\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 0.7340 - accuracy: 0.4414 - val_loss: 0.6808 - val_accuracy: 0.6786\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7293 - accuracy: 0.5135 - val_loss: 0.6662 - val_accuracy: 0.6786\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.7174 - accuracy: 0.4955 - val_loss: 0.7070 - val_accuracy: 0.4107\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.7085 - accuracy: 0.4820 - val_loss: 0.6433 - val_accuracy: 0.6607\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7007 - accuracy: 0.5225 - val_loss: 0.6930 - val_accuracy: 0.5000\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7147 - accuracy: 0.4820 - val_loss: 0.7115 - val_accuracy: 0.3571\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6674 - accuracy: 0.5856 - val_loss: 0.6395 - val_accuracy: 0.6607\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6870 - accuracy: 0.5586 - val_loss: 0.6708 - val_accuracy: 0.6607\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6787 - accuracy: 0.6171 - val_loss: 0.7259 - val_accuracy: 0.3929\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6569 - accuracy: 0.6306 - val_loss: 0.6548 - val_accuracy: 0.6607\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 6s 539ms/step - loss: 0.6932 - accuracy: 0.5405 - val_loss: 0.6800 - val_accuracy: 0.7143\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 3s 447ms/step - loss: 0.6917 - accuracy: 0.5270 - val_loss: 0.6703 - val_accuracy: 0.7143\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 3s 451ms/step - loss: 0.6897 - accuracy: 0.5270 - val_loss: 0.6683 - val_accuracy: 0.7143\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 3s 450ms/step - loss: 0.6885 - accuracy: 0.5360 - val_loss: 0.6600 - val_accuracy: 0.6964\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 3s 465ms/step - loss: 0.6885 - accuracy: 0.5450 - val_loss: 0.6601 - val_accuracy: 0.6429\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 4s 543ms/step - loss: 0.6878 - accuracy: 0.5495 - val_loss: 0.6654 - val_accuracy: 0.6250\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 3s 454ms/step - loss: 0.6832 - accuracy: 0.5495 - val_loss: 0.6626 - val_accuracy: 0.6429\n",
      "3/3 [==============================] - 1s 78ms/step\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.7290 - accuracy: 0.5405 - val_loss: 0.6450 - val_accuracy: 0.6607\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6676 - accuracy: 0.5946 - val_loss: 0.7166 - val_accuracy: 0.3393\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7089 - accuracy: 0.5270 - val_loss: 0.6884 - val_accuracy: 0.6071\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6818 - accuracy: 0.5811 - val_loss: 0.6537 - val_accuracy: 0.6607\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 6s 541ms/step - loss: 0.6932 - accuracy: 0.4820 - val_loss: 0.6830 - val_accuracy: 0.6786\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 3s 447ms/step - loss: 0.6893 - accuracy: 0.5405 - val_loss: 0.6777 - val_accuracy: 0.6786\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 3s 446ms/step - loss: 0.6894 - accuracy: 0.5405 - val_loss: 0.6778 - val_accuracy: 0.6786\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 3s 445ms/step - loss: 0.6885 - accuracy: 0.5495 - val_loss: 0.6711 - val_accuracy: 0.6786\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 3s 450ms/step - loss: 0.6873 - accuracy: 0.5541 - val_loss: 0.6708 - val_accuracy: 0.6786\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 3s 444ms/step - loss: 0.6880 - accuracy: 0.5495 - val_loss: 0.6702 - val_accuracy: 0.6786\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 3s 456ms/step - loss: 0.6866 - accuracy: 0.5405 - val_loss: 0.6775 - val_accuracy: 0.6786\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 3s 446ms/step - loss: 0.6851 - accuracy: 0.5360 - val_loss: 0.6838 - val_accuracy: 0.6786\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 3s 455ms/step - loss: 0.6822 - accuracy: 0.5541 - val_loss: 0.6903 - val_accuracy: 0.6607\n",
      "3/3 [==============================] - 1s 79ms/step\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.7395 - accuracy: 0.4640 - val_loss: 0.7113 - val_accuracy: 0.3571\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7246 - accuracy: 0.5090 - val_loss: 0.7007 - val_accuracy: 0.4107\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6664 - accuracy: 0.5631 - val_loss: 0.6483 - val_accuracy: 0.6607\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6910 - accuracy: 0.5450 - val_loss: 0.6617 - val_accuracy: 0.6429\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6753 - accuracy: 0.5631 - val_loss: 0.6889 - val_accuracy: 0.5357\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6502 - accuracy: 0.6126 - val_loss: 0.6651 - val_accuracy: 0.6071\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 6s 553ms/step - loss: 0.6950 - accuracy: 0.4369 - val_loss: 0.6956 - val_accuracy: 0.3929\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 3s 447ms/step - loss: 0.6931 - accuracy: 0.5045 - val_loss: 0.6871 - val_accuracy: 0.6607\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 3s 443ms/step - loss: 0.6911 - accuracy: 0.5450 - val_loss: 0.6820 - val_accuracy: 0.6786\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 3s 445ms/step - loss: 0.6919 - accuracy: 0.5405 - val_loss: 0.6798 - val_accuracy: 0.6607\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 3s 445ms/step - loss: 0.6914 - accuracy: 0.5360 - val_loss: 0.6760 - val_accuracy: 0.6429\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 3s 444ms/step - loss: 0.6898 - accuracy: 0.5360 - val_loss: 0.6724 - val_accuracy: 0.6607\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 3s 435ms/step - loss: 0.6898 - accuracy: 0.5360 - val_loss: 0.6679 - val_accuracy: 0.6607\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 3s 438ms/step - loss: 0.6898 - accuracy: 0.5405 - val_loss: 0.6689 - val_accuracy: 0.6607\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 3s 446ms/step - loss: 0.6894 - accuracy: 0.5405 - val_loss: 0.6722 - val_accuracy: 0.6607\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 3s 443ms/step - loss: 0.6895 - accuracy: 0.5495 - val_loss: 0.6732 - val_accuracy: 0.6607\n",
      "3/3 [==============================] - 1s 78ms/step\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.7534 - accuracy: 0.5450 - val_loss: 0.6418 - val_accuracy: 0.6607\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7374 - accuracy: 0.5450 - val_loss: 0.6496 - val_accuracy: 0.6607\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6976 - accuracy: 0.5360 - val_loss: 0.7277 - val_accuracy: 0.3393\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6960 - accuracy: 0.5135 - val_loss: 0.6608 - val_accuracy: 0.6250\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 6s 525ms/step - loss: 0.6948 - accuracy: 0.5090 - val_loss: 0.6823 - val_accuracy: 0.6964\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 3s 451ms/step - loss: 0.6915 - accuracy: 0.5360 - val_loss: 0.6810 - val_accuracy: 0.6607\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 3s 448ms/step - loss: 0.6913 - accuracy: 0.5360 - val_loss: 0.6800 - val_accuracy: 0.6607\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 3s 457ms/step - loss: 0.6899 - accuracy: 0.5360 - val_loss: 0.6747 - val_accuracy: 0.6607\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 3s 445ms/step - loss: 0.6897 - accuracy: 0.5360 - val_loss: 0.6749 - val_accuracy: 0.6607\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 3s 449ms/step - loss: 0.6880 - accuracy: 0.5360 - val_loss: 0.6717 - val_accuracy: 0.6607\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 3s 457ms/step - loss: 0.6854 - accuracy: 0.5495 - val_loss: 0.6722 - val_accuracy: 0.6429\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 3s 458ms/step - loss: 0.6846 - accuracy: 0.5631 - val_loss: 0.6689 - val_accuracy: 0.6607\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 3s 456ms/step - loss: 0.6852 - accuracy: 0.5586 - val_loss: 0.6735 - val_accuracy: 0.6607\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 3s 446ms/step - loss: 0.6791 - accuracy: 0.5541 - val_loss: 0.6693 - val_accuracy: 0.6429\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 3s 441ms/step - loss: 0.6825 - accuracy: 0.5631 - val_loss: 0.6604 - val_accuracy: 0.6607\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 3s 442ms/step - loss: 0.6826 - accuracy: 0.5721 - val_loss: 0.6613 - val_accuracy: 0.6607\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 3s 506ms/step - loss: 0.6711 - accuracy: 0.5721 - val_loss: 0.6730 - val_accuracy: 0.5893\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 3s 472ms/step - loss: 0.6710 - accuracy: 0.5991 - val_loss: 0.6739 - val_accuracy: 0.6250\n",
      "3/3 [==============================] - 1s 77ms/step\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.7037 - accuracy: 0.5360 - val_loss: 0.7072 - val_accuracy: 0.3214\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7124 - accuracy: 0.5225 - val_loss: 0.6466 - val_accuracy: 0.6607\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6950 - accuracy: 0.5586 - val_loss: 0.7006 - val_accuracy: 0.5000\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6717 - accuracy: 0.5811 - val_loss: 0.6660 - val_accuracy: 0.6250\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.6656 - accuracy: 0.5856 - val_loss: 0.6554 - val_accuracy: 0.6250\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 7s 605ms/step - loss: 0.6954 - accuracy: 0.4730 - val_loss: 0.6843 - val_accuracy: 0.6607\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 3s 495ms/step - loss: 0.6906 - accuracy: 0.5405 - val_loss: 0.6816 - val_accuracy: 0.6607\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 3s 478ms/step - loss: 0.6919 - accuracy: 0.5360 - val_loss: 0.6780 - val_accuracy: 0.6607\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 3s 483ms/step - loss: 0.6907 - accuracy: 0.5360 - val_loss: 0.6780 - val_accuracy: 0.6607\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 3s 477ms/step - loss: 0.6889 - accuracy: 0.5405 - val_loss: 0.6753 - val_accuracy: 0.6607\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 3s 470ms/step - loss: 0.6887 - accuracy: 0.5405 - val_loss: 0.6698 - val_accuracy: 0.6607\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 3s 475ms/step - loss: 0.6885 - accuracy: 0.5495 - val_loss: 0.6708 - val_accuracy: 0.6607\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 3s 485ms/step - loss: 0.6880 - accuracy: 0.5586 - val_loss: 0.6627 - val_accuracy: 0.6429\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 3s 472ms/step - loss: 0.6869 - accuracy: 0.5450 - val_loss: 0.6638 - val_accuracy: 0.6429\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 3s 470ms/step - loss: 0.6848 - accuracy: 0.5541 - val_loss: 0.6677 - val_accuracy: 0.6607\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 3s 466ms/step - loss: 0.6811 - accuracy: 0.5676 - val_loss: 0.6686 - val_accuracy: 0.6607\n",
      "3/3 [==============================] - 1s 80ms/step\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.7151 - accuracy: 0.5090 - val_loss: 0.6449 - val_accuracy: 0.6607\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7114 - accuracy: 0.5270 - val_loss: 0.6680 - val_accuracy: 0.6429\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6762 - accuracy: 0.5811 - val_loss: 0.6929 - val_accuracy: 0.5000\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6748 - accuracy: 0.5946 - val_loss: 0.6530 - val_accuracy: 0.6607\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 6s 551ms/step - loss: 0.6935 - accuracy: 0.5360 - val_loss: 0.6905 - val_accuracy: 0.4643\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 3s 461ms/step - loss: 0.6908 - accuracy: 0.5180 - val_loss: 0.6842 - val_accuracy: 0.6607\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 3s 465ms/step - loss: 0.6896 - accuracy: 0.5405 - val_loss: 0.6813 - val_accuracy: 0.6607\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 3s 460ms/step - loss: 0.6899 - accuracy: 0.5360 - val_loss: 0.6777 - val_accuracy: 0.6607\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 3s 477ms/step - loss: 0.6894 - accuracy: 0.5360 - val_loss: 0.6764 - val_accuracy: 0.6607\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 3s 465ms/step - loss: 0.6893 - accuracy: 0.5360 - val_loss: 0.6772 - val_accuracy: 0.6607\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 3s 458ms/step - loss: 0.6892 - accuracy: 0.5360 - val_loss: 0.6729 - val_accuracy: 0.6607\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 3s 466ms/step - loss: 0.6871 - accuracy: 0.5360 - val_loss: 0.6714 - val_accuracy: 0.6607\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 3s 469ms/step - loss: 0.6901 - accuracy: 0.5360 - val_loss: 0.6712 - val_accuracy: 0.6607\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 3s 476ms/step - loss: 0.6881 - accuracy: 0.5270 - val_loss: 0.6715 - val_accuracy: 0.6607\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 3s 461ms/step - loss: 0.6869 - accuracy: 0.5315 - val_loss: 0.6715 - val_accuracy: 0.6429\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 3s 459ms/step - loss: 0.6859 - accuracy: 0.5450 - val_loss: 0.6671 - val_accuracy: 0.6429\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 3s 476ms/step - loss: 0.6821 - accuracy: 0.5541 - val_loss: 0.6525 - val_accuracy: 0.6429\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 3s 456ms/step - loss: 0.6835 - accuracy: 0.5360 - val_loss: 0.6680 - val_accuracy: 0.6429\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - 3s 465ms/step - loss: 0.6809 - accuracy: 0.5541 - val_loss: 0.6582 - val_accuracy: 0.6250\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 3s 452ms/step - loss: 0.6864 - accuracy: 0.5495 - val_loss: 0.6717 - val_accuracy: 0.6429\n",
      "3/3 [==============================] - 1s 80ms/step\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.7263 - accuracy: 0.4730 - val_loss: 0.7349 - val_accuracy: 0.3214\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7110 - accuracy: 0.4910 - val_loss: 0.6479 - val_accuracy: 0.6607\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6933 - accuracy: 0.5315 - val_loss: 0.6803 - val_accuracy: 0.5714\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6783 - accuracy: 0.5360 - val_loss: 0.6732 - val_accuracy: 0.6071\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6406 - accuracy: 0.6306 - val_loss: 0.6727 - val_accuracy: 0.5893\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 6s 526ms/step - loss: 0.6946 - accuracy: 0.4820 - val_loss: 0.6881 - val_accuracy: 0.5357\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 3s 445ms/step - loss: 0.6915 - accuracy: 0.5405 - val_loss: 0.6817 - val_accuracy: 0.6607\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 3s 442ms/step - loss: 0.6913 - accuracy: 0.5360 - val_loss: 0.6756 - val_accuracy: 0.6607\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 3s 466ms/step - loss: 0.6886 - accuracy: 0.5360 - val_loss: 0.6760 - val_accuracy: 0.6607\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 3s 448ms/step - loss: 0.6900 - accuracy: 0.5360 - val_loss: 0.6744 - val_accuracy: 0.6607\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 3s 465ms/step - loss: 0.6883 - accuracy: 0.5360 - val_loss: 0.6710 - val_accuracy: 0.6607\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 3s 445ms/step - loss: 0.6894 - accuracy: 0.5360 - val_loss: 0.6740 - val_accuracy: 0.6607\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 3s 451ms/step - loss: 0.6875 - accuracy: 0.5360 - val_loss: 0.6748 - val_accuracy: 0.6607\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 3s 448ms/step - loss: 0.6885 - accuracy: 0.5586 - val_loss: 0.6763 - val_accuracy: 0.5179\n",
      "3/3 [==============================] - 1s 77ms/step\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 0.7066 - accuracy: 0.5676 - val_loss: 0.6957 - val_accuracy: 0.4643\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7081 - accuracy: 0.5135 - val_loss: 0.6649 - val_accuracy: 0.6429\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6740 - accuracy: 0.6036 - val_loss: 0.6771 - val_accuracy: 0.6607\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6752 - accuracy: 0.5721 - val_loss: 0.6541 - val_accuracy: 0.6250\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6358 - accuracy: 0.6216 - val_loss: 0.6742 - val_accuracy: 0.5714\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6196 - accuracy: 0.6486 - val_loss: 0.6485 - val_accuracy: 0.6071\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6172 - accuracy: 0.6486 - val_loss: 0.6618 - val_accuracy: 0.5893\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6375 - accuracy: 0.6216 - val_loss: 0.7015 - val_accuracy: 0.5536\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6078 - accuracy: 0.6441 - val_loss: 0.6396 - val_accuracy: 0.5893\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5894 - accuracy: 0.6486 - val_loss: 0.6813 - val_accuracy: 0.5893\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.5787 - accuracy: 0.7117 - val_loss: 0.6728 - val_accuracy: 0.5536\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5464 - accuracy: 0.7027 - val_loss: 0.6658 - val_accuracy: 0.5893\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 6s 523ms/step - loss: 0.6941 - accuracy: 0.4550 - val_loss: 0.6884 - val_accuracy: 0.6607\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 3s 440ms/step - loss: 0.6913 - accuracy: 0.5045 - val_loss: 0.6860 - val_accuracy: 0.4821\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 3s 431ms/step - loss: 0.6903 - accuracy: 0.5090 - val_loss: 0.6814 - val_accuracy: 0.5179\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 3s 444ms/step - loss: 0.6886 - accuracy: 0.5676 - val_loss: 0.6785 - val_accuracy: 0.6607\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 3s 438ms/step - loss: 0.6892 - accuracy: 0.5135 - val_loss: 0.6743 - val_accuracy: 0.6607\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 3s 433ms/step - loss: 0.6894 - accuracy: 0.5135 - val_loss: 0.6734 - val_accuracy: 0.6607\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 3s 433ms/step - loss: 0.6873 - accuracy: 0.5225 - val_loss: 0.6708 - val_accuracy: 0.6607\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 3s 476ms/step - loss: 0.6887 - accuracy: 0.5405 - val_loss: 0.6691 - val_accuracy: 0.6607\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 3s 443ms/step - loss: 0.6868 - accuracy: 0.5360 - val_loss: 0.6692 - val_accuracy: 0.6607\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 3s 437ms/step - loss: 0.6843 - accuracy: 0.5495 - val_loss: 0.6670 - val_accuracy: 0.6607\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 3s 491ms/step - loss: 0.6854 - accuracy: 0.5135 - val_loss: 0.6689 - val_accuracy: 0.6071\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 3s 501ms/step - loss: 0.6842 - accuracy: 0.5631 - val_loss: 0.6685 - val_accuracy: 0.5893\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 4s 531ms/step - loss: 0.6834 - accuracy: 0.5631 - val_loss: 0.6605 - val_accuracy: 0.6071\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 3s 447ms/step - loss: 0.6856 - accuracy: 0.5450 - val_loss: 0.6446 - val_accuracy: 0.6429\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - 3s 451ms/step - loss: 0.6835 - accuracy: 0.5586 - val_loss: 0.6603 - val_accuracy: 0.6071\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 3s 448ms/step - loss: 0.6822 - accuracy: 0.5676 - val_loss: 0.6713 - val_accuracy: 0.5357\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 3s 455ms/step - loss: 0.6810 - accuracy: 0.5901 - val_loss: 0.6684 - val_accuracy: 0.6250\n",
      "3/3 [==============================] - 1s 76ms/step\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.7354 - accuracy: 0.4640 - val_loss: 0.7538 - val_accuracy: 0.3393\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7207 - accuracy: 0.5225 - val_loss: 0.6331 - val_accuracy: 0.6607\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6861 - accuracy: 0.5360 - val_loss: 0.6554 - val_accuracy: 0.6429\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6680 - accuracy: 0.6036 - val_loss: 0.6436 - val_accuracy: 0.6071\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.6038 - accuracy: 0.7162 - val_loss: 0.6250 - val_accuracy: 0.6250\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6066 - accuracy: 0.7207 - val_loss: 0.6156 - val_accuracy: 0.6071\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5670 - accuracy: 0.7117 - val_loss: 0.5940 - val_accuracy: 0.6607\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5505 - accuracy: 0.7523 - val_loss: 0.5895 - val_accuracy: 0.6964\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4892 - accuracy: 0.8243 - val_loss: 0.5698 - val_accuracy: 0.7143\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4786 - accuracy: 0.7883 - val_loss: 0.5772 - val_accuracy: 0.6964\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4566 - accuracy: 0.8108 - val_loss: 0.5353 - val_accuracy: 0.7321\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4172 - accuracy: 0.8423 - val_loss: 0.5700 - val_accuracy: 0.6786\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4070 - accuracy: 0.8243 - val_loss: 0.5597 - val_accuracy: 0.6786\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3738 - accuracy: 0.8378 - val_loss: 0.5217 - val_accuracy: 0.7500\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3424 - accuracy: 0.8919 - val_loss: 0.5542 - val_accuracy: 0.6607\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3436 - accuracy: 0.8649 - val_loss: 0.5470 - val_accuracy: 0.6786\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3012 - accuracy: 0.8919 - val_loss: 0.5197 - val_accuracy: 0.7321\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2997 - accuracy: 0.8739 - val_loss: 0.5613 - val_accuracy: 0.6786\n",
      "Epoch 19/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3039 - accuracy: 0.8919 - val_loss: 0.5448 - val_accuracy: 0.7500\n",
      "Epoch 20/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3065 - accuracy: 0.8829 - val_loss: 0.5668 - val_accuracy: 0.7143\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 7s 602ms/step - loss: 0.6936 - accuracy: 0.4955 - val_loss: 0.6865 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 4s 518ms/step - loss: 0.6890 - accuracy: 0.5676 - val_loss: 0.6797 - val_accuracy: 0.6429\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 4s 526ms/step - loss: 0.6889 - accuracy: 0.5405 - val_loss: 0.6720 - val_accuracy: 0.6607\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 4s 573ms/step - loss: 0.6848 - accuracy: 0.5270 - val_loss: 0.6680 - val_accuracy: 0.6429\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 4s 574ms/step - loss: 0.6849 - accuracy: 0.5541 - val_loss: 0.6662 - val_accuracy: 0.6429\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 4s 543ms/step - loss: 0.6847 - accuracy: 0.5676 - val_loss: 0.6566 - val_accuracy: 0.6429\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 4s 539ms/step - loss: 0.6816 - accuracy: 0.5541 - val_loss: 0.6527 - val_accuracy: 0.6607\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 4s 550ms/step - loss: 0.6789 - accuracy: 0.5946 - val_loss: 0.6479 - val_accuracy: 0.6607\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 4s 532ms/step - loss: 0.6770 - accuracy: 0.5721 - val_loss: 0.6415 - val_accuracy: 0.6607\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 4s 526ms/step - loss: 0.6776 - accuracy: 0.6036 - val_loss: 0.6487 - val_accuracy: 0.6786\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 4s 547ms/step - loss: 0.6730 - accuracy: 0.6261 - val_loss: 0.6442 - val_accuracy: 0.6607\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 4s 563ms/step - loss: 0.6789 - accuracy: 0.5766 - val_loss: 0.6460 - val_accuracy: 0.6607\n",
      "3/3 [==============================] - 1s 94ms/step\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7523 - accuracy: 0.4766 - val_loss: 0.6889 - val_accuracy: 0.5556\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7202 - accuracy: 0.5514 - val_loss: 0.7146 - val_accuracy: 0.4444\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6986 - accuracy: 0.5327 - val_loss: 0.6876 - val_accuracy: 0.4815\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7352 - accuracy: 0.4579 - val_loss: 0.6793 - val_accuracy: 0.6296\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7204 - accuracy: 0.5421 - val_loss: 0.6765 - val_accuracy: 0.5556\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6970 - accuracy: 0.5514 - val_loss: 0.6743 - val_accuracy: 0.6296\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6732 - accuracy: 0.5981 - val_loss: 0.6870 - val_accuracy: 0.5185\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6830 - accuracy: 0.5327 - val_loss: 0.6868 - val_accuracy: 0.5185\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6668 - accuracy: 0.6262 - val_loss: 0.6658 - val_accuracy: 0.6667\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6923 - accuracy: 0.5607 - val_loss: 0.6602 - val_accuracy: 0.6296\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6540 - accuracy: 0.5981 - val_loss: 0.6568 - val_accuracy: 0.6296\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6990 - accuracy: 0.4766 - val_loss: 0.6536 - val_accuracy: 0.6296\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6727 - accuracy: 0.5888 - val_loss: 0.6517 - val_accuracy: 0.6667\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6597 - accuracy: 0.5607 - val_loss: 0.6532 - val_accuracy: 0.6296\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6490 - accuracy: 0.6355 - val_loss: 0.6508 - val_accuracy: 0.6667\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6671 - accuracy: 0.5514 - val_loss: 0.6448 - val_accuracy: 0.6667\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6397 - accuracy: 0.6355 - val_loss: 0.6386 - val_accuracy: 0.6667\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6293 - accuracy: 0.6729 - val_loss: 0.6353 - val_accuracy: 0.6667\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6466 - accuracy: 0.6075 - val_loss: 0.6291 - val_accuracy: 0.6296\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6312 - accuracy: 0.6262 - val_loss: 0.6296 - val_accuracy: 0.7407\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6410 - accuracy: 0.5981 - val_loss: 0.6315 - val_accuracy: 0.7407\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6002 - accuracy: 0.6822 - val_loss: 0.6280 - val_accuracy: 0.7407\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6374 - accuracy: 0.6636 - val_loss: 0.6230 - val_accuracy: 0.7407\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6291 - accuracy: 0.6822 - val_loss: 0.6223 - val_accuracy: 0.6296\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6113 - accuracy: 0.7290 - val_loss: 0.6246 - val_accuracy: 0.6296\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6356 - accuracy: 0.6355 - val_loss: 0.6195 - val_accuracy: 0.6667\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5991 - accuracy: 0.6822 - val_loss: 0.6179 - val_accuracy: 0.7407\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6185 - accuracy: 0.6355 - val_loss: 0.6160 - val_accuracy: 0.7407\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.6092 - accuracy: 0.6822 - val_loss: 0.6150 - val_accuracy: 0.6667\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5954 - accuracy: 0.7009 - val_loss: 0.6130 - val_accuracy: 0.7407\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5981 - accuracy: 0.6729 - val_loss: 0.6121 - val_accuracy: 0.7407\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6266 - accuracy: 0.6636 - val_loss: 0.6129 - val_accuracy: 0.6667\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5921 - accuracy: 0.7009 - val_loss: 0.6124 - val_accuracy: 0.7407\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5884 - accuracy: 0.6916 - val_loss: 0.6107 - val_accuracy: 0.7407\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5781 - accuracy: 0.7290 - val_loss: 0.6116 - val_accuracy: 0.6667\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5885 - accuracy: 0.7477 - val_loss: 0.6075 - val_accuracy: 0.7407\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5717 - accuracy: 0.7196 - val_loss: 0.6085 - val_accuracy: 0.7037\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5678 - accuracy: 0.7196 - val_loss: 0.6117 - val_accuracy: 0.6667\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5944 - accuracy: 0.6916 - val_loss: 0.6111 - val_accuracy: 0.6667\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 4s 385ms/step - loss: 0.6939 - accuracy: 0.4393 - val_loss: 0.6929 - val_accuracy: 0.5556\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 1s 215ms/step - loss: 0.6923 - accuracy: 0.5607 - val_loss: 0.6919 - val_accuracy: 0.5556\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 1s 217ms/step - loss: 0.6915 - accuracy: 0.5514 - val_loss: 0.6910 - val_accuracy: 0.5556\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.6899 - accuracy: 0.5514 - val_loss: 0.6904 - val_accuracy: 0.5556\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 1s 217ms/step - loss: 0.6884 - accuracy: 0.5514 - val_loss: 0.6890 - val_accuracy: 0.5556\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 1s 215ms/step - loss: 0.6871 - accuracy: 0.5514 - val_loss: 0.6873 - val_accuracy: 0.5556\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.6868 - accuracy: 0.5514 - val_loss: 0.6867 - val_accuracy: 0.5556\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 0.6856 - accuracy: 0.5514 - val_loss: 0.6868 - val_accuracy: 0.5556\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.6865 - accuracy: 0.5701 - val_loss: 0.6867 - val_accuracy: 0.5556\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 1s 260ms/step - loss: 0.6840 - accuracy: 0.5701 - val_loss: 0.6865 - val_accuracy: 0.5556\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 1s 213ms/step - loss: 0.6834 - accuracy: 0.5701 - val_loss: 0.6856 - val_accuracy: 0.5556\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 1s 217ms/step - loss: 0.6861 - accuracy: 0.5701 - val_loss: 0.6853 - val_accuracy: 0.5556\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.6850 - accuracy: 0.5701 - val_loss: 0.6864 - val_accuracy: 0.5556\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.6859 - accuracy: 0.5701 - val_loss: 0.6877 - val_accuracy: 0.5556\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 1s 272ms/step - loss: 0.6827 - accuracy: 0.5701 - val_loss: 0.6881 - val_accuracy: 0.5556\n",
      "2/2 [==============================] - 1s 17ms/step\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 1s 50ms/step - loss: 0.7472 - accuracy: 0.4953 - val_loss: 0.6956 - val_accuracy: 0.5556\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7425 - accuracy: 0.5140 - val_loss: 0.6870 - val_accuracy: 0.5556\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7228 - accuracy: 0.4673 - val_loss: 0.6833 - val_accuracy: 0.5556\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7113 - accuracy: 0.4486 - val_loss: 0.6787 - val_accuracy: 0.7037\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6752 - accuracy: 0.5607 - val_loss: 0.6758 - val_accuracy: 0.5926\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6576 - accuracy: 0.6075 - val_loss: 0.6744 - val_accuracy: 0.6667\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6619 - accuracy: 0.5514 - val_loss: 0.6735 - val_accuracy: 0.6667\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6410 - accuracy: 0.6355 - val_loss: 0.6729 - val_accuracy: 0.6667\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.6645 - accuracy: 0.6168 - val_loss: 0.6746 - val_accuracy: 0.5556\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6657 - accuracy: 0.6168 - val_loss: 0.6687 - val_accuracy: 0.7037\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6387 - accuracy: 0.6075 - val_loss: 0.6666 - val_accuracy: 0.6667\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.6827 - accuracy: 0.5421 - val_loss: 0.6638 - val_accuracy: 0.7037\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6428 - accuracy: 0.5981 - val_loss: 0.6624 - val_accuracy: 0.7037\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6363 - accuracy: 0.5888 - val_loss: 0.6651 - val_accuracy: 0.5926\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6426 - accuracy: 0.6168 - val_loss: 0.6652 - val_accuracy: 0.5926\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6397 - accuracy: 0.6636 - val_loss: 0.6585 - val_accuracy: 0.6296\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6297 - accuracy: 0.5981 - val_loss: 0.6527 - val_accuracy: 0.7407\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5954 - accuracy: 0.6262 - val_loss: 0.6520 - val_accuracy: 0.7037\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6120 - accuracy: 0.6916 - val_loss: 0.6527 - val_accuracy: 0.7407\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6055 - accuracy: 0.6355 - val_loss: 0.6484 - val_accuracy: 0.7407\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5927 - accuracy: 0.6916 - val_loss: 0.6477 - val_accuracy: 0.7407\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5918 - accuracy: 0.6636 - val_loss: 0.6468 - val_accuracy: 0.7407\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.6226 - accuracy: 0.6542 - val_loss: 0.6453 - val_accuracy: 0.7407\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5829 - accuracy: 0.6542 - val_loss: 0.6457 - val_accuracy: 0.6296\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5599 - accuracy: 0.7009 - val_loss: 0.6462 - val_accuracy: 0.7407\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5334 - accuracy: 0.7664 - val_loss: 0.6493 - val_accuracy: 0.7778\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 4s 408ms/step - loss: 0.6935 - accuracy: 0.4486 - val_loss: 0.6923 - val_accuracy: 0.5556\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 1s 221ms/step - loss: 0.6926 - accuracy: 0.5421 - val_loss: 0.6913 - val_accuracy: 0.5556\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.6921 - accuracy: 0.5421 - val_loss: 0.6909 - val_accuracy: 0.5556\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.6909 - accuracy: 0.5421 - val_loss: 0.6901 - val_accuracy: 0.5556\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 1s 251ms/step - loss: 0.6910 - accuracy: 0.5421 - val_loss: 0.6893 - val_accuracy: 0.5556\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 1s 293ms/step - loss: 0.6911 - accuracy: 0.5421 - val_loss: 0.6893 - val_accuracy: 0.5556\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.6897 - accuracy: 0.5421 - val_loss: 0.6893 - val_accuracy: 0.5556\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 1s 214ms/step - loss: 0.6890 - accuracy: 0.5421 - val_loss: 0.6894 - val_accuracy: 0.5556\n",
      "2/2 [==============================] - 1s 17ms/step\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7437 - accuracy: 0.5234 - val_loss: 0.6863 - val_accuracy: 0.5556\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7306 - accuracy: 0.4579 - val_loss: 0.6938 - val_accuracy: 0.5185\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7087 - accuracy: 0.5327 - val_loss: 0.7067 - val_accuracy: 0.4444\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6883 - accuracy: 0.5701 - val_loss: 0.6741 - val_accuracy: 0.5926\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6949 - accuracy: 0.5140 - val_loss: 0.6827 - val_accuracy: 0.5556\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7014 - accuracy: 0.5327 - val_loss: 0.6830 - val_accuracy: 0.5556\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6603 - accuracy: 0.5888 - val_loss: 0.6640 - val_accuracy: 0.6296\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6640 - accuracy: 0.5701 - val_loss: 0.6799 - val_accuracy: 0.5185\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6757 - accuracy: 0.5327 - val_loss: 0.6771 - val_accuracy: 0.5185\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.6643 - accuracy: 0.5701 - val_loss: 0.6592 - val_accuracy: 0.5926\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6397 - accuracy: 0.6355 - val_loss: 0.6534 - val_accuracy: 0.6667\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6573 - accuracy: 0.6449 - val_loss: 0.6495 - val_accuracy: 0.7037\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6158 - accuracy: 0.6729 - val_loss: 0.6474 - val_accuracy: 0.6296\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6130 - accuracy: 0.6729 - val_loss: 0.6437 - val_accuracy: 0.6667\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6352 - accuracy: 0.5888 - val_loss: 0.6396 - val_accuracy: 0.6667\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5927 - accuracy: 0.7103 - val_loss: 0.6359 - val_accuracy: 0.6667\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6069 - accuracy: 0.7290 - val_loss: 0.6348 - val_accuracy: 0.6667\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5887 - accuracy: 0.6729 - val_loss: 0.6284 - val_accuracy: 0.6667\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5969 - accuracy: 0.6542 - val_loss: 0.6257 - val_accuracy: 0.7037\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5642 - accuracy: 0.7477 - val_loss: 0.6220 - val_accuracy: 0.7037\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5652 - accuracy: 0.7290 - val_loss: 0.6195 - val_accuracy: 0.7407\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5765 - accuracy: 0.6729 - val_loss: 0.6213 - val_accuracy: 0.6667\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5546 - accuracy: 0.7009 - val_loss: 0.6181 - val_accuracy: 0.7037\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5385 - accuracy: 0.7196 - val_loss: 0.6148 - val_accuracy: 0.6667\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5384 - accuracy: 0.7290 - val_loss: 0.6187 - val_accuracy: 0.6667\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.5330 - accuracy: 0.6916 - val_loss: 0.6192 - val_accuracy: 0.6667\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5380 - accuracy: 0.7570 - val_loss: 0.6165 - val_accuracy: 0.6667\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 4s 401ms/step - loss: 0.6923 - accuracy: 0.4860 - val_loss: 0.6913 - val_accuracy: 0.4815\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 0.6918 - accuracy: 0.5327 - val_loss: 0.6898 - val_accuracy: 0.5556\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.6934 - accuracy: 0.5327 - val_loss: 0.6880 - val_accuracy: 0.5556\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.6902 - accuracy: 0.5327 - val_loss: 0.6877 - val_accuracy: 0.5556\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.6889 - accuracy: 0.5327 - val_loss: 0.6874 - val_accuracy: 0.5556\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 0.6902 - accuracy: 0.5327 - val_loss: 0.6873 - val_accuracy: 0.5556\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 1s 283ms/step - loss: 0.6906 - accuracy: 0.5327 - val_loss: 0.6865 - val_accuracy: 0.5556\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.6896 - accuracy: 0.5327 - val_loss: 0.6861 - val_accuracy: 0.5556\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.6883 - accuracy: 0.5327 - val_loss: 0.6851 - val_accuracy: 0.5556\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.6885 - accuracy: 0.5327 - val_loss: 0.6842 - val_accuracy: 0.5556\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.6898 - accuracy: 0.5327 - val_loss: 0.6841 - val_accuracy: 0.5556\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.6882 - accuracy: 0.5327 - val_loss: 0.6839 - val_accuracy: 0.5556\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.6871 - accuracy: 0.5327 - val_loss: 0.6839 - val_accuracy: 0.5556\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 1s 254ms/step - loss: 0.6896 - accuracy: 0.5327 - val_loss: 0.6837 - val_accuracy: 0.5556\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.6878 - accuracy: 0.5327 - val_loss: 0.6839 - val_accuracy: 0.5556\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.6863 - accuracy: 0.5327 - val_loss: 0.6842 - val_accuracy: 0.5556\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.6885 - accuracy: 0.5327 - val_loss: 0.6840 - val_accuracy: 0.5556\n",
      "2/2 [==============================] - 1s 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhin\\anaconda3\\envs\\DevelopmentEnv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7328 - accuracy: 0.4860 - val_loss: 0.6926 - val_accuracy: 0.5556\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7155 - accuracy: 0.5421 - val_loss: 0.6856 - val_accuracy: 0.5556\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6819 - accuracy: 0.5514 - val_loss: 0.6824 - val_accuracy: 0.5926\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6809 - accuracy: 0.6075 - val_loss: 0.6836 - val_accuracy: 0.4815\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6622 - accuracy: 0.6075 - val_loss: 0.6768 - val_accuracy: 0.5926\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6626 - accuracy: 0.6075 - val_loss: 0.6752 - val_accuracy: 0.5556\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6315 - accuracy: 0.6075 - val_loss: 0.6750 - val_accuracy: 0.5556\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6365 - accuracy: 0.6168 - val_loss: 0.6721 - val_accuracy: 0.6667\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6405 - accuracy: 0.6168 - val_loss: 0.6798 - val_accuracy: 0.4815\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5933 - accuracy: 0.6449 - val_loss: 0.6702 - val_accuracy: 0.5926\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6039 - accuracy: 0.6262 - val_loss: 0.6757 - val_accuracy: 0.5926\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6103 - accuracy: 0.6636 - val_loss: 0.6746 - val_accuracy: 0.5926\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5840 - accuracy: 0.7009 - val_loss: 0.6719 - val_accuracy: 0.5185\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 3s 386ms/step - loss: 0.6913 - accuracy: 0.5327 - val_loss: 0.6889 - val_accuracy: 0.5556\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 1s 210ms/step - loss: 0.6918 - accuracy: 0.5234 - val_loss: 0.6834 - val_accuracy: 0.5556\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 1s 218ms/step - loss: 0.6873 - accuracy: 0.5047 - val_loss: 0.6798 - val_accuracy: 0.5556\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 1s 215ms/step - loss: 0.6897 - accuracy: 0.5607 - val_loss: 0.6777 - val_accuracy: 0.5185\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 1s 218ms/step - loss: 0.6881 - accuracy: 0.5701 - val_loss: 0.6766 - val_accuracy: 0.5185\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 1s 215ms/step - loss: 0.6841 - accuracy: 0.5701 - val_loss: 0.6759 - val_accuracy: 0.5185\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 1s 209ms/step - loss: 0.6872 - accuracy: 0.5701 - val_loss: 0.6760 - val_accuracy: 0.5185\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 1s 210ms/step - loss: 0.6859 - accuracy: 0.5514 - val_loss: 0.6766 - val_accuracy: 0.5185\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 1s 215ms/step - loss: 0.6857 - accuracy: 0.5421 - val_loss: 0.6749 - val_accuracy: 0.5185\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 1s 221ms/step - loss: 0.6845 - accuracy: 0.5888 - val_loss: 0.6748 - val_accuracy: 0.5185\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 0.6848 - accuracy: 0.5701 - val_loss: 0.6734 - val_accuracy: 0.5185\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 0.6782 - accuracy: 0.5981 - val_loss: 0.6731 - val_accuracy: 0.5185\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 0.6782 - accuracy: 0.5794 - val_loss: 0.6713 - val_accuracy: 0.6296\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 0.6779 - accuracy: 0.5327 - val_loss: 0.6685 - val_accuracy: 0.6296\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.6759 - accuracy: 0.5981 - val_loss: 0.6639 - val_accuracy: 0.6296\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.6716 - accuracy: 0.5794 - val_loss: 0.6596 - val_accuracy: 0.5185\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.6650 - accuracy: 0.6075 - val_loss: 0.6441 - val_accuracy: 0.6296\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.6519 - accuracy: 0.6449 - val_loss: 0.5909 - val_accuracy: 0.7407\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 0.6267 - accuracy: 0.6449 - val_loss: 0.5867 - val_accuracy: 0.6667\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.6183 - accuracy: 0.6542 - val_loss: 0.6024 - val_accuracy: 0.5926\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.6179 - accuracy: 0.6449 - val_loss: 0.6143 - val_accuracy: 0.5926\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 1s 207ms/step - loss: 0.6061 - accuracy: 0.6542 - val_loss: 0.6329 - val_accuracy: 0.5926\n",
      "2/2 [==============================] - 1s 17ms/step\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 1s 46ms/step - loss: 0.9064 - accuracy: 0.4953 - val_loss: 0.6872 - val_accuracy: 0.5556\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6909 - accuracy: 0.5888 - val_loss: 0.7384 - val_accuracy: 0.5556\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7749 - accuracy: 0.5234 - val_loss: 0.7047 - val_accuracy: 0.5556\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6781 - accuracy: 0.5607 - val_loss: 0.6701 - val_accuracy: 0.6296\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.6589 - accuracy: 0.6075 - val_loss: 0.6838 - val_accuracy: 0.4444\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6601 - accuracy: 0.6449 - val_loss: 0.6843 - val_accuracy: 0.4444\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6263 - accuracy: 0.6636 - val_loss: 0.6637 - val_accuracy: 0.6667\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6263 - accuracy: 0.6542 - val_loss: 0.6718 - val_accuracy: 0.5926\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6372 - accuracy: 0.6168 - val_loss: 0.6703 - val_accuracy: 0.5926\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.6345 - accuracy: 0.6168 - val_loss: 0.6598 - val_accuracy: 0.6667\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6200 - accuracy: 0.6729 - val_loss: 0.6644 - val_accuracy: 0.4444\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6349 - accuracy: 0.6636 - val_loss: 0.6627 - val_accuracy: 0.4444\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6141 - accuracy: 0.6262 - val_loss: 0.6587 - val_accuracy: 0.7037\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6420 - accuracy: 0.6449 - val_loss: 0.6589 - val_accuracy: 0.6667\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5403 - accuracy: 0.7944 - val_loss: 0.6573 - val_accuracy: 0.7037\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5768 - accuracy: 0.6449 - val_loss: 0.6576 - val_accuracy: 0.7037\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5519 - accuracy: 0.7290 - val_loss: 0.6594 - val_accuracy: 0.6296\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5633 - accuracy: 0.6542 - val_loss: 0.6602 - val_accuracy: 0.6296\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 4s 433ms/step - loss: 0.6896 - accuracy: 0.5327 - val_loss: 0.6838 - val_accuracy: 0.4815\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 1s 220ms/step - loss: 0.6868 - accuracy: 0.5047 - val_loss: 0.6815 - val_accuracy: 0.5185\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 1s 214ms/step - loss: 0.6854 - accuracy: 0.5514 - val_loss: 0.6798 - val_accuracy: 0.5556\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 1s 220ms/step - loss: 0.6852 - accuracy: 0.5421 - val_loss: 0.6796 - val_accuracy: 0.5556\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 1s 220ms/step - loss: 0.6839 - accuracy: 0.5140 - val_loss: 0.6790 - val_accuracy: 0.5556\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 1s 258ms/step - loss: 0.6838 - accuracy: 0.5514 - val_loss: 0.6790 - val_accuracy: 0.5556\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 0.6853 - accuracy: 0.5047 - val_loss: 0.6805 - val_accuracy: 0.5556\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.6833 - accuracy: 0.5421 - val_loss: 0.6801 - val_accuracy: 0.5556\n",
      "2/2 [==============================] - 1s 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhin\\anaconda3\\envs\\DevelopmentEnv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7416 - accuracy: 0.4579 - val_loss: 0.6919 - val_accuracy: 0.5556\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6756 - accuracy: 0.5327 - val_loss: 0.6878 - val_accuracy: 0.5556\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6729 - accuracy: 0.5888 - val_loss: 0.6855 - val_accuracy: 0.4815\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6805 - accuracy: 0.5514 - val_loss: 0.6800 - val_accuracy: 0.5926\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6459 - accuracy: 0.5701 - val_loss: 0.6793 - val_accuracy: 0.5185\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6500 - accuracy: 0.5701 - val_loss: 0.6796 - val_accuracy: 0.5185\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6377 - accuracy: 0.5794 - val_loss: 0.6799 - val_accuracy: 0.5185\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6106 - accuracy: 0.6822 - val_loss: 0.6830 - val_accuracy: 0.5556\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 4s 396ms/step - loss: 0.6934 - accuracy: 0.4953 - val_loss: 0.6824 - val_accuracy: 0.5185\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.6888 - accuracy: 0.5794 - val_loss: 0.6763 - val_accuracy: 0.4815\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.6857 - accuracy: 0.5981 - val_loss: 0.6727 - val_accuracy: 0.5185\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 1s 220ms/step - loss: 0.6819 - accuracy: 0.5514 - val_loss: 0.6696 - val_accuracy: 0.5556\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.6827 - accuracy: 0.5514 - val_loss: 0.6682 - val_accuracy: 0.5185\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.6822 - accuracy: 0.5981 - val_loss: 0.6681 - val_accuracy: 0.5185\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.6826 - accuracy: 0.6075 - val_loss: 0.6678 - val_accuracy: 0.5185\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 1s 322ms/step - loss: 0.6775 - accuracy: 0.6075 - val_loss: 0.6673 - val_accuracy: 0.5185\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.6782 - accuracy: 0.6168 - val_loss: 0.6680 - val_accuracy: 0.5556\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 1s 218ms/step - loss: 0.6800 - accuracy: 0.5981 - val_loss: 0.6695 - val_accuracy: 0.5556\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 1s 216ms/step - loss: 0.6742 - accuracy: 0.5607 - val_loss: 0.6706 - val_accuracy: 0.5556\n",
      "2/2 [==============================] - 1s 17ms/step\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.8286 - accuracy: 0.4579 - val_loss: 0.6758 - val_accuracy: 0.5556\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7403 - accuracy: 0.4860 - val_loss: 0.7125 - val_accuracy: 0.5556\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6975 - accuracy: 0.5421 - val_loss: 0.6807 - val_accuracy: 0.5556\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6716 - accuracy: 0.5607 - val_loss: 0.6687 - val_accuracy: 0.5185\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6589 - accuracy: 0.6262 - val_loss: 0.6822 - val_accuracy: 0.5556\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6841 - accuracy: 0.5794 - val_loss: 0.6754 - val_accuracy: 0.5556\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6615 - accuracy: 0.6262 - val_loss: 0.6635 - val_accuracy: 0.5556\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6384 - accuracy: 0.6449 - val_loss: 0.6613 - val_accuracy: 0.5556\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6266 - accuracy: 0.6729 - val_loss: 0.6601 - val_accuracy: 0.5926\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6410 - accuracy: 0.6168 - val_loss: 0.6597 - val_accuracy: 0.5185\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6202 - accuracy: 0.6542 - val_loss: 0.6607 - val_accuracy: 0.5556\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6305 - accuracy: 0.6449 - val_loss: 0.6605 - val_accuracy: 0.5556\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5821 - accuracy: 0.7383 - val_loss: 0.6614 - val_accuracy: 0.5556\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 4s 383ms/step - loss: 0.6955 - accuracy: 0.4579 - val_loss: 0.6894 - val_accuracy: 0.5556\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 1s 219ms/step - loss: 0.6888 - accuracy: 0.5140 - val_loss: 0.6833 - val_accuracy: 0.5185\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.6830 - accuracy: 0.5607 - val_loss: 0.6788 - val_accuracy: 0.4444\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.6853 - accuracy: 0.5514 - val_loss: 0.6774 - val_accuracy: 0.4444\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.6841 - accuracy: 0.5607 - val_loss: 0.6754 - val_accuracy: 0.4444\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 0.6791 - accuracy: 0.5607 - val_loss: 0.6743 - val_accuracy: 0.4444\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.6802 - accuracy: 0.5327 - val_loss: 0.6743 - val_accuracy: 0.5556\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 1s 217ms/step - loss: 0.6798 - accuracy: 0.6262 - val_loss: 0.6743 - val_accuracy: 0.5556\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 1s 205ms/step - loss: 0.6792 - accuracy: 0.6355 - val_loss: 0.6754 - val_accuracy: 0.5556\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 1s 205ms/step - loss: 0.6779 - accuracy: 0.6262 - val_loss: 0.6754 - val_accuracy: 0.5556\n",
      "2/2 [==============================] - 1s 15ms/step\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 1s 45ms/step - loss: 0.7325 - accuracy: 0.5140 - val_loss: 0.6962 - val_accuracy: 0.5556\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7148 - accuracy: 0.5607 - val_loss: 0.6823 - val_accuracy: 0.5556\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6754 - accuracy: 0.5047 - val_loss: 0.6887 - val_accuracy: 0.4815\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6773 - accuracy: 0.5794 - val_loss: 0.6929 - val_accuracy: 0.4815\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6610 - accuracy: 0.5981 - val_loss: 0.6754 - val_accuracy: 0.5926\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6455 - accuracy: 0.5981 - val_loss: 0.6818 - val_accuracy: 0.5926\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6411 - accuracy: 0.5701 - val_loss: 0.6773 - val_accuracy: 0.5926\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6306 - accuracy: 0.6822 - val_loss: 0.6789 - val_accuracy: 0.5185\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 4s 394ms/step - loss: 0.6932 - accuracy: 0.5701 - val_loss: 0.6904 - val_accuracy: 0.4815\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 1s 206ms/step - loss: 0.6899 - accuracy: 0.5327 - val_loss: 0.6870 - val_accuracy: 0.4815\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 1s 218ms/step - loss: 0.6843 - accuracy: 0.5607 - val_loss: 0.6845 - val_accuracy: 0.4815\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 0.6830 - accuracy: 0.5421 - val_loss: 0.6816 - val_accuracy: 0.4815\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.6781 - accuracy: 0.5514 - val_loss: 0.6789 - val_accuracy: 0.4815\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.6796 - accuracy: 0.5421 - val_loss: 0.6790 - val_accuracy: 0.4815\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.6822 - accuracy: 0.5514 - val_loss: 0.6804 - val_accuracy: 0.4815\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.6808 - accuracy: 0.5421 - val_loss: 0.6810 - val_accuracy: 0.4815\n",
      "2/2 [==============================] - 1s 19ms/step\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7719 - accuracy: 0.5234 - val_loss: 0.6844 - val_accuracy: 0.5556\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7671 - accuracy: 0.5140 - val_loss: 0.7126 - val_accuracy: 0.5556\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6555 - accuracy: 0.5888 - val_loss: 0.6729 - val_accuracy: 0.6296\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7017 - accuracy: 0.4953 - val_loss: 0.6957 - val_accuracy: 0.4444\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6798 - accuracy: 0.5888 - val_loss: 0.7008 - val_accuracy: 0.4815\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6815 - accuracy: 0.5514 - val_loss: 0.6744 - val_accuracy: 0.4815\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 4s 396ms/step - loss: 0.6912 - accuracy: 0.5701 - val_loss: 0.6878 - val_accuracy: 0.4444\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 1s 205ms/step - loss: 0.6844 - accuracy: 0.5421 - val_loss: 0.6848 - val_accuracy: 0.4815\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 1s 207ms/step - loss: 0.6833 - accuracy: 0.5514 - val_loss: 0.6821 - val_accuracy: 0.4815\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 1s 214ms/step - loss: 0.6803 - accuracy: 0.5327 - val_loss: 0.6811 - val_accuracy: 0.4815\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.6798 - accuracy: 0.5327 - val_loss: 0.6806 - val_accuracy: 0.4815\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 1s 218ms/step - loss: 0.6774 - accuracy: 0.5421 - val_loss: 0.6812 - val_accuracy: 0.5926\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.6834 - accuracy: 0.4766 - val_loss: 0.6831 - val_accuracy: 0.5185\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 1s 218ms/step - loss: 0.6776 - accuracy: 0.5234 - val_loss: 0.6855 - val_accuracy: 0.4815\n",
      "2/2 [==============================] - 1s 16ms/step\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7460 - accuracy: 0.5234 - val_loss: 0.7071 - val_accuracy: 0.4815\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7169 - accuracy: 0.5234 - val_loss: 0.7148 - val_accuracy: 0.5185\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6723 - accuracy: 0.5888 - val_loss: 0.6680 - val_accuracy: 0.5926\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6532 - accuracy: 0.6168 - val_loss: 0.6683 - val_accuracy: 0.5556\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6319 - accuracy: 0.6075 - val_loss: 0.6572 - val_accuracy: 0.6667\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6321 - accuracy: 0.6729 - val_loss: 0.6554 - val_accuracy: 0.5185\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5865 - accuracy: 0.7290 - val_loss: 0.6497 - val_accuracy: 0.5185\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5923 - accuracy: 0.7196 - val_loss: 0.6471 - val_accuracy: 0.5185\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5943 - accuracy: 0.6822 - val_loss: 0.6425 - val_accuracy: 0.5185\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5489 - accuracy: 0.7664 - val_loss: 0.6303 - val_accuracy: 0.6296\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.5477 - accuracy: 0.7290 - val_loss: 0.6208 - val_accuracy: 0.6667\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5098 - accuracy: 0.7290 - val_loss: 0.6136 - val_accuracy: 0.7037\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5297 - accuracy: 0.7290 - val_loss: 0.6038 - val_accuracy: 0.7037\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4990 - accuracy: 0.8037 - val_loss: 0.5933 - val_accuracy: 0.6667\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4796 - accuracy: 0.8131 - val_loss: 0.5790 - val_accuracy: 0.7407\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4382 - accuracy: 0.8505 - val_loss: 0.5732 - val_accuracy: 0.7407\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4537 - accuracy: 0.8131 - val_loss: 0.5628 - val_accuracy: 0.7037\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4415 - accuracy: 0.8131 - val_loss: 0.5492 - val_accuracy: 0.7407\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3865 - accuracy: 0.8692 - val_loss: 0.5420 - val_accuracy: 0.7407\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3792 - accuracy: 0.8972 - val_loss: 0.5429 - val_accuracy: 0.7407\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3595 - accuracy: 0.8785 - val_loss: 0.5363 - val_accuracy: 0.7778\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3391 - accuracy: 0.8785 - val_loss: 0.5334 - val_accuracy: 0.7407\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3027 - accuracy: 0.8972 - val_loss: 0.5329 - val_accuracy: 0.7407\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3282 - accuracy: 0.9065 - val_loss: 0.5336 - val_accuracy: 0.7778\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3094 - accuracy: 0.9065 - val_loss: 0.5355 - val_accuracy: 0.7778\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2980 - accuracy: 0.9159 - val_loss: 0.5361 - val_accuracy: 0.7778\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 4s 406ms/step - loss: 0.6929 - accuracy: 0.5140 - val_loss: 0.6871 - val_accuracy: 0.4815\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 1s 205ms/step - loss: 0.6822 - accuracy: 0.5701 - val_loss: 0.6845 - val_accuracy: 0.4815\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 1s 204ms/step - loss: 0.6795 - accuracy: 0.5514 - val_loss: 0.6833 - val_accuracy: 0.4815\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 1s 211ms/step - loss: 0.6769 - accuracy: 0.5607 - val_loss: 0.6843 - val_accuracy: 0.4815\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 1s 202ms/step - loss: 0.6757 - accuracy: 0.5421 - val_loss: 0.6845 - val_accuracy: 0.4815\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 1s 203ms/step - loss: 0.6760 - accuracy: 0.5421 - val_loss: 0.6850 - val_accuracy: 0.4815\n",
      "2/2 [==============================] - 1s 15ms/step\n",
      "Epoch 1/50\n",
      "57/57 [==============================] - 1s 7ms/step - loss: 0.7215 - accuracy: 0.5129 - val_loss: 0.6815 - val_accuracy: 0.5330\n",
      "Epoch 2/50\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.6664 - accuracy: 0.6066 - val_loss: 0.6610 - val_accuracy: 0.6432\n",
      "Epoch 3/50\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.6477 - accuracy: 0.6193 - val_loss: 0.6972 - val_accuracy: 0.5749\n",
      "Epoch 4/50\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.6467 - accuracy: 0.6353 - val_loss: 0.6688 - val_accuracy: 0.6322\n",
      "Epoch 5/50\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.6154 - accuracy: 0.6584 - val_loss: 0.6498 - val_accuracy: 0.6322\n",
      "Epoch 6/50\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.6327 - accuracy: 0.6452 - val_loss: 0.6440 - val_accuracy: 0.6432\n",
      "Epoch 7/50\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.6124 - accuracy: 0.6529 - val_loss: 0.6446 - val_accuracy: 0.6674\n",
      "Epoch 8/50\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.6088 - accuracy: 0.6612 - val_loss: 0.6480 - val_accuracy: 0.6432\n",
      "Epoch 9/50\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.6062 - accuracy: 0.6672 - val_loss: 0.6440 - val_accuracy: 0.6696\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "57/57 [==============================] - 56s 953ms/step - loss: 0.6931 - accuracy: 0.5163 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "57/57 [==============================] - 49s 854ms/step - loss: 0.6925 - accuracy: 0.5196 - val_loss: 0.6938 - val_accuracy: 0.5000\n",
      "Epoch 3/50\n",
      "57/57 [==============================] - 51s 891ms/step - loss: 0.6929 - accuracy: 0.5196 - val_loss: 0.6939 - val_accuracy: 0.5000\n",
      "Epoch 4/50\n",
      "57/57 [==============================] - 50s 876ms/step - loss: 0.6928 - accuracy: 0.5196 - val_loss: 0.6937 - val_accuracy: 0.5000\n",
      "18/18 [==============================] - 5s 236ms/step\n",
      "Epoch 1/50\n",
      "57/57 [==============================] - 1s 7ms/step - loss: 0.7290 - accuracy: 0.5223 - val_loss: 0.6844 - val_accuracy: 0.5859\n",
      "Epoch 2/50\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.6699 - accuracy: 0.5791 - val_loss: 0.6685 - val_accuracy: 0.6278\n",
      "Epoch 3/50\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.6473 - accuracy: 0.6110 - val_loss: 0.6632 - val_accuracy: 0.6388\n",
      "Epoch 4/50\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.6319 - accuracy: 0.6336 - val_loss: 0.6644 - val_accuracy: 0.6454\n",
      "Epoch 5/50\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.6035 - accuracy: 0.6755 - val_loss: 0.6690 - val_accuracy: 0.6123\n",
      "Epoch 6/50\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.5901 - accuracy: 0.6837 - val_loss: 0.6614 - val_accuracy: 0.6718\n",
      "Epoch 7/50\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.5801 - accuracy: 0.6898 - val_loss: 0.6636 - val_accuracy: 0.6630\n",
      "Epoch 8/50\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.5739 - accuracy: 0.7003 - val_loss: 0.6599 - val_accuracy: 0.6916\n",
      "Epoch 9/50\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.5651 - accuracy: 0.7030 - val_loss: 0.6576 - val_accuracy: 0.6894\n",
      "Epoch 10/50\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.5652 - accuracy: 0.7036 - val_loss: 0.6668 - val_accuracy: 0.6784\n",
      "Epoch 11/50\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.5522 - accuracy: 0.7069 - val_loss: 0.6830 - val_accuracy: 0.6564\n",
      "Epoch 12/50\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.5608 - accuracy: 0.6953 - val_loss: 0.6614 - val_accuracy: 0.6894\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "57/57 [==============================] - 54s 907ms/step - loss: 0.6934 - accuracy: 0.5113 - val_loss: 0.6943 - val_accuracy: 0.4934\n",
      "Epoch 2/50\n",
      "57/57 [==============================] - 52s 915ms/step - loss: 0.6934 - accuracy: 0.5052 - val_loss: 0.6940 - val_accuracy: 0.5044\n",
      "Epoch 3/50\n",
      "57/57 [==============================] - 50s 878ms/step - loss: 0.6935 - accuracy: 0.5179 - val_loss: 0.6931 - val_accuracy: 0.5044\n",
      "Epoch 4/50\n",
      "57/57 [==============================] - 47s 827ms/step - loss: 0.6926 - accuracy: 0.5190 - val_loss: 0.6935 - val_accuracy: 0.4956\n",
      "Epoch 5/50\n",
      "57/57 [==============================] - 48s 834ms/step - loss: 0.6921 - accuracy: 0.5245 - val_loss: 0.6946 - val_accuracy: 0.4978\n",
      "Epoch 6/50\n",
      "57/57 [==============================] - 48s 844ms/step - loss: 0.6931 - accuracy: 0.5174 - val_loss: 0.6941 - val_accuracy: 0.5088\n",
      "18/18 [==============================] - 5s 231ms/step\n",
      "Epoch 1/50\n",
      "57/57 [==============================] - 1s 7ms/step - loss: 0.7041 - accuracy: 0.5240 - val_loss: 0.6802 - val_accuracy: 0.5749\n",
      "Epoch 2/50\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.6573 - accuracy: 0.6022 - val_loss: 0.6756 - val_accuracy: 0.5859\n",
      "Epoch 3/50\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.6313 - accuracy: 0.6424 - val_loss: 0.6748 - val_accuracy: 0.6057\n",
      "Epoch 4/50\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.6163 - accuracy: 0.6634 - val_loss: 0.6797 - val_accuracy: 0.6344\n",
      "Epoch 5/50\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.5905 - accuracy: 0.6975 - val_loss: 0.6806 - val_accuracy: 0.6410\n",
      "Epoch 6/50\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.5804 - accuracy: 0.6904 - val_loss: 0.6835 - val_accuracy: 0.6520\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "57/57 [==============================] - 50s 833ms/step - loss: 0.6929 - accuracy: 0.5229 - val_loss: 0.6957 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "57/57 [==============================] - 47s 823ms/step - loss: 0.6921 - accuracy: 0.5212 - val_loss: 0.6940 - val_accuracy: 0.5176\n",
      "Epoch 3/50\n",
      "57/57 [==============================] - 47s 830ms/step - loss: 0.6925 - accuracy: 0.5190 - val_loss: 0.6946 - val_accuracy: 0.5000\n",
      "Epoch 4/50\n",
      "57/57 [==============================] - 46s 805ms/step - loss: 0.6927 - accuracy: 0.5201 - val_loss: 0.6951 - val_accuracy: 0.5022\n",
      "Epoch 5/50\n",
      "57/57 [==============================] - 45s 792ms/step - loss: 0.6926 - accuracy: 0.5229 - val_loss: 0.6946 - val_accuracy: 0.5000\n",
      "18/18 [==============================] - 5s 226ms/step\n",
      "Epoch 1/50\n",
      "57/57 [==============================] - 1s 7ms/step - loss: 0.6954 - accuracy: 0.5372 - val_loss: 0.6807 - val_accuracy: 0.5793\n",
      "Epoch 2/50\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.6592 - accuracy: 0.6011 - val_loss: 0.6715 - val_accuracy: 0.6322\n",
      "Epoch 3/50\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.6192 - accuracy: 0.6556 - val_loss: 0.6720 - val_accuracy: 0.6256\n",
      "Epoch 4/50\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.5878 - accuracy: 0.6909 - val_loss: 0.6685 - val_accuracy: 0.6564\n",
      "Epoch 5/50\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.5706 - accuracy: 0.6981 - val_loss: 0.6906 - val_accuracy: 0.6498\n",
      "Epoch 6/50\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.5561 - accuracy: 0.7118 - val_loss: 0.6805 - val_accuracy: 0.6696\n",
      "Epoch 7/50\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.5436 - accuracy: 0.7201 - val_loss: 0.6817 - val_accuracy: 0.6718\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "57/57 [==============================] - 49s 815ms/step - loss: 0.6933 - accuracy: 0.5113 - val_loss: 0.6930 - val_accuracy: 0.5154\n",
      "Epoch 2/50\n",
      "57/57 [==============================] - 46s 814ms/step - loss: 0.6926 - accuracy: 0.5245 - val_loss: 0.6932 - val_accuracy: 0.5088\n",
      "Epoch 3/50\n",
      "57/57 [==============================] - 48s 839ms/step - loss: 0.6915 - accuracy: 0.5251 - val_loss: 0.6935 - val_accuracy: 0.5110\n",
      "Epoch 4/50\n",
      "57/57 [==============================] - 49s 870ms/step - loss: 0.6917 - accuracy: 0.5201 - val_loss: 0.6937 - val_accuracy: 0.5110\n",
      "18/18 [==============================] - 7s 366ms/step\n",
      "Epoch 1/50\n",
      "57/57 [==============================] - 1s 8ms/step - loss: 0.7042 - accuracy: 0.5399 - val_loss: 0.6865 - val_accuracy: 0.5441\n",
      "Epoch 2/50\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.6546 - accuracy: 0.6110 - val_loss: 0.6672 - val_accuracy: 0.5903\n",
      "Epoch 3/50\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.6137 - accuracy: 0.6612 - val_loss: 0.6579 - val_accuracy: 0.6674\n",
      "Epoch 4/50\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.5796 - accuracy: 0.6926 - val_loss: 0.6636 - val_accuracy: 0.6696\n",
      "Epoch 5/50\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.5470 - accuracy: 0.7251 - val_loss: 0.6898 - val_accuracy: 0.6586\n",
      "Epoch 6/50\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.5375 - accuracy: 0.7234 - val_loss: 0.6892 - val_accuracy: 0.6608\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "57/57 [==============================] - 57s 964ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6922 - val_accuracy: 0.5176\n",
      "Epoch 2/50\n",
      "57/57 [==============================] - 53s 925ms/step - loss: 0.6922 - accuracy: 0.5212 - val_loss: 0.6925 - val_accuracy: 0.5176\n",
      "Epoch 3/50\n",
      "57/57 [==============================] - 47s 824ms/step - loss: 0.6919 - accuracy: 0.5240 - val_loss: 0.6928 - val_accuracy: 0.5132\n",
      "Epoch 4/50\n",
      "57/57 [==============================] - 47s 830ms/step - loss: 0.6919 - accuracy: 0.5174 - val_loss: 0.6930 - val_accuracy: 0.5110\n",
      " 1/18 [>.............................] - ETA: 11s"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[95], line 63\u001b[0m\n\u001b[0;32m     61\u001b[0m     X_test_reshaped \u001b[38;5;241m=\u001b[39m X_test\u001b[38;5;241m.\u001b[39mreshape((X_test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], X_test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     62\u001b[0m     model\u001b[38;5;241m.\u001b[39mfit(X_train_reshaped, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, callbacks\u001b[38;5;241m=\u001b[39m[EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)])\n\u001b[1;32m---> 63\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_reshaped\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, callbacks\u001b[38;5;241m=\u001b[39m[EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)])\n",
      "File \u001b[1;32mc:\\Users\\abhin\\anaconda3\\envs\\DevelopmentEnv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\abhin\\anaconda3\\envs\\DevelopmentEnv\\lib\\site-packages\\keras\\engine\\training.py:2253\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   2251\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n\u001b[0;32m   2252\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_predict_batch_begin(step)\n\u001b[1;32m-> 2253\u001b[0m     tmp_batch_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2254\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   2255\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\abhin\\anaconda3\\envs\\DevelopmentEnv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\abhin\\anaconda3\\envs\\DevelopmentEnv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\abhin\\anaconda3\\envs\\DevelopmentEnv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    952\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    953\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 954\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[0;32m    956\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    957\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\abhin\\anaconda3\\envs\\DevelopmentEnv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\abhin\\anaconda3\\envs\\DevelopmentEnv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\abhin\\anaconda3\\envs\\DevelopmentEnv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\abhin\\anaconda3\\envs\\DevelopmentEnv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "# Assume 'files' is defined\n",
    "df_list = []\n",
    "\n",
    "for file in files:\n",
    "    data = pd.read_csv('../Processed Datasets/' + file)\n",
    "    data = data[data['Winner'].isin([1, 2])]\n",
    "    data['Winner'] = data['Winner'].replace(1, 0)\n",
    "    data['Winner'] = data['Winner'].replace(2, 1)\n",
    "\n",
    "    label_encoders = {}\n",
    "    for column in ['ReplayID', 'Player1_Race', 'Player2_Race', 'MapName']:\n",
    "        label_encoders[column] = LabelEncoder()\n",
    "        data[column] = label_encoders[column].fit_transform(data[column])\n",
    "\n",
    "    for per in range(1, 11):\n",
    "        percentile_80_grouped = data.groupby('ReplayID')['Frame'].quantile(per / 10)\n",
    "        def find_nearest_row(group):\n",
    "            nearest_index = (group['Frame'] - percentile_80_grouped[group.name]).abs().idxmin()\n",
    "            return group.loc[[nearest_index]]\n",
    "        nearest_rows = data.groupby('ReplayID', group_keys=False).apply(find_nearest_row)\n",
    "        nearest_rows.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(nearest_rows.drop('Winner', axis=1))\n",
    "        y = nearest_rows['Winner'].values\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "        # TensorFlow models within your existing loop\n",
    "        models = {\n",
    "            'NeuralNetwork': tf.keras.models.Sequential([\n",
    "                        tf.keras.layers.Dense(250, activation='sigmoid', input_shape=(X_train.shape[1],)),\n",
    "                        tf.keras.layers.Dropout(0.2),\n",
    "                        tf.keras.layers.Dense(125, activation='sigmoid'),\n",
    "                        tf.keras.layers.Dropout(0.2),\n",
    "                        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "            ]),\n",
    "            'LSTM': Sequential([\n",
    "                LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], 1)),\n",
    "                Dropout(0.2),\n",
    "                LSTM(50),\n",
    "                Dropout(0.2),\n",
    "                Dense(1, activation='sigmoid') \n",
    "            ])\n",
    "        }\n",
    "\n",
    "        # Compile Keras models\n",
    "        models['NeuralNetwork'].compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        models['LSTM'].compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        scores_dict = {'File': file, 'Percentile': per / 10}\n",
    "\n",
    "        # Training and evaluation loop for Keras models\n",
    "        for model_name, model in models.items():\n",
    "            if model_name == 'LSTM':\n",
    "                X_train_reshaped = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "                X_test_reshaped = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "                model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1, callbacks=[EarlyStopping(monitor='val_loss', patience=3)])\n",
    "                predictions = model.predict(X_test_reshaped)\n",
    "            else:\n",
    "                model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1, callbacks=[EarlyStopping(monitor='val_loss', patience=3)])\n",
    "                predictions = model.predict(X_test)\n",
    "\n",
    "\n",
    "            # Post-processing for metrics calculation\n",
    "            predictions = (predictions > 0.5).astype(int)\n",
    "            accuracy = accuracy_score(y_test, predictions)\n",
    "            precision = precision_score(y_test, predictions)\n",
    "            recall = recall_score(y_test, predictions)\n",
    "            f1 = f1_score(y_test, predictions)\n",
    "            roc = roc_auc_score(y_test, predictions)\n",
    "\n",
    "            scores_dict[f'{model_name}_accuracy'] = accuracy\n",
    "            scores_dict[f'{model_name}_precision'] = precision\n",
    "            scores_dict[f'{model_name}_recall'] = recall\n",
    "            scores_dict[f'{model_name}_f1'] = f1\n",
    "            scores_dict[f'{model_name}_rocauc'] = roc\n",
    "\n",
    "            df_list.append(pd.DataFrame([scores_dict]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49830508474576274"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, predictions)  # Eansure predictions are probabilities for ROC AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[                         File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_PvP.csv         0.1                0.657534   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.658537              0.710526          0.683544   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0              0.655263  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_PvP.csv         0.1                0.657534   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.658537              0.710526          0.683544   \n",
       " \n",
       "    NeuralNetwork_rocauc  LSTM_accuracy  LSTM_precision  LSTM_recall   LSTM_f1  \\\n",
       " 0              0.655263       0.520548        0.520548          1.0  0.684685   \n",
       " \n",
       "    LSTM_rocauc  \n",
       " 0          0.5  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_PvP.csv         0.2                0.616438   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.631579              0.631579          0.631579   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0              0.615789  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_PvP.csv         0.2                0.616438   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.631579              0.631579          0.631579   \n",
       " \n",
       "    NeuralNetwork_rocauc  LSTM_accuracy  LSTM_precision  LSTM_recall   LSTM_f1  \\\n",
       " 0              0.615789       0.520548        0.520548          1.0  0.684685   \n",
       " \n",
       "    LSTM_rocauc  \n",
       " 0          0.5  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_PvP.csv         0.3                0.561644   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.571429              0.631579               0.6   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0              0.558647  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_PvP.csv         0.3                0.561644   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.571429              0.631579               0.6   \n",
       " \n",
       "    NeuralNetwork_rocauc  LSTM_accuracy  LSTM_precision  LSTM_recall   LSTM_f1  \\\n",
       " 0              0.558647       0.520548        0.520548          1.0  0.684685   \n",
       " \n",
       "    LSTM_rocauc  \n",
       " 0          0.5  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_PvP.csv         0.4                0.589041   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                    0.625              0.526316          0.571429   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0              0.591729  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_PvP.csv         0.4                0.589041   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                    0.625              0.526316          0.571429   \n",
       " \n",
       "    NeuralNetwork_rocauc  LSTM_accuracy  LSTM_precision  LSTM_recall   LSTM_f1  \\\n",
       " 0              0.591729       0.520548        0.520548          1.0  0.684685   \n",
       " \n",
       "    LSTM_rocauc  \n",
       " 0          0.5  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_PvP.csv         0.5                0.616438   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.608696              0.736842          0.666667   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0              0.611278  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_PvP.csv         0.5                0.616438   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.608696              0.736842          0.666667   \n",
       " \n",
       "    NeuralNetwork_rocauc  LSTM_accuracy  LSTM_precision  LSTM_recall   LSTM_f1  \\\n",
       " 0              0.611278       0.520548        0.520548          1.0  0.684685   \n",
       " \n",
       "    LSTM_rocauc  \n",
       " 0          0.5  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_PvP.csv         0.6                 0.60274   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.591837              0.763158          0.666667   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0              0.595865  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_PvP.csv         0.6                 0.60274   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.591837              0.763158          0.666667   \n",
       " \n",
       "    NeuralNetwork_rocauc  LSTM_accuracy  LSTM_precision  LSTM_recall   LSTM_f1  \\\n",
       " 0              0.595865       0.520548        0.520548          1.0  0.684685   \n",
       " \n",
       "    LSTM_rocauc  \n",
       " 0          0.5  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_PvP.csv         0.7                0.671233   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.666667              0.736842               0.7   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0              0.668421  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_PvP.csv         0.7                0.671233   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.666667              0.736842               0.7   \n",
       " \n",
       "    NeuralNetwork_rocauc  LSTM_accuracy  LSTM_precision  LSTM_recall   LSTM_f1  \\\n",
       " 0              0.668421       0.520548        0.520548          1.0  0.684685   \n",
       " \n",
       "    LSTM_rocauc  \n",
       " 0          0.5  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_PvP.csv         0.8                0.808219   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.833333              0.789474          0.810811   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0              0.809023  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_PvP.csv         0.8                0.808219   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.833333              0.789474          0.810811   \n",
       " \n",
       "    NeuralNetwork_rocauc  LSTM_accuracy  LSTM_precision  LSTM_recall   LSTM_f1  \\\n",
       " 0              0.809023       0.465753        0.487179          0.5  0.493506   \n",
       " \n",
       "    LSTM_rocauc  \n",
       " 0     0.464286  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_PvP.csv         0.9                0.808219   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                    0.875              0.736842               0.8   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0              0.811278  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_PvP.csv         0.9                0.808219   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                    0.875              0.736842               0.8   \n",
       " \n",
       "    NeuralNetwork_rocauc  LSTM_accuracy  LSTM_precision  LSTM_recall   LSTM_f1  \\\n",
       " 0              0.811278       0.465753        0.487179          0.5  0.493506   \n",
       " \n",
       "    LSTM_rocauc  \n",
       " 0     0.464286  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_PvP.csv         1.0                 0.90411   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.969697              0.842105          0.901408   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0              0.906767  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_PvP.csv         1.0                 0.90411   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.969697              0.842105          0.901408   \n",
       " \n",
       "    NeuralNetwork_rocauc  LSTM_accuracy  LSTM_precision  LSTM_recall  LSTM_f1  \\\n",
       " 0              0.906767       0.506849        0.519231     0.710526      0.6   \n",
       " \n",
       "    LSTM_rocauc  \n",
       " 0      0.49812  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_PvT.csv         0.1                 0.65812   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.671642              0.714286          0.692308   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0              0.653439  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_PvT.csv         0.1                 0.65812   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.671642              0.714286          0.692308   \n",
       " \n",
       "    NeuralNetwork_rocauc  LSTM_accuracy  LSTM_precision  LSTM_recall  LSTM_f1  \\\n",
       " 0              0.653439       0.461538             0.0          0.0      0.0   \n",
       " \n",
       "    LSTM_rocauc  \n",
       " 0          0.5  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_PvT.csv         0.2                0.786325   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.796875              0.809524           0.80315   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0              0.784392  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_PvT.csv         0.2                0.786325   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.796875              0.809524           0.80315   \n",
       " \n",
       "    NeuralNetwork_rocauc  LSTM_accuracy  LSTM_precision  LSTM_recall  LSTM_f1  \\\n",
       " 0              0.784392       0.461538             0.0          0.0      0.0   \n",
       " \n",
       "    LSTM_rocauc  \n",
       " 0          0.5  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_PvT.csv         0.3                0.769231   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.833333              0.714286          0.769231   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0               0.77381  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_PvT.csv         0.3                0.769231   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.833333              0.714286          0.769231   \n",
       " \n",
       "    NeuralNetwork_rocauc  LSTM_accuracy  LSTM_precision  LSTM_recall   LSTM_f1  \\\n",
       " 0               0.77381       0.581197           0.675     0.428571  0.524272   \n",
       " \n",
       "    LSTM_rocauc  \n",
       " 0     0.593915  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_PvT.csv         0.4                0.649573   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.789474               0.47619          0.594059   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0              0.664021  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_PvT.csv         0.4                0.649573   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.789474               0.47619          0.594059   \n",
       " \n",
       "    NeuralNetwork_rocauc  LSTM_accuracy  LSTM_precision  LSTM_recall   LSTM_f1  \\\n",
       " 0              0.664021       0.478632        0.529412     0.285714  0.371134   \n",
       " \n",
       "    LSTM_rocauc  \n",
       " 0     0.494709  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_PvT.csv         0.5                0.735043   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.766667              0.730159          0.747967   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0               0.73545  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_PvT.csv         0.5                0.735043   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.766667              0.730159          0.747967   \n",
       " \n",
       "    NeuralNetwork_rocauc  LSTM_accuracy  LSTM_precision  LSTM_recall   LSTM_f1  \\\n",
       " 0               0.73545       0.564103        0.569767     0.777778  0.657718   \n",
       " \n",
       "    LSTM_rocauc  \n",
       " 0     0.546296  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_PvT.csv         0.6                0.709402   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.710145              0.777778          0.742424   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0              0.703704  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_PvT.csv         0.6                0.709402   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.710145              0.777778          0.742424   \n",
       " \n",
       "    NeuralNetwork_rocauc  LSTM_accuracy  LSTM_precision  LSTM_recall  LSTM_f1  \\\n",
       " 0              0.703704       0.581197        0.612903     0.603175    0.608   \n",
       " \n",
       "    LSTM_rocauc  \n",
       " 0     0.579365  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_PvT.csv         0.7                0.786325   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.796875              0.809524           0.80315   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0              0.784392  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_PvT.csv         0.7                0.786325   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.796875              0.809524           0.80315   \n",
       " \n",
       "    NeuralNetwork_rocauc  LSTM_accuracy  LSTM_precision  LSTM_recall   LSTM_f1  \\\n",
       " 0              0.784392       0.632479        0.638889     0.730159  0.681481   \n",
       " \n",
       "    LSTM_rocauc  \n",
       " 0     0.624339  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_PvT.csv         0.8                0.803419   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.822581              0.809524             0.816   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0               0.80291  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_PvT.csv         0.8                0.803419   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.822581              0.809524             0.816   \n",
       " \n",
       "    NeuralNetwork_rocauc  LSTM_accuracy  LSTM_precision  LSTM_recall   LSTM_f1  \\\n",
       " 0               0.80291        0.57265        0.606557     0.587302  0.596774   \n",
       " \n",
       "    LSTM_rocauc  \n",
       " 0     0.571429  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_PvT.csv         0.9                 0.82906   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                  0.84127               0.84127           0.84127   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0              0.828042  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_PvT.csv         0.9                 0.82906   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                  0.84127               0.84127           0.84127   \n",
       " \n",
       "    NeuralNetwork_rocauc  LSTM_accuracy  LSTM_precision  LSTM_recall   LSTM_f1  \\\n",
       " 0              0.828042       0.641026        0.677966     0.634921  0.655738   \n",
       " \n",
       "    LSTM_rocauc  \n",
       " 0     0.641534  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_PvT.csv         1.0                0.905983   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.893939              0.936508          0.914729   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0              0.903439  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_PvT.csv         1.0                0.905983   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.893939              0.936508          0.914729   \n",
       " \n",
       "    NeuralNetwork_rocauc  LSTM_accuracy  LSTM_precision  LSTM_recall  LSTM_f1  \\\n",
       " 0              0.903439       0.564103        0.596774     0.587302    0.592   \n",
       " \n",
       "    LSTM_rocauc  \n",
       " 0     0.562169  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_PvZ.csv         0.1                0.525641   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.529412              0.461538          0.493151   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0              0.525641  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_PvZ.csv         0.1                0.525641   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.529412              0.461538          0.493151   \n",
       " \n",
       "    NeuralNetwork_rocauc  LSTM_accuracy  LSTM_precision  LSTM_recall   LSTM_f1  \\\n",
       " 0              0.525641            0.5             0.5          1.0  0.666667   \n",
       " \n",
       "    LSTM_rocauc  \n",
       " 0          0.5  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_PvZ.csv         0.2                     0.5   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                      0.5              0.974359           0.66087   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0                   0.5  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_PvZ.csv         0.2                     0.5   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                      0.5              0.974359           0.66087   \n",
       " \n",
       "    NeuralNetwork_rocauc  LSTM_accuracy  LSTM_precision  LSTM_recall   LSTM_f1  \\\n",
       " 0                   0.5       0.474359        0.486842     0.948718  0.643478   \n",
       " \n",
       "    LSTM_rocauc  \n",
       " 0     0.474359  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_PvZ.csv         0.3                0.448718   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.466667              0.717949          0.565657   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0              0.448718  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_PvZ.csv         0.3                0.448718   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.466667              0.717949          0.565657   \n",
       " \n",
       "    NeuralNetwork_rocauc  LSTM_accuracy  LSTM_precision  LSTM_recall   LSTM_f1  \\\n",
       " 0              0.448718       0.538462        0.565217     0.333333  0.419355   \n",
       " \n",
       "    LSTM_rocauc  \n",
       " 0     0.538462  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_PvZ.csv         0.4                0.474359   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.484848              0.820513          0.609524   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0              0.474359  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_PvZ.csv         0.4                0.474359   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.484848              0.820513          0.609524   \n",
       " \n",
       "    NeuralNetwork_rocauc  LSTM_accuracy  LSTM_precision  LSTM_recall   LSTM_f1  \\\n",
       " 0              0.474359       0.487179        0.491228     0.717949  0.583333   \n",
       " \n",
       "    LSTM_rocauc  \n",
       " 0     0.487179  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_PvZ.csv         0.5                0.487179   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.489362              0.589744          0.534884   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0              0.487179  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_PvZ.csv         0.5                0.487179   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.489362              0.589744          0.534884   \n",
       " \n",
       "    NeuralNetwork_rocauc  LSTM_accuracy  LSTM_precision  LSTM_recall   LSTM_f1  \\\n",
       " 0              0.487179       0.512821        0.507937     0.820513  0.627451   \n",
       " \n",
       "    LSTM_rocauc  \n",
       " 0     0.512821  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_PvZ.csv         0.6                0.435897   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.462687              0.794872          0.584906   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0              0.435897  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_PvZ.csv         0.6                0.435897   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.462687              0.794872          0.584906   \n",
       " \n",
       "    NeuralNetwork_rocauc  LSTM_accuracy  LSTM_precision  LSTM_recall   LSTM_f1  \\\n",
       " 0              0.435897       0.538462        0.521127     0.948718  0.672727   \n",
       " \n",
       "    LSTM_rocauc  \n",
       " 0     0.538462  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_PvZ.csv         0.7                0.512821   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.508197              0.794872              0.62   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0              0.512821  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_PvZ.csv         0.7                0.512821   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.508197              0.794872              0.62   \n",
       " \n",
       "    NeuralNetwork_rocauc  LSTM_accuracy  LSTM_precision  LSTM_recall   LSTM_f1  \\\n",
       " 0              0.512821       0.487179        0.493151     0.923077  0.642857   \n",
       " \n",
       "    LSTM_rocauc  \n",
       " 0     0.487179  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_PvZ.csv         0.8                0.487179   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.491525               0.74359          0.591837   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0              0.487179  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_PvZ.csv         0.8                0.487179   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.491525               0.74359          0.591837   \n",
       " \n",
       "    NeuralNetwork_rocauc  LSTM_accuracy  LSTM_precision  LSTM_recall   LSTM_f1  \\\n",
       " 0              0.487179       0.474359        0.486111     0.897436  0.630631   \n",
       " \n",
       "    LSTM_rocauc  \n",
       " 0     0.474359  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_PvZ.csv         0.9                0.487179   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.491525               0.74359          0.591837   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0              0.487179  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_PvZ.csv         0.9                0.487179   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.491525               0.74359          0.591837   \n",
       " \n",
       "    NeuralNetwork_rocauc  LSTM_accuracy  LSTM_precision  LSTM_recall   LSTM_f1  \\\n",
       " 0              0.487179       0.423077        0.444444     0.615385  0.516129   \n",
       " \n",
       "    LSTM_rocauc  \n",
       " 0     0.423077  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_PvZ.csv         1.0                0.679487   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.659091               0.74359          0.698795   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0              0.679487  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_PvZ.csv         1.0                0.679487   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.659091               0.74359          0.698795   \n",
       " \n",
       "    NeuralNetwork_rocauc  LSTM_accuracy  LSTM_precision  LSTM_recall   LSTM_f1  \\\n",
       " 0              0.679487       0.423077            0.45     0.692308  0.545455   \n",
       " \n",
       "    LSTM_rocauc  \n",
       " 0     0.423077  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_TvT.csv         0.1                0.662338   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.658537              0.692308             0.675   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0              0.661943  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_TvT.csv         0.1                0.662338   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.658537              0.692308             0.675   \n",
       " \n",
       "    NeuralNetwork_rocauc  LSTM_accuracy  LSTM_precision  LSTM_recall   LSTM_f1  \\\n",
       " 0              0.661943       0.506494        0.506494          1.0  0.672414   \n",
       " \n",
       "    LSTM_rocauc  \n",
       " 0          0.5  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_TvT.csv         0.2                0.727273   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.764706              0.666667          0.712329   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0               0.72807  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_TvT.csv         0.2                0.727273   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.764706              0.666667          0.712329   \n",
       " \n",
       "    NeuralNetwork_rocauc  LSTM_accuracy  LSTM_precision  LSTM_recall   LSTM_f1  \\\n",
       " 0               0.72807       0.506494        0.506494          1.0  0.672414   \n",
       " \n",
       "    LSTM_rocauc  \n",
       " 0          0.5  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_TvT.csv         0.3                0.558442   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.586207              0.435897               0.5   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0              0.560054  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_TvT.csv         0.3                0.558442   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.586207              0.435897               0.5   \n",
       " \n",
       "    NeuralNetwork_rocauc  LSTM_accuracy  LSTM_precision  LSTM_recall   LSTM_f1  \\\n",
       " 0              0.560054       0.506494        0.516129     0.410256  0.457143   \n",
       " \n",
       "    LSTM_rocauc  \n",
       " 0      0.50776  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_TvT.csv         0.4                0.571429   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.607143              0.435897          0.507463   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0              0.573212  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_TvT.csv         0.4                0.571429   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.607143              0.435897          0.507463   \n",
       " \n",
       "    NeuralNetwork_rocauc  LSTM_accuracy  LSTM_precision  LSTM_recall   LSTM_f1  \\\n",
       " 0              0.573212       0.519481        0.527778     0.487179  0.506667   \n",
       " \n",
       "    LSTM_rocauc  \n",
       " 0     0.519906  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_TvT.csv         0.5                0.623377   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                  0.65625              0.538462          0.591549   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0              0.624494  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_TvT.csv         0.5                0.623377   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                  0.65625              0.538462          0.591549   \n",
       " \n",
       "    NeuralNetwork_rocauc  LSTM_accuracy  LSTM_precision  LSTM_recall   LSTM_f1  \\\n",
       " 0              0.624494       0.493506             0.5     0.487179  0.493506   \n",
       " \n",
       "    LSTM_rocauc  \n",
       " 0      0.49359  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_TvT.csv         0.6                0.727273   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                     0.75              0.692308              0.72   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0              0.727733  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_TvT.csv         0.6                0.727273   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                     0.75              0.692308              0.72   \n",
       " \n",
       "    NeuralNetwork_rocauc  LSTM_accuracy  LSTM_precision  LSTM_recall   LSTM_f1  \\\n",
       " 0              0.727733       0.480519        0.492308     0.820513  0.615385   \n",
       " \n",
       "    LSTM_rocauc  \n",
       " 0     0.476046  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_TvT.csv         0.7                0.714286   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                  0.72973              0.692308          0.710526   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0              0.714575  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_TvT.csv         0.7                0.714286   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                  0.72973              0.692308          0.710526   \n",
       " \n",
       "    NeuralNetwork_rocauc  LSTM_accuracy  LSTM_precision  LSTM_recall   LSTM_f1  \\\n",
       " 0              0.714575       0.493506             0.5     0.641026  0.561798   \n",
       " \n",
       "    LSTM_rocauc  \n",
       " 0     0.491565  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_TvT.csv         0.8                0.662338   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                  0.69697              0.589744          0.638889   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0              0.663293  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_TvT.csv         0.8                0.662338   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                  0.69697              0.589744          0.638889   \n",
       " \n",
       "    NeuralNetwork_rocauc  LSTM_accuracy  LSTM_precision  LSTM_recall   LSTM_f1  \\\n",
       " 0              0.663293       0.480519        0.485714     0.435897  0.459459   \n",
       " \n",
       "    LSTM_rocauc  \n",
       " 0     0.481107  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_TvT.csv         0.9                 0.74026   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.827586              0.615385          0.705882   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0              0.741903  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_TvT.csv         0.9                 0.74026   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.827586              0.615385          0.705882   \n",
       " \n",
       "    NeuralNetwork_rocauc  LSTM_accuracy  LSTM_precision  LSTM_recall  LSTM_f1  \\\n",
       " 0              0.741903        0.61039        0.609756     0.641026    0.625   \n",
       " \n",
       "    LSTM_rocauc  \n",
       " 0     0.609987  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_TvT.csv         1.0                0.857143   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.888889              0.820513          0.853333   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0              0.857625  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_TvT.csv         1.0                0.857143   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.888889              0.820513          0.853333   \n",
       " \n",
       "    NeuralNetwork_rocauc  LSTM_accuracy  LSTM_precision  LSTM_recall   LSTM_f1  \\\n",
       " 0              0.857625       0.584416        0.606061     0.512821  0.555556   \n",
       " \n",
       "    LSTM_rocauc  \n",
       " 0     0.585358  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_TvZ.csv         0.1                     0.5   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                      0.5              0.971429          0.660194   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0                   0.5  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_TvZ.csv         0.1                     0.5   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                      0.5              0.971429          0.660194   \n",
       " \n",
       "    NeuralNetwork_rocauc  LSTM_accuracy  LSTM_precision  LSTM_recall   LSTM_f1  \\\n",
       " 0                   0.5            0.5             0.5          1.0  0.666667   \n",
       " \n",
       "    LSTM_rocauc  \n",
       " 0          0.5  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_TvZ.csv         0.2                0.557143   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.530303                   1.0          0.693069   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0              0.557143  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_TvZ.csv         0.2                0.557143   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.530303                   1.0          0.693069   \n",
       " \n",
       "    NeuralNetwork_rocauc  LSTM_accuracy  LSTM_precision  LSTM_recall   LSTM_f1  \\\n",
       " 0              0.557143       0.514286        0.507937     0.914286  0.653061   \n",
       " \n",
       "    LSTM_rocauc  \n",
       " 0     0.514286  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_TvZ.csv         0.3                     0.5   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                      0.5                   1.0          0.666667   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0                   0.5  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_TvZ.csv         0.3                     0.5   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                      0.5                   1.0          0.666667   \n",
       " \n",
       "    NeuralNetwork_rocauc  LSTM_accuracy  LSTM_precision  LSTM_recall   LSTM_f1  \\\n",
       " 0                   0.5       0.528571        0.516667     0.885714  0.652632   \n",
       " \n",
       "    LSTM_rocauc  \n",
       " 0     0.528571  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_TvZ.csv         0.4                0.571429   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.540984              0.942857            0.6875   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0              0.571429  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_TvZ.csv         0.4                0.571429   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.540984              0.942857            0.6875   \n",
       " \n",
       "    NeuralNetwork_rocauc  LSTM_accuracy  LSTM_precision  LSTM_recall   LSTM_f1  \\\n",
       " 0              0.571429       0.514286        0.507246          1.0  0.673077   \n",
       " \n",
       "    LSTM_rocauc  \n",
       " 0     0.514286  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_TvZ.csv         0.5                0.585714   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.548387              0.971429          0.701031   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0              0.585714  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_TvZ.csv         0.5                0.585714   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.548387              0.971429          0.701031   \n",
       " \n",
       "    NeuralNetwork_rocauc  LSTM_accuracy  LSTM_precision  LSTM_recall   LSTM_f1  \\\n",
       " 0              0.585714       0.614286        0.571429     0.914286  0.703297   \n",
       " \n",
       "    LSTM_rocauc  \n",
       " 0     0.614286  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_TvZ.csv         0.6                0.585714   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.548387              0.971429          0.701031   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0              0.585714  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_TvZ.csv         0.6                0.585714   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.548387              0.971429          0.701031   \n",
       " \n",
       "    NeuralNetwork_rocauc  LSTM_accuracy  LSTM_precision  LSTM_recall   LSTM_f1  \\\n",
       " 0              0.585714       0.585714        0.551724     0.914286  0.688172   \n",
       " \n",
       "    LSTM_rocauc  \n",
       " 0     0.585714  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_TvZ.csv         0.7                0.557143   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.530303                   1.0          0.693069   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0              0.557143  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_TvZ.csv         0.7                0.557143   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.530303                   1.0          0.693069   \n",
       " \n",
       "    NeuralNetwork_rocauc  LSTM_accuracy  LSTM_precision  LSTM_recall   LSTM_f1  \\\n",
       " 0              0.557143       0.642857        0.592593     0.914286  0.719101   \n",
       " \n",
       "    LSTM_rocauc  \n",
       " 0     0.642857  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_TvZ.csv         0.8                0.557143   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.537037              0.828571          0.651685   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0              0.557143  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_TvZ.csv         0.8                0.557143   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.537037              0.828571          0.651685   \n",
       " \n",
       "    NeuralNetwork_rocauc  LSTM_accuracy  LSTM_precision  LSTM_recall  LSTM_f1  \\\n",
       " 0              0.557143       0.485714        0.490909     0.771429      0.6   \n",
       " \n",
       "    LSTM_rocauc  \n",
       " 0     0.485714  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_TvZ.csv         0.9                0.614286   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.583333                   0.8          0.674699   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0              0.614286  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_TvZ.csv         0.9                0.614286   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.583333                   0.8          0.674699   \n",
       " \n",
       "    NeuralNetwork_rocauc  LSTM_accuracy  LSTM_precision  LSTM_recall   LSTM_f1  \\\n",
       " 0              0.614286       0.571429        0.545455     0.857143  0.666667   \n",
       " \n",
       "    LSTM_rocauc  \n",
       " 0     0.571429  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_TvZ.csv         1.0                0.728571   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                     0.75              0.685714          0.716418   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0              0.728571  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_TvZ.csv         1.0                0.728571   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                     0.75              0.685714          0.716418   \n",
       " \n",
       "    NeuralNetwork_rocauc  LSTM_accuracy  LSTM_precision  LSTM_recall   LSTM_f1  \\\n",
       " 0              0.728571            0.6        0.563636     0.885714  0.688889   \n",
       " \n",
       "    LSTM_rocauc  \n",
       " 0          0.6  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_ZvZ.csv         0.1                0.529412   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                      0.5                   0.5               0.5   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0              0.527778  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_ZvZ.csv         0.1                0.529412   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                      0.5                   0.5               0.5   \n",
       " \n",
       "    NeuralNetwork_rocauc  LSTM_accuracy  LSTM_precision  LSTM_recall   LSTM_f1  \\\n",
       " 0              0.527778       0.558824             1.0       0.0625  0.117647   \n",
       " \n",
       "    LSTM_rocauc  \n",
       " 0      0.53125  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_ZvZ.csv         0.2                0.588235   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.666667                  0.25          0.363636   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0              0.569444  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_ZvZ.csv         0.2                0.588235   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.666667                  0.25          0.363636   \n",
       " \n",
       "    NeuralNetwork_rocauc  LSTM_accuracy  LSTM_precision  LSTM_recall   LSTM_f1  \\\n",
       " 0              0.569444       0.558824             1.0       0.0625  0.117647   \n",
       " \n",
       "    LSTM_rocauc  \n",
       " 0      0.53125  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_ZvZ.csv         0.3                0.588235   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.583333                0.4375               0.5   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0              0.579861  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_ZvZ.csv         0.3                0.588235   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.583333                0.4375               0.5   \n",
       " \n",
       "    NeuralNetwork_rocauc  LSTM_accuracy  LSTM_precision  LSTM_recall  LSTM_f1  \\\n",
       " 0              0.579861       0.529412             0.0          0.0      0.0   \n",
       " \n",
       "    LSTM_rocauc  \n",
       " 0          0.5  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_ZvZ.csv         0.4                0.617647   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.578947                0.6875          0.628571   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0              0.621528  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_ZvZ.csv         0.4                0.617647   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.578947                0.6875          0.628571   \n",
       " \n",
       "    NeuralNetwork_rocauc  LSTM_accuracy  LSTM_precision  LSTM_recall   LSTM_f1  \\\n",
       " 0              0.621528       0.441176        0.421053          0.5  0.457143   \n",
       " \n",
       "    LSTM_rocauc  \n",
       " 0     0.444444  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_ZvZ.csv         0.5                0.529412   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                      0.5                   0.5               0.5   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0              0.527778  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_ZvZ.csv         0.5                0.529412   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                      0.5                   0.5               0.5   \n",
       " \n",
       "    NeuralNetwork_rocauc  LSTM_accuracy  LSTM_precision  LSTM_recall  LSTM_f1  \\\n",
       " 0              0.527778       0.529412             0.0          0.0      0.0   \n",
       " \n",
       "    LSTM_rocauc  \n",
       " 0          0.5  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_ZvZ.csv         0.6                0.588235   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                     0.75                0.1875               0.3   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0              0.565972  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_ZvZ.csv         0.6                0.588235   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                     0.75                0.1875               0.3   \n",
       " \n",
       "    NeuralNetwork_rocauc  LSTM_accuracy  LSTM_precision  LSTM_recall  LSTM_f1  \\\n",
       " 0              0.565972       0.441176        0.333333       0.1875     0.24   \n",
       " \n",
       "    LSTM_rocauc  \n",
       " 0     0.427083  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_ZvZ.csv         0.7                     0.5   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.470588                   0.5          0.484848   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0                   0.5  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_ZvZ.csv         0.7                     0.5   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.470588                   0.5          0.484848   \n",
       " \n",
       "    NeuralNetwork_rocauc  LSTM_accuracy  LSTM_precision  LSTM_recall  LSTM_f1  \\\n",
       " 0                   0.5       0.441176        0.333333       0.1875     0.24   \n",
       " \n",
       "    LSTM_rocauc  \n",
       " 0     0.427083  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_ZvZ.csv         0.8                0.558824   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.529412                0.5625          0.545455   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0              0.559028  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_ZvZ.csv         0.8                0.558824   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.529412                0.5625          0.545455   \n",
       " \n",
       "    NeuralNetwork_rocauc  LSTM_accuracy  LSTM_precision  LSTM_recall  LSTM_f1  \\\n",
       " 0              0.559028       0.441176        0.444444         0.75  0.55814   \n",
       " \n",
       "    LSTM_rocauc  \n",
       " 0     0.458333  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_ZvZ.csv         0.9                0.529412   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                      0.5                0.6875          0.578947   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0              0.538194  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_ZvZ.csv         0.9                0.529412   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                      0.5                0.6875          0.578947   \n",
       " \n",
       "    NeuralNetwork_rocauc  LSTM_accuracy  LSTM_precision  LSTM_recall   LSTM_f1  \\\n",
       " 0              0.538194       0.588235        0.545455         0.75  0.631579   \n",
       " \n",
       "    LSTM_rocauc  \n",
       " 0     0.597222  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_ZvZ.csv         1.0                0.794118   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.736842                 0.875               0.8   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0              0.798611  ,\n",
       "                          File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  1D_All_ReplaysData_ZvZ.csv         1.0                0.794118   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.736842                 0.875               0.8   \n",
       " \n",
       "    NeuralNetwork_rocauc  LSTM_accuracy  LSTM_precision  LSTM_recall  LSTM_f1  \\\n",
       " 0              0.798611       0.470588        0.458333       0.6875     0.55   \n",
       " \n",
       "    LSTM_rocauc  \n",
       " 0     0.482639  ,\n",
       "                              File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  StarCraft_Combined_Dataset.csv         0.1                 0.65493   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.662295              0.684746          0.673333   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0              0.653728  ,\n",
       "                              File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  StarCraft_Combined_Dataset.csv         0.1                 0.65493   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.662295              0.684746          0.673333   \n",
       " \n",
       "    NeuralNetwork_rocauc  LSTM_accuracy  LSTM_precision  LSTM_recall   LSTM_f1  \\\n",
       " 0              0.653728       0.517606        0.518584      0.99322  0.681395   \n",
       " \n",
       "    LSTM_rocauc  \n",
       " 0     0.498442  ,\n",
       "                              File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  StarCraft_Combined_Dataset.csv         0.2                0.658451   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                  0.66343              0.694915          0.678808   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0              0.656981  ,\n",
       "                              File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  StarCraft_Combined_Dataset.csv         0.2                0.658451   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                  0.66343              0.694915          0.678808   \n",
       " \n",
       "    NeuralNetwork_rocauc  LSTM_accuracy  LSTM_precision  LSTM_recall   LSTM_f1  \\\n",
       " 0              0.656981       0.522887         0.52214     0.959322  0.676225   \n",
       " \n",
       "    LSTM_rocauc  \n",
       " 0     0.505302  ,\n",
       "                              File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  StarCraft_Combined_Dataset.csv         0.3                0.669014   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.683849              0.674576          0.679181   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0               0.66879  ,\n",
       "                              File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  StarCraft_Combined_Dataset.csv         0.3                0.669014   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.683849              0.674576          0.679181   \n",
       " \n",
       "    NeuralNetwork_rocauc  LSTM_accuracy  LSTM_precision  LSTM_recall   LSTM_f1  \\\n",
       " 0               0.66879       0.505282        0.512821     0.949153  0.665874   \n",
       " \n",
       "    LSTM_rocauc  \n",
       " 0     0.487397  ,\n",
       "                              File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  StarCraft_Combined_Dataset.csv         0.4                0.684859   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.684713              0.728814          0.706076   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0              0.683088  ,\n",
       "                              File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  StarCraft_Combined_Dataset.csv         0.4                0.684859   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.684713              0.728814          0.706076   \n",
       " \n",
       "    NeuralNetwork_rocauc  LSTM_accuracy  LSTM_precision  LSTM_recall   LSTM_f1  \\\n",
       " 0              0.683088       0.517606        0.519553     0.945763  0.670673   \n",
       " \n",
       "    LSTM_rocauc  \n",
       " 0     0.500354  ,\n",
       "                              File  Percentile  NeuralNetwork_accuracy  \\\n",
       " 0  StarCraft_Combined_Dataset.csv         0.5                0.667254   \n",
       " \n",
       "    NeuralNetwork_precision  NeuralNetwork_recall  NeuralNetwork_f1  \\\n",
       " 0                 0.720833              0.586441          0.646729   \n",
       " \n",
       "    NeuralNetwork_rocauc  \n",
       " 0               0.67051  ]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhin\\AppData\\Local\\Temp\\ipykernel_31476\\801015304.py:13: FutureWarning: \n",
      "\n",
      "The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.\n",
      "\n",
      "  plot = sns.barplot(x='Metric', y='Score', hue='Model', data=df_long,  ci=None)\n",
      "c:\\Users\\abhin\\anaconda3\\envs\\DevelopmentEnv\\lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "c:\\Users\\abhin\\anaconda3\\envs\\DevelopmentEnv\\lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "c:\\Users\\abhin\\anaconda3\\envs\\DevelopmentEnv\\lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "c:\\Users\\abhin\\anaconda3\\envs\\DevelopmentEnv\\lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "df_long = pd.DataFrame()\n",
    "\n",
    "# Pivot the DataFrame for plotting\n",
    "df_long = pd.melt(df, id_vars=['File', 'Percentile'], var_name='Model_Metric', value_name='Score')\n",
    "\n",
    "# Split the 'Model_Metric' into separate 'Model' and 'Metric' columns\n",
    "df_long[['Model', 'Metric']] = df_long['Model_Metric'].str.rsplit('_', n=1, expand=True)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(15, 8))\n",
    "plot = sns.barplot(x='Metric', y='Score', hue='Model', data=df_long,  ci=None)\n",
    "# Add labels on top of each bar\n",
    "for p in plot.patches:\n",
    "    plot.annotate(format(p.get_height(), '.2f'),  # format the value\n",
    "                (p.get_x() + p.get_width() / 2., p.get_height()),  # position\n",
    "                ha='center', va='center',\n",
    "                xytext=(0, 10),  # 10 points vertical offset\n",
    "                textcoords='offset points')\n",
    "plt.title('Performance Metrics for Different Models')\n",
    "plt.xlabel('Metric')\n",
    "plt.ylabel('Score')\n",
    "plt.legend(title='Model', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "# Manually setting the x-ticks\n",
    "plot.set_xticks(range(len(['Accuracy', 'Precision', 'Recall', 'F1 Score', 'AU-ROC'])))\n",
    "plot.set_xticklabels(['Accuracy', 'Precision', 'Recall', 'F1 Score','AU-ROC'])\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Based Model Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhin\\anaconda3\\envs\\DevelopmentEnv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list to store DataFrames to concatenate later.\n",
    "df_list = []\n",
    "\n",
    "for file in files:\n",
    "    data = pd.read_csv('../Processed Datasets/' + file)\n",
    "    data = data[data['Winner'].isin([1, 2])]\n",
    "    data['Winner'] = data['Winner'].replace(1, 0)\n",
    "    data['Winner'] = data['Winner'].replace(2, 1)\n",
    "\n",
    "    label_encoders = {}\n",
    "    for column in ['ReplayID', 'Player1_Race', 'Player2_Race', 'MapName']:\n",
    "        label_encoders[column] = LabelEncoder()\n",
    "        data[column] = label_encoders[column].fit_transform(data[column])\n",
    "    # Apply the function to each group of 'ReplayID' and concatenate the results\n",
    "    nearest_rows = data[data['Frame'] == 1800*10]\n",
    "\n",
    "    # scaler = StandardScaler()\n",
    "    # nearest_rows[nearest_rows.columns.drop(['Winner'])] = scaler.fit_transform(nearest_rows[nearest_rows.columns.drop(['Winner'])])\n",
    "\n",
    "    X = nearest_rows.drop('Winner', axis=1)\n",
    "    y = nearest_rows['Winner']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    models = {\n",
    "        'RandomForest': RandomForestClassifier(bootstrap=False, criterion='entropy', max_depth=12, max_features=23, min_samples_split=30, random_state=63),\n",
    "        'LogisticRegression': LogisticRegression(solver='liblinear', max_iter=1000, C=0.1, penalty='l1'),\n",
    "        'SVM': svm.LinearSVC(C=0.00001, random_state=42, dual=False, max_iter=1000),\n",
    "        'KNN': KNeighborsClassifier(n_jobs=-1, n_neighbors=17, weights='distance'),\n",
    "    }\n",
    "\n",
    "    # Dictionary to hold scores for the models\n",
    "    scores_dict = {'File': file, 'Percentile': per / 10}\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        metrics = ['accuracy', 'precision', 'recall', 'f1']\n",
    "        scores = cross_validate(model, X, y, cv=5, scoring=metrics)\n",
    "        for metric in metrics:\n",
    "            scores_dict[f'{model_name}_{metric}'] = scores['test_' + metric].mean()\n",
    "        roc = cross_validate(model, X, y, cv=5, scoring=\"roc_auc\")\n",
    "        scores_dict[f'{model_name}_roc'] = roc['test_' + 'score'].mean()\n",
    "        \n",
    "\n",
    "    # Append the scores_dict as a DataFrame to df_list\n",
    "    df_list.append(pd.DataFrame([scores_dict]))\n",
    "\n",
    "df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Pivot the DataFrame for plotting\n",
    "df_long = pd.melt(df, id_vars=['File', 'Percentile'], var_name='Model_Metric', value_name='Score')\n",
    "\n",
    "# Split the 'Model_Metric' into separate 'Model' and 'Metric' columns\n",
    "df_long[['Model', 'Metric']] = df_long['Model_Metric'].str.rsplit('_', n=1, expand=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhin\\AppData\\Local\\Temp\\ipykernel_31476\\2494723424.py:3: FutureWarning: \n",
      "\n",
      "The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.\n",
      "\n",
      "  plot = sns.barplot(x='Metric', y='Score', hue='Model', data=df_long,  ci=None)\n",
      "c:\\Users\\abhin\\anaconda3\\envs\\DevelopmentEnv\\lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "c:\\Users\\abhin\\anaconda3\\envs\\DevelopmentEnv\\lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "c:\\Users\\abhin\\anaconda3\\envs\\DevelopmentEnv\\lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "c:\\Users\\abhin\\anaconda3\\envs\\DevelopmentEnv\\lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting\n",
    "plt.figure(figsize=(15, 8))\n",
    "plot = sns.barplot(x='Metric', y='Score', hue='Model', data=df_long,  ci=None)\n",
    "# Add labels on top of each bar\n",
    "for p in plot.patches:\n",
    "    plot.annotate(format(p.get_height(), '.2f'),  # format the value\n",
    "                (p.get_x() + p.get_width() / 2., p.get_height()),  # position\n",
    "                ha='center', va='center',\n",
    "                xytext=(0, 10),  # 10 points vertical offset\n",
    "                textcoords='offset points')\n",
    "plt.title('Performance Metrics for Different Models')\n",
    "plt.xlabel('Metric')\n",
    "plt.ylabel('Score')\n",
    "plt.legend(title='Model', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "# Manually setting the x-ticks\n",
    "plot.set_xticks(range(len(['Accuracy', 'Precision', 'Recall', 'F1 Score', 'AU-ROC'])))\n",
    "plot.set_xticklabels(['Accuracy', 'Precision', 'Recall', 'F1 Score', 'AU-ROC'])\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep learning time based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6938 - accuracy: 0.5216 - val_loss: 0.7466 - val_accuracy: 0.4068\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6974 - accuracy: 0.5172 - val_loss: 0.6983 - val_accuracy: 0.5254\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6814 - accuracy: 0.5776 - val_loss: 0.7429 - val_accuracy: 0.4068\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6588 - accuracy: 0.5819 - val_loss: 0.6882 - val_accuracy: 0.5424\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6814 - accuracy: 0.5302 - val_loss: 0.6855 - val_accuracy: 0.5424\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6336 - accuracy: 0.6336 - val_loss: 0.7575 - val_accuracy: 0.4237\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6295 - accuracy: 0.6767 - val_loss: 0.6793 - val_accuracy: 0.5424\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6163 - accuracy: 0.6595 - val_loss: 0.7230 - val_accuracy: 0.4746\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6158 - accuracy: 0.6552 - val_loss: 0.7442 - val_accuracy: 0.4915\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5859 - accuracy: 0.6681 - val_loss: 0.6804 - val_accuracy: 0.6441\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7488 - accuracy: 0.5000 - val_loss: 0.7141 - val_accuracy: 0.4068\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.7161 - accuracy: 0.5603 - val_loss: 0.7367 - val_accuracy: 0.4068\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.7179 - accuracy: 0.4828 - val_loss: 0.6913 - val_accuracy: 0.5763\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6792 - accuracy: 0.5862 - val_loss: 0.7344 - val_accuracy: 0.4237\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6545 - accuracy: 0.5948 - val_loss: 0.6979 - val_accuracy: 0.5593\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6641 - accuracy: 0.5905 - val_loss: 0.7126 - val_accuracy: 0.5254\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7204 - accuracy: 0.4871 - val_loss: 0.7754 - val_accuracy: 0.4068\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.7253 - accuracy: 0.5129 - val_loss: 0.7175 - val_accuracy: 0.3729\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6725 - accuracy: 0.5905 - val_loss: 0.7409 - val_accuracy: 0.4068\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6597 - accuracy: 0.6121 - val_loss: 0.7394 - val_accuracy: 0.3898\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6634 - accuracy: 0.5776 - val_loss: 0.7267 - val_accuracy: 0.4746\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 1s 92ms/step - loss: 0.7569 - accuracy: 0.5000 - val_loss: 0.7170 - val_accuracy: 0.4068\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6826 - accuracy: 0.5776 - val_loss: 0.7016 - val_accuracy: 0.4237\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6817 - accuracy: 0.5733 - val_loss: 0.7599 - val_accuracy: 0.3898\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6512 - accuracy: 0.5905 - val_loss: 0.7605 - val_accuracy: 0.3898\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6614 - accuracy: 0.5819 - val_loss: 0.7473 - val_accuracy: 0.4237\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7341 - accuracy: 0.5216 - val_loss: 0.6810 - val_accuracy: 0.5932\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6975 - accuracy: 0.5474 - val_loss: 0.7792 - val_accuracy: 0.4068\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6831 - accuracy: 0.5776 - val_loss: 0.7007 - val_accuracy: 0.4746\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6972 - accuracy: 0.5302 - val_loss: 0.6953 - val_accuracy: 0.5593\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7104 - accuracy: 0.5517 - val_loss: 0.6894 - val_accuracy: 0.5932\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6968 - accuracy: 0.5302 - val_loss: 0.7341 - val_accuracy: 0.4237\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6635 - accuracy: 0.5905 - val_loss: 0.7380 - val_accuracy: 0.4068\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6521 - accuracy: 0.6293 - val_loss: 0.7321 - val_accuracy: 0.4407\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7119 - accuracy: 0.4957 - val_loss: 0.7340 - val_accuracy: 0.4237\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6999 - accuracy: 0.5129 - val_loss: 0.7051 - val_accuracy: 0.4237\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6559 - accuracy: 0.6207 - val_loss: 0.7805 - val_accuracy: 0.4068\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6390 - accuracy: 0.6078 - val_loss: 0.7325 - val_accuracy: 0.4237\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6210 - accuracy: 0.6379 - val_loss: 0.7808 - val_accuracy: 0.4237\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7469 - accuracy: 0.4353 - val_loss: 0.6898 - val_accuracy: 0.4915\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6664 - accuracy: 0.5991 - val_loss: 0.7451 - val_accuracy: 0.3898\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6477 - accuracy: 0.5862 - val_loss: 0.7426 - val_accuracy: 0.4407\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6182 - accuracy: 0.6767 - val_loss: 0.7240 - val_accuracy: 0.5085\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7298 - accuracy: 0.4741 - val_loss: 0.7425 - val_accuracy: 0.4068\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6660 - accuracy: 0.6078 - val_loss: 0.6840 - val_accuracy: 0.6271\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6277 - accuracy: 0.6983 - val_loss: 0.7187 - val_accuracy: 0.4915\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5852 - accuracy: 0.6595 - val_loss: 0.6855 - val_accuracy: 0.5932\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5372 - accuracy: 0.7931 - val_loss: 0.6304 - val_accuracy: 0.7119\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5028 - accuracy: 0.7974 - val_loss: 0.6321 - val_accuracy: 0.7627\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4553 - accuracy: 0.8362 - val_loss: 0.5905 - val_accuracy: 0.7797\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3975 - accuracy: 0.8707 - val_loss: 0.6130 - val_accuracy: 0.7966\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3405 - accuracy: 0.9095 - val_loss: 0.6050 - val_accuracy: 0.7797\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3210 - accuracy: 0.9052 - val_loss: 0.5886 - val_accuracy: 0.7627\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2964 - accuracy: 0.9138 - val_loss: 0.6221 - val_accuracy: 0.7966\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2721 - accuracy: 0.9267 - val_loss: 0.6291 - val_accuracy: 0.7797\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2517 - accuracy: 0.9224 - val_loss: 0.6166 - val_accuracy: 0.7627\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6543 - accuracy: 0.6164 - val_loss: 0.6769 - val_accuracy: 0.4576\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6422 - accuracy: 0.6422 - val_loss: 0.6363 - val_accuracy: 0.7458\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5361 - accuracy: 0.8060 - val_loss: 0.6093 - val_accuracy: 0.7288\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4599 - accuracy: 0.8750 - val_loss: 0.5409 - val_accuracy: 0.8136\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4015 - accuracy: 0.8836 - val_loss: 0.5164 - val_accuracy: 0.8136\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3434 - accuracy: 0.8750 - val_loss: 0.4844 - val_accuracy: 0.8136\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2854 - accuracy: 0.9009 - val_loss: 0.4267 - val_accuracy: 0.8814\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2414 - accuracy: 0.9310 - val_loss: 0.4151 - val_accuracy: 0.8814\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2277 - accuracy: 0.9267 - val_loss: 0.4334 - val_accuracy: 0.8305\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1893 - accuracy: 0.9310 - val_loss: 0.4434 - val_accuracy: 0.8136\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1784 - accuracy: 0.9483 - val_loss: 0.4460 - val_accuracy: 0.7966\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.7402 - accuracy: 0.4785 - val_loss: 0.6760 - val_accuracy: 0.5426\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.7140 - accuracy: 0.5000 - val_loss: 0.6793 - val_accuracy: 0.5000\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.7081 - accuracy: 0.5833 - val_loss: 0.6556 - val_accuracy: 0.7021\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6995 - accuracy: 0.5242 - val_loss: 0.6478 - val_accuracy: 0.6809\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6701 - accuracy: 0.5726 - val_loss: 0.6365 - val_accuracy: 0.6915\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6414 - accuracy: 0.6263 - val_loss: 0.6191 - val_accuracy: 0.7447\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6379 - accuracy: 0.6317 - val_loss: 0.6089 - val_accuracy: 0.7766\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6021 - accuracy: 0.6935 - val_loss: 0.5995 - val_accuracy: 0.7766\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.5842 - accuracy: 0.6828 - val_loss: 0.5827 - val_accuracy: 0.7872\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5763 - accuracy: 0.7043 - val_loss: 0.5760 - val_accuracy: 0.7979\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.5671 - accuracy: 0.7016 - val_loss: 0.5741 - val_accuracy: 0.7660\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.5392 - accuracy: 0.7419 - val_loss: 0.5727 - val_accuracy: 0.7660\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.5385 - accuracy: 0.7151 - val_loss: 0.5664 - val_accuracy: 0.7340\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.5226 - accuracy: 0.7527 - val_loss: 0.5541 - val_accuracy: 0.7660\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5478 - accuracy: 0.7258 - val_loss: 0.5586 - val_accuracy: 0.7660\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.5271 - accuracy: 0.7392 - val_loss: 0.5643 - val_accuracy: 0.7447\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5063 - accuracy: 0.7500 - val_loss: 0.5641 - val_accuracy: 0.7447\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 1s 18ms/step - loss: 0.7155 - accuracy: 0.4892 - val_loss: 0.6762 - val_accuracy: 0.6170\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6969 - accuracy: 0.5511 - val_loss: 0.6701 - val_accuracy: 0.6702\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.6687 - accuracy: 0.5618 - val_loss: 0.6622 - val_accuracy: 0.6809\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6500 - accuracy: 0.6210 - val_loss: 0.6508 - val_accuracy: 0.7021\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6301 - accuracy: 0.6344 - val_loss: 0.6352 - val_accuracy: 0.7447\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6119 - accuracy: 0.6909 - val_loss: 0.6307 - val_accuracy: 0.7128\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5901 - accuracy: 0.7231 - val_loss: 0.6165 - val_accuracy: 0.6915\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5739 - accuracy: 0.7258 - val_loss: 0.6087 - val_accuracy: 0.7234\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5415 - accuracy: 0.7312 - val_loss: 0.6128 - val_accuracy: 0.6809\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.7849 - val_loss: 0.6195 - val_accuracy: 0.6596\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.4664 - accuracy: 0.7930 - val_loss: 0.6170 - val_accuracy: 0.6809\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.7140 - accuracy: 0.5054 - val_loss: 0.7036 - val_accuracy: 0.4787\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.6855 - accuracy: 0.5860 - val_loss: 0.6714 - val_accuracy: 0.5957\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6676 - accuracy: 0.5914 - val_loss: 0.6629 - val_accuracy: 0.6277\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.6580 - accuracy: 0.6156 - val_loss: 0.6527 - val_accuracy: 0.6596\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.6253 - accuracy: 0.6774 - val_loss: 0.6470 - val_accuracy: 0.7021\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.6066 - accuracy: 0.6882 - val_loss: 0.6321 - val_accuracy: 0.6596\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5794 - accuracy: 0.6882 - val_loss: 0.6342 - val_accuracy: 0.7128\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.5557 - accuracy: 0.7500 - val_loss: 0.6148 - val_accuracy: 0.6702\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5269 - accuracy: 0.7849 - val_loss: 0.6096 - val_accuracy: 0.6489\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.4963 - accuracy: 0.7930 - val_loss: 0.6165 - val_accuracy: 0.6596\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.4987 - accuracy: 0.7634 - val_loss: 0.6015 - val_accuracy: 0.6596\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.4524 - accuracy: 0.7849 - val_loss: 0.5936 - val_accuracy: 0.6915\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.4403 - accuracy: 0.7957 - val_loss: 0.6104 - val_accuracy: 0.6596\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.4409 - accuracy: 0.7957 - val_loss: 0.5796 - val_accuracy: 0.6702\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.4202 - accuracy: 0.8145 - val_loss: 0.6292 - val_accuracy: 0.6809\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.4126 - accuracy: 0.8226 - val_loss: 0.5928 - val_accuracy: 0.7021\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.4034 - accuracy: 0.8306 - val_loss: 0.5925 - val_accuracy: 0.7021\n",
      "4/4 [==============================] - 0s 0s/step\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.7299 - accuracy: 0.5269 - val_loss: 0.6751 - val_accuracy: 0.5319\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.7172 - accuracy: 0.5054 - val_loss: 0.6747 - val_accuracy: 0.5957\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6600 - accuracy: 0.5887 - val_loss: 0.6669 - val_accuracy: 0.5745\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.6290 - accuracy: 0.6747 - val_loss: 0.6872 - val_accuracy: 0.5213\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6263 - accuracy: 0.6586 - val_loss: 0.6690 - val_accuracy: 0.5957\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.5872 - accuracy: 0.6935 - val_loss: 0.6700 - val_accuracy: 0.6064\n",
      "4/4 [==============================] - 0s 6ms/step\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.7013 - accuracy: 0.5511 - val_loss: 0.7033 - val_accuracy: 0.4787\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5538 - val_loss: 0.6813 - val_accuracy: 0.5213\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6473 - accuracy: 0.6452 - val_loss: 0.6811 - val_accuracy: 0.6170\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.6288 - accuracy: 0.6532 - val_loss: 0.6733 - val_accuracy: 0.6064\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5975 - accuracy: 0.6909 - val_loss: 0.6657 - val_accuracy: 0.6064\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5527 - accuracy: 0.7527 - val_loss: 0.6760 - val_accuracy: 0.5957\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5031 - accuracy: 0.7903 - val_loss: 0.6558 - val_accuracy: 0.6277\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.4943 - accuracy: 0.7661 - val_loss: 0.6788 - val_accuracy: 0.5957\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.4587 - accuracy: 0.8306 - val_loss: 0.6618 - val_accuracy: 0.6702\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.4315 - accuracy: 0.8441 - val_loss: 0.6656 - val_accuracy: 0.6064\n",
      "4/4 [==============================] - 0s 0s/step\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.7098 - accuracy: 0.5323 - val_loss: 0.6848 - val_accuracy: 0.5745\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6921 - accuracy: 0.5457 - val_loss: 0.6727 - val_accuracy: 0.6489\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6562 - accuracy: 0.6048 - val_loss: 0.6630 - val_accuracy: 0.6596\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6244 - accuracy: 0.6801 - val_loss: 0.6646 - val_accuracy: 0.6489\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.5713 - accuracy: 0.7177 - val_loss: 0.6728 - val_accuracy: 0.6064\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.5502 - accuracy: 0.7366 - val_loss: 0.6760 - val_accuracy: 0.6489\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.7267 - accuracy: 0.5215 - val_loss: 0.6883 - val_accuracy: 0.4894\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.6660 - accuracy: 0.5645 - val_loss: 0.6533 - val_accuracy: 0.6277\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6466 - accuracy: 0.6210 - val_loss: 0.6460 - val_accuracy: 0.7340\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.5915 - accuracy: 0.7231 - val_loss: 0.6378 - val_accuracy: 0.7128\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.5679 - accuracy: 0.7554 - val_loss: 0.6304 - val_accuracy: 0.7128\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5266 - accuracy: 0.7715 - val_loss: 0.6061 - val_accuracy: 0.7340\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.5038 - accuracy: 0.8038 - val_loss: 0.6165 - val_accuracy: 0.7128\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.4774 - accuracy: 0.7930 - val_loss: 0.6171 - val_accuracy: 0.7447\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.4354 - accuracy: 0.8253 - val_loss: 0.6043 - val_accuracy: 0.7766\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.3952 - accuracy: 0.8602 - val_loss: 0.6052 - val_accuracy: 0.7766\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.3832 - accuracy: 0.8710 - val_loss: 0.6173 - val_accuracy: 0.7553\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.3555 - accuracy: 0.8763 - val_loss: 0.6323 - val_accuracy: 0.7553\n",
      "4/4 [==============================] - 0s 667us/step\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.7145 - accuracy: 0.5027 - val_loss: 0.6530 - val_accuracy: 0.7234\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.6679 - accuracy: 0.5887 - val_loss: 0.6308 - val_accuracy: 0.7340\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.6466 - accuracy: 0.6102 - val_loss: 0.6168 - val_accuracy: 0.7234\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.6260 - accuracy: 0.6183 - val_loss: 0.6012 - val_accuracy: 0.7660\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.5257 - accuracy: 0.7876 - val_loss: 0.5674 - val_accuracy: 0.8191\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.4754 - accuracy: 0.8253 - val_loss: 0.5428 - val_accuracy: 0.8191\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.4430 - accuracy: 0.8683 - val_loss: 0.5319 - val_accuracy: 0.8298\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.4055 - accuracy: 0.8656 - val_loss: 0.5204 - val_accuracy: 0.8085\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.3772 - accuracy: 0.8683 - val_loss: 0.5286 - val_accuracy: 0.7660\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.3537 - accuracy: 0.8737 - val_loss: 0.5135 - val_accuracy: 0.8298\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.3295 - accuracy: 0.8898 - val_loss: 0.5104 - val_accuracy: 0.8191\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.3116 - accuracy: 0.9086 - val_loss: 0.5236 - val_accuracy: 0.7979\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2950 - accuracy: 0.9059 - val_loss: 0.5352 - val_accuracy: 0.7979\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2984 - accuracy: 0.9059 - val_loss: 0.5300 - val_accuracy: 0.8085\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.7189 - accuracy: 0.5349 - val_loss: 0.6545 - val_accuracy: 0.5319\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.6440 - accuracy: 0.6102 - val_loss: 0.6063 - val_accuracy: 0.7340\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.5895 - accuracy: 0.7339 - val_loss: 0.5799 - val_accuracy: 0.8404\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5346 - accuracy: 0.8038 - val_loss: 0.5332 - val_accuracy: 0.8404\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.4695 - accuracy: 0.8280 - val_loss: 0.4832 - val_accuracy: 0.8404\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.4327 - accuracy: 0.8656 - val_loss: 0.4618 - val_accuracy: 0.8617\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.3946 - accuracy: 0.8737 - val_loss: 0.4230 - val_accuracy: 0.8617\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.3442 - accuracy: 0.8978 - val_loss: 0.4166 - val_accuracy: 0.8617\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.3144 - accuracy: 0.9059 - val_loss: 0.4122 - val_accuracy: 0.8404\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2987 - accuracy: 0.9220 - val_loss: 0.3986 - val_accuracy: 0.8511\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2866 - accuracy: 0.9086 - val_loss: 0.3865 - val_accuracy: 0.8617\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.2726 - accuracy: 0.9167 - val_loss: 0.3898 - val_accuracy: 0.8617\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.2643 - accuracy: 0.9194 - val_loss: 0.3995 - val_accuracy: 0.8511\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.2423 - accuracy: 0.9220 - val_loss: 0.4149 - val_accuracy: 0.8404\n",
      "4/4 [==============================] - 0s 0s/step\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.7115 - accuracy: 0.5242 - val_loss: 0.6141 - val_accuracy: 0.7553\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5993 - accuracy: 0.7258 - val_loss: 0.5569 - val_accuracy: 0.8404\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.5051 - accuracy: 0.8495 - val_loss: 0.4692 - val_accuracy: 0.9468\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.4174 - accuracy: 0.8898 - val_loss: 0.3771 - val_accuracy: 0.9362\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.3383 - accuracy: 0.9140 - val_loss: 0.3123 - val_accuracy: 0.9468\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2745 - accuracy: 0.9274 - val_loss: 0.2719 - val_accuracy: 0.9362\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2411 - accuracy: 0.9462 - val_loss: 0.2506 - val_accuracy: 0.9362\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2095 - accuracy: 0.9543 - val_loss: 0.2465 - val_accuracy: 0.9362\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2173 - accuracy: 0.9516 - val_loss: 0.2371 - val_accuracy: 0.9149\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1968 - accuracy: 0.9516 - val_loss: 0.2335 - val_accuracy: 0.9149\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1816 - accuracy: 0.9462 - val_loss: 0.2275 - val_accuracy: 0.9149\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1804 - accuracy: 0.9543 - val_loss: 0.2312 - val_accuracy: 0.9149\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1739 - accuracy: 0.9543 - val_loss: 0.2261 - val_accuracy: 0.9043\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1639 - accuracy: 0.9597 - val_loss: 0.2322 - val_accuracy: 0.9149\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1512 - accuracy: 0.9624 - val_loss: 0.2338 - val_accuracy: 0.9043\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1421 - accuracy: 0.9651 - val_loss: 0.2375 - val_accuracy: 0.8936\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7984 - accuracy: 0.5041 - val_loss: 0.7359 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.7140 - accuracy: 0.5366 - val_loss: 0.6922 - val_accuracy: 0.5000\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.7029 - accuracy: 0.5285 - val_loss: 0.7012 - val_accuracy: 0.5000\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6992 - accuracy: 0.5244 - val_loss: 0.6964 - val_accuracy: 0.4839\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6799 - accuracy: 0.5610 - val_loss: 0.6961 - val_accuracy: 0.5484\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7289 - accuracy: 0.4878 - val_loss: 0.7109 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.7131 - accuracy: 0.5000 - val_loss: 0.7064 - val_accuracy: 0.5000\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6832 - accuracy: 0.5325 - val_loss: 0.7074 - val_accuracy: 0.5000\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6977 - accuracy: 0.5366 - val_loss: 0.7110 - val_accuracy: 0.4839\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6770 - accuracy: 0.5650 - val_loss: 0.7131 - val_accuracy: 0.4032\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7175 - accuracy: 0.5244 - val_loss: 0.7214 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6930 - accuracy: 0.5407 - val_loss: 0.7068 - val_accuracy: 0.4839\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.7022 - accuracy: 0.5285 - val_loss: 0.7081 - val_accuracy: 0.4194\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6822 - accuracy: 0.5854 - val_loss: 0.7166 - val_accuracy: 0.4355\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6654 - accuracy: 0.6098 - val_loss: 0.7216 - val_accuracy: 0.4839\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7295 - accuracy: 0.4512 - val_loss: 0.6959 - val_accuracy: 0.4677\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.7037 - accuracy: 0.5325 - val_loss: 0.6943 - val_accuracy: 0.5161\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6935 - accuracy: 0.5488 - val_loss: 0.6947 - val_accuracy: 0.5161\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6899 - accuracy: 0.5488 - val_loss: 0.6940 - val_accuracy: 0.5484\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6627 - accuracy: 0.5935 - val_loss: 0.6957 - val_accuracy: 0.5161\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6818 - accuracy: 0.5772 - val_loss: 0.6954 - val_accuracy: 0.5484\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6603 - accuracy: 0.6138 - val_loss: 0.7062 - val_accuracy: 0.4839\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7149 - accuracy: 0.5244 - val_loss: 0.7107 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.7142 - accuracy: 0.4878 - val_loss: 0.7091 - val_accuracy: 0.4677\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.7006 - accuracy: 0.5285 - val_loss: 0.7052 - val_accuracy: 0.4839\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6883 - accuracy: 0.5488 - val_loss: 0.7064 - val_accuracy: 0.4839\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6771 - accuracy: 0.5488 - val_loss: 0.7054 - val_accuracy: 0.4839\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6777 - accuracy: 0.5935 - val_loss: 0.7092 - val_accuracy: 0.4839\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 1s 24ms/step - loss: 0.7038 - accuracy: 0.5285 - val_loss: 0.7099 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.7217 - accuracy: 0.5081 - val_loss: 0.7110 - val_accuracy: 0.5000\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.7275 - accuracy: 0.4878 - val_loss: 0.7021 - val_accuracy: 0.4516\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.7023 - accuracy: 0.5122 - val_loss: 0.7052 - val_accuracy: 0.5000\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6807 - accuracy: 0.5488 - val_loss: 0.7014 - val_accuracy: 0.4839\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6546 - accuracy: 0.6260 - val_loss: 0.7057 - val_accuracy: 0.5484\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6295 - accuracy: 0.6382 - val_loss: 0.7069 - val_accuracy: 0.5323\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6118 - accuracy: 0.6667 - val_loss: 0.7150 - val_accuracy: 0.4839\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7206 - accuracy: 0.4512 - val_loss: 0.6981 - val_accuracy: 0.4355\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.7332 - accuracy: 0.4878 - val_loss: 0.7104 - val_accuracy: 0.5000\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.7002 - accuracy: 0.5610 - val_loss: 0.7177 - val_accuracy: 0.5000\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6981 - accuracy: 0.5447 - val_loss: 0.7093 - val_accuracy: 0.5000\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7875 - accuracy: 0.4472 - val_loss: 0.7286 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.7261 - accuracy: 0.4715 - val_loss: 0.6997 - val_accuracy: 0.5323\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6777 - accuracy: 0.5935 - val_loss: 0.7018 - val_accuracy: 0.4839\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6948 - accuracy: 0.5447 - val_loss: 0.7044 - val_accuracy: 0.4355\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.7129 - accuracy: 0.5244 - val_loss: 0.7081 - val_accuracy: 0.4516\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7111 - accuracy: 0.4959 - val_loss: 0.6924 - val_accuracy: 0.5484\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.7135 - accuracy: 0.5488 - val_loss: 0.6888 - val_accuracy: 0.5000\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6888 - accuracy: 0.5325 - val_loss: 0.6986 - val_accuracy: 0.4839\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6718 - accuracy: 0.5732 - val_loss: 0.6982 - val_accuracy: 0.5161\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6607 - accuracy: 0.5976 - val_loss: 0.6936 - val_accuracy: 0.5000\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7438 - accuracy: 0.5407 - val_loss: 0.6944 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6986 - accuracy: 0.5325 - val_loss: 0.6885 - val_accuracy: 0.5323\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6959 - accuracy: 0.5325 - val_loss: 0.6857 - val_accuracy: 0.5645\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6642 - accuracy: 0.5854 - val_loss: 0.6772 - val_accuracy: 0.5161\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6683 - accuracy: 0.5976 - val_loss: 0.6665 - val_accuracy: 0.6452\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6275 - accuracy: 0.6423 - val_loss: 0.6518 - val_accuracy: 0.6774\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6012 - accuracy: 0.7114 - val_loss: 0.6428 - val_accuracy: 0.6129\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5761 - accuracy: 0.7439 - val_loss: 0.6288 - val_accuracy: 0.7742\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5593 - accuracy: 0.7561 - val_loss: 0.6222 - val_accuracy: 0.6452\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5201 - accuracy: 0.7764 - val_loss: 0.6091 - val_accuracy: 0.7097\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4884 - accuracy: 0.7886 - val_loss: 0.6035 - val_accuracy: 0.6613\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4640 - accuracy: 0.7967 - val_loss: 0.5956 - val_accuracy: 0.7258\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4163 - accuracy: 0.8537 - val_loss: 0.5965 - val_accuracy: 0.6774\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4220 - accuracy: 0.8130 - val_loss: 0.5840 - val_accuracy: 0.6774\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3859 - accuracy: 0.8252 - val_loss: 0.5890 - val_accuracy: 0.6613\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3637 - accuracy: 0.8659 - val_loss: 0.5921 - val_accuracy: 0.7097\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3576 - accuracy: 0.8618 - val_loss: 0.5911 - val_accuracy: 0.6774\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7225 - accuracy: 0.5102 - val_loss: 0.7111 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6883 - accuracy: 0.5347 - val_loss: 0.6915 - val_accuracy: 0.5000\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.7047 - accuracy: 0.5020 - val_loss: 0.6707 - val_accuracy: 0.6774\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6855 - accuracy: 0.5755 - val_loss: 0.6673 - val_accuracy: 0.5323\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6568 - accuracy: 0.6122 - val_loss: 0.6615 - val_accuracy: 0.5806\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6358 - accuracy: 0.6286 - val_loss: 0.6437 - val_accuracy: 0.6452\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6430 - accuracy: 0.6327 - val_loss: 0.6347 - val_accuracy: 0.7258\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6134 - accuracy: 0.6980 - val_loss: 0.6241 - val_accuracy: 0.6774\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5893 - accuracy: 0.7143 - val_loss: 0.6134 - val_accuracy: 0.7258\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6068 - accuracy: 0.6939 - val_loss: 0.6041 - val_accuracy: 0.7419\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5928 - accuracy: 0.6735 - val_loss: 0.5996 - val_accuracy: 0.7258\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5509 - accuracy: 0.7102 - val_loss: 0.5899 - val_accuracy: 0.7258\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5638 - accuracy: 0.7020 - val_loss: 0.5854 - val_accuracy: 0.7419\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5631 - accuracy: 0.7306 - val_loss: 0.5898 - val_accuracy: 0.7419\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5528 - accuracy: 0.7347 - val_loss: 0.5843 - val_accuracy: 0.7258\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5557 - accuracy: 0.6898 - val_loss: 0.5975 - val_accuracy: 0.7419\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5353 - accuracy: 0.7224 - val_loss: 0.5872 - val_accuracy: 0.7581\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5457 - accuracy: 0.7102 - val_loss: 0.5914 - val_accuracy: 0.7419\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7086 - accuracy: 0.5347 - val_loss: 0.6945 - val_accuracy: 0.4677\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6824 - accuracy: 0.5469 - val_loss: 0.6851 - val_accuracy: 0.5161\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6706 - accuracy: 0.5714 - val_loss: 0.6798 - val_accuracy: 0.5806\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6813 - accuracy: 0.5714 - val_loss: 0.6843 - val_accuracy: 0.6452\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6428 - accuracy: 0.6490 - val_loss: 0.6719 - val_accuracy: 0.5484\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6581 - accuracy: 0.6041 - val_loss: 0.6677 - val_accuracy: 0.6935\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6093 - accuracy: 0.6980 - val_loss: 0.6542 - val_accuracy: 0.7097\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6137 - accuracy: 0.6327 - val_loss: 0.6520 - val_accuracy: 0.6129\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5683 - accuracy: 0.7102 - val_loss: 0.6533 - val_accuracy: 0.6613\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5613 - accuracy: 0.6980 - val_loss: 0.6321 - val_accuracy: 0.6774\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5496 - accuracy: 0.7224 - val_loss: 0.6196 - val_accuracy: 0.7419\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5348 - accuracy: 0.7224 - val_loss: 0.6105 - val_accuracy: 0.7258\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5091 - accuracy: 0.7469 - val_loss: 0.6024 - val_accuracy: 0.7581\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4907 - accuracy: 0.7959 - val_loss: 0.5962 - val_accuracy: 0.7258\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4921 - accuracy: 0.8000 - val_loss: 0.5994 - val_accuracy: 0.7258\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4768 - accuracy: 0.7714 - val_loss: 0.5916 - val_accuracy: 0.7258\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4558 - accuracy: 0.7837 - val_loss: 0.5800 - val_accuracy: 0.7419\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4383 - accuracy: 0.8122 - val_loss: 0.5844 - val_accuracy: 0.7258\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4363 - accuracy: 0.7837 - val_loss: 0.5893 - val_accuracy: 0.7581\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4120 - accuracy: 0.8204 - val_loss: 0.5849 - val_accuracy: 0.7097\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7214 - accuracy: 0.5388 - val_loss: 0.6900 - val_accuracy: 0.5161\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.7020 - accuracy: 0.5265 - val_loss: 0.6822 - val_accuracy: 0.5645\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6604 - accuracy: 0.6245 - val_loss: 0.6745 - val_accuracy: 0.6452\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6497 - accuracy: 0.6327 - val_loss: 0.6663 - val_accuracy: 0.6452\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6529 - accuracy: 0.6163 - val_loss: 0.6579 - val_accuracy: 0.7742\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6418 - accuracy: 0.6367 - val_loss: 0.6536 - val_accuracy: 0.5645\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6182 - accuracy: 0.6776 - val_loss: 0.6452 - val_accuracy: 0.7419\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5914 - accuracy: 0.6857 - val_loss: 0.6312 - val_accuracy: 0.7419\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5788 - accuracy: 0.7102 - val_loss: 0.6214 - val_accuracy: 0.7742\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5700 - accuracy: 0.6857 - val_loss: 0.6135 - val_accuracy: 0.7903\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5397 - accuracy: 0.7714 - val_loss: 0.6063 - val_accuracy: 0.7903\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5066 - accuracy: 0.7755 - val_loss: 0.6016 - val_accuracy: 0.7742\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5029 - accuracy: 0.7633 - val_loss: 0.5993 - val_accuracy: 0.7581\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5025 - accuracy: 0.7714 - val_loss: 0.5980 - val_accuracy: 0.7419\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4766 - accuracy: 0.7592 - val_loss: 0.5972 - val_accuracy: 0.7419\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4499 - accuracy: 0.8000 - val_loss: 0.5997 - val_accuracy: 0.7419\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4328 - accuracy: 0.8245 - val_loss: 0.6035 - val_accuracy: 0.7419\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4279 - accuracy: 0.7837 - val_loss: 0.6101 - val_accuracy: 0.7258\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 1s 97ms/step - loss: 0.7439 - accuracy: 0.4490 - val_loss: 0.6920 - val_accuracy: 0.5323\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.7394 - accuracy: 0.5020 - val_loss: 0.6835 - val_accuracy: 0.6613\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5306 - val_loss: 0.6876 - val_accuracy: 0.5161\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6991 - accuracy: 0.5143 - val_loss: 0.6809 - val_accuracy: 0.5323\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6491 - accuracy: 0.6041 - val_loss: 0.6664 - val_accuracy: 0.5806\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6389 - accuracy: 0.6367 - val_loss: 0.6573 - val_accuracy: 0.6774\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6087 - accuracy: 0.6531 - val_loss: 0.6478 - val_accuracy: 0.7581\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6018 - accuracy: 0.7061 - val_loss: 0.6400 - val_accuracy: 0.6935\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5783 - accuracy: 0.7020 - val_loss: 0.6344 - val_accuracy: 0.7581\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5796 - accuracy: 0.7061 - val_loss: 0.6324 - val_accuracy: 0.6774\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5538 - accuracy: 0.7224 - val_loss: 0.6264 - val_accuracy: 0.7581\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5213 - accuracy: 0.7551 - val_loss: 0.6195 - val_accuracy: 0.7258\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5151 - accuracy: 0.7510 - val_loss: 0.6179 - val_accuracy: 0.7419\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4856 - accuracy: 0.7837 - val_loss: 0.6191 - val_accuracy: 0.7581\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4883 - accuracy: 0.7429 - val_loss: 0.6239 - val_accuracy: 0.7419\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4783 - accuracy: 0.7673 - val_loss: 0.6280 - val_accuracy: 0.7581\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.8183 - accuracy: 0.4408 - val_loss: 0.7425 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.7302 - accuracy: 0.4980 - val_loss: 0.6920 - val_accuracy: 0.4677\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.7095 - accuracy: 0.5143 - val_loss: 0.6903 - val_accuracy: 0.5161\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6447 - accuracy: 0.6367 - val_loss: 0.6921 - val_accuracy: 0.4839\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6543 - accuracy: 0.6041 - val_loss: 0.6781 - val_accuracy: 0.5323\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.6208 - accuracy: 0.6571 - val_loss: 0.6770 - val_accuracy: 0.7419\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6010 - accuracy: 0.6980 - val_loss: 0.6724 - val_accuracy: 0.5323\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5792 - accuracy: 0.6612 - val_loss: 0.6586 - val_accuracy: 0.7097\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5608 - accuracy: 0.6898 - val_loss: 0.6543 - val_accuracy: 0.5806\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5571 - accuracy: 0.7184 - val_loss: 0.6468 - val_accuracy: 0.6935\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5217 - accuracy: 0.7265 - val_loss: 0.6457 - val_accuracy: 0.6935\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5139 - accuracy: 0.7510 - val_loss: 0.6444 - val_accuracy: 0.5968\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4885 - accuracy: 0.7878 - val_loss: 0.6372 - val_accuracy: 0.6935\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4566 - accuracy: 0.8000 - val_loss: 0.6356 - val_accuracy: 0.6935\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4498 - accuracy: 0.8041 - val_loss: 0.6416 - val_accuracy: 0.6935\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4606 - accuracy: 0.7633 - val_loss: 0.6508 - val_accuracy: 0.6290\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4374 - accuracy: 0.8082 - val_loss: 0.6501 - val_accuracy: 0.6613\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7393 - accuracy: 0.4857 - val_loss: 0.6905 - val_accuracy: 0.5161\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.7063 - accuracy: 0.5102 - val_loss: 0.6787 - val_accuracy: 0.5323\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6561 - accuracy: 0.6122 - val_loss: 0.6638 - val_accuracy: 0.7258\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6363 - accuracy: 0.6735 - val_loss: 0.6525 - val_accuracy: 0.7419\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6128 - accuracy: 0.6694 - val_loss: 0.6395 - val_accuracy: 0.6613\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5861 - accuracy: 0.7020 - val_loss: 0.6240 - val_accuracy: 0.7742\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5633 - accuracy: 0.7224 - val_loss: 0.6035 - val_accuracy: 0.7581\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5407 - accuracy: 0.7796 - val_loss: 0.5953 - val_accuracy: 0.6774\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5001 - accuracy: 0.7714 - val_loss: 0.5822 - val_accuracy: 0.7258\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4969 - accuracy: 0.7959 - val_loss: 0.5685 - val_accuracy: 0.7581\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4447 - accuracy: 0.8327 - val_loss: 0.5651 - val_accuracy: 0.7581\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4133 - accuracy: 0.8531 - val_loss: 0.5700 - val_accuracy: 0.6613\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4251 - accuracy: 0.8531 - val_loss: 0.5553 - val_accuracy: 0.7097\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4019 - accuracy: 0.8367 - val_loss: 0.5613 - val_accuracy: 0.7097\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3913 - accuracy: 0.8531 - val_loss: 0.5726 - val_accuracy: 0.7258\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3877 - accuracy: 0.8286 - val_loss: 0.5647 - val_accuracy: 0.7419\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7301 - accuracy: 0.5020 - val_loss: 0.6808 - val_accuracy: 0.5968\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.7085 - accuracy: 0.5184 - val_loss: 0.6832 - val_accuracy: 0.5000\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6662 - accuracy: 0.5918 - val_loss: 0.6682 - val_accuracy: 0.5323\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6302 - accuracy: 0.6898 - val_loss: 0.6409 - val_accuracy: 0.7581\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5996 - accuracy: 0.7265 - val_loss: 0.6265 - val_accuracy: 0.6452\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5357 - accuracy: 0.8122 - val_loss: 0.6041 - val_accuracy: 0.7097\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5300 - accuracy: 0.7959 - val_loss: 0.5895 - val_accuracy: 0.7742\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4953 - accuracy: 0.8286 - val_loss: 0.5788 - val_accuracy: 0.6613\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4756 - accuracy: 0.8163 - val_loss: 0.5572 - val_accuracy: 0.7097\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4210 - accuracy: 0.8408 - val_loss: 0.5468 - val_accuracy: 0.7258\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3932 - accuracy: 0.8531 - val_loss: 0.5434 - val_accuracy: 0.7097\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3810 - accuracy: 0.8531 - val_loss: 0.5403 - val_accuracy: 0.7097\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3379 - accuracy: 0.8694 - val_loss: 0.5285 - val_accuracy: 0.7258\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3188 - accuracy: 0.8939 - val_loss: 0.5342 - val_accuracy: 0.7097\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3085 - accuracy: 0.8857 - val_loss: 0.5457 - val_accuracy: 0.7419\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3010 - accuracy: 0.8776 - val_loss: 0.5539 - val_accuracy: 0.7258\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7168 - accuracy: 0.5673 - val_loss: 0.7024 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6634 - accuracy: 0.6122 - val_loss: 0.6623 - val_accuracy: 0.5000\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6741 - accuracy: 0.5306 - val_loss: 0.6163 - val_accuracy: 0.7581\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6176 - accuracy: 0.6816 - val_loss: 0.5849 - val_accuracy: 0.7742\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5426 - accuracy: 0.7755 - val_loss: 0.5519 - val_accuracy: 0.8387\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5122 - accuracy: 0.7918 - val_loss: 0.5198 - val_accuracy: 0.8065\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4652 - accuracy: 0.8245 - val_loss: 0.4966 - val_accuracy: 0.7581\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4250 - accuracy: 0.8367 - val_loss: 0.4695 - val_accuracy: 0.8226\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4000 - accuracy: 0.8327 - val_loss: 0.4551 - val_accuracy: 0.8226\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3678 - accuracy: 0.8571 - val_loss: 0.4392 - val_accuracy: 0.8710\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3433 - accuracy: 0.8694 - val_loss: 0.4398 - val_accuracy: 0.8387\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3246 - accuracy: 0.8816 - val_loss: 0.4487 - val_accuracy: 0.7742\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2989 - accuracy: 0.8980 - val_loss: 0.4401 - val_accuracy: 0.8226\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7000 - accuracy: 0.5184 - val_loss: 0.6524 - val_accuracy: 0.6935\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6549 - accuracy: 0.6204 - val_loss: 0.6183 - val_accuracy: 0.8226\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5999 - accuracy: 0.6776 - val_loss: 0.5864 - val_accuracy: 0.7097\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5422 - accuracy: 0.7714 - val_loss: 0.5437 - val_accuracy: 0.8065\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4837 - accuracy: 0.8571 - val_loss: 0.5093 - val_accuracy: 0.8065\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4304 - accuracy: 0.8531 - val_loss: 0.4772 - val_accuracy: 0.7903\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3996 - accuracy: 0.8735 - val_loss: 0.4750 - val_accuracy: 0.7581\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3702 - accuracy: 0.8531 - val_loss: 0.4489 - val_accuracy: 0.8065\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3111 - accuracy: 0.9143 - val_loss: 0.4496 - val_accuracy: 0.8226\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2819 - accuracy: 0.9224 - val_loss: 0.4507 - val_accuracy: 0.7742\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2718 - accuracy: 0.9224 - val_loss: 0.4447 - val_accuracy: 0.7742\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2561 - accuracy: 0.9143 - val_loss: 0.4435 - val_accuracy: 0.7742\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2407 - accuracy: 0.9306 - val_loss: 0.4585 - val_accuracy: 0.7742\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2382 - accuracy: 0.9265 - val_loss: 0.4723 - val_accuracy: 0.7742\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2098 - accuracy: 0.9224 - val_loss: 0.4874 - val_accuracy: 0.7742\n",
      "3/3 [==============================] - 0s 500us/step\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6718 - accuracy: 0.5633 - val_loss: 0.6719 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6289 - accuracy: 0.6367 - val_loss: 0.6038 - val_accuracy: 0.7581\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5616 - accuracy: 0.7143 - val_loss: 0.5368 - val_accuracy: 0.8065\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4618 - accuracy: 0.8694 - val_loss: 0.4777 - val_accuracy: 0.8226\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3949 - accuracy: 0.8776 - val_loss: 0.4180 - val_accuracy: 0.8387\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3161 - accuracy: 0.9429 - val_loss: 0.3674 - val_accuracy: 0.8387\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2647 - accuracy: 0.9184 - val_loss: 0.3379 - val_accuracy: 0.8387\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2414 - accuracy: 0.9469 - val_loss: 0.3192 - val_accuracy: 0.8226\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.2120 - accuracy: 0.9429 - val_loss: 0.3039 - val_accuracy: 0.8548\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1909 - accuracy: 0.9388 - val_loss: 0.2930 - val_accuracy: 0.8548\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1835 - accuracy: 0.9469 - val_loss: 0.2915 - val_accuracy: 0.8548\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1711 - accuracy: 0.9633 - val_loss: 0.2847 - val_accuracy: 0.8387\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1627 - accuracy: 0.9469 - val_loss: 0.2932 - val_accuracy: 0.8548\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1401 - accuracy: 0.9551 - val_loss: 0.3005 - val_accuracy: 0.8387\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1067 - accuracy: 0.9796 - val_loss: 0.2922 - val_accuracy: 0.8548\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.7677 - accuracy: 0.4865 - val_loss: 0.6455 - val_accuracy: 0.6607\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.7315 - accuracy: 0.4685 - val_loss: 0.7691 - val_accuracy: 0.3393\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.7180 - accuracy: 0.4865 - val_loss: 0.6463 - val_accuracy: 0.6607\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.7186 - accuracy: 0.5405 - val_loss: 0.6444 - val_accuracy: 0.6607\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6952 - accuracy: 0.5270 - val_loss: 0.7229 - val_accuracy: 0.3393\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6910 - accuracy: 0.5450 - val_loss: 0.6568 - val_accuracy: 0.6429\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6960 - accuracy: 0.5991 - val_loss: 0.6684 - val_accuracy: 0.6429\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.7693 - accuracy: 0.4775 - val_loss: 0.7835 - val_accuracy: 0.3393\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.7222 - accuracy: 0.5180 - val_loss: 0.6502 - val_accuracy: 0.6607\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.7009 - accuracy: 0.5495 - val_loss: 0.6506 - val_accuracy: 0.6607\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6834 - accuracy: 0.5676 - val_loss: 0.7128 - val_accuracy: 0.3750\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6837 - accuracy: 0.5586 - val_loss: 0.6741 - val_accuracy: 0.6250\n",
      "3/3 [==============================] - 0s 662us/step\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.7026 - accuracy: 0.5135 - val_loss: 0.7020 - val_accuracy: 0.4286\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6826 - accuracy: 0.5586 - val_loss: 0.6636 - val_accuracy: 0.6429\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6978 - accuracy: 0.5135 - val_loss: 0.6767 - val_accuracy: 0.5893\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6972 - accuracy: 0.5541 - val_loss: 0.6500 - val_accuracy: 0.6607\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6857 - accuracy: 0.5495 - val_loss: 0.6943 - val_accuracy: 0.5179\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6702 - accuracy: 0.5766 - val_loss: 0.6719 - val_accuracy: 0.6071\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6544 - accuracy: 0.6216 - val_loss: 0.6563 - val_accuracy: 0.6429\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.7612 - accuracy: 0.4414 - val_loss: 0.6879 - val_accuracy: 0.5893\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.7110 - accuracy: 0.5450 - val_loss: 0.6488 - val_accuracy: 0.6607\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6918 - accuracy: 0.5225 - val_loss: 0.7172 - val_accuracy: 0.3393\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6580 - accuracy: 0.6171 - val_loss: 0.6747 - val_accuracy: 0.6250\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.6468 - accuracy: 0.6577 - val_loss: 0.6770 - val_accuracy: 0.5536\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.7015 - accuracy: 0.5270 - val_loss: 0.7051 - val_accuracy: 0.3571\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7275 - accuracy: 0.5270 - val_loss: 0.6491 - val_accuracy: 0.6607\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6981 - accuracy: 0.5360 - val_loss: 0.6878 - val_accuracy: 0.5357\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6748 - accuracy: 0.5766 - val_loss: 0.6947 - val_accuracy: 0.5000\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6583 - accuracy: 0.5721 - val_loss: 0.6610 - val_accuracy: 0.6250\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.7286 - accuracy: 0.5045 - val_loss: 0.7247 - val_accuracy: 0.3750\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.7028 - accuracy: 0.5045 - val_loss: 0.6441 - val_accuracy: 0.6607\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.7218 - accuracy: 0.5225 - val_loss: 0.6492 - val_accuracy: 0.6786\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6727 - accuracy: 0.5721 - val_loss: 0.6903 - val_accuracy: 0.5357\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6803 - accuracy: 0.5766 - val_loss: 0.6563 - val_accuracy: 0.6250\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.7411 - accuracy: 0.4685 - val_loss: 0.7590 - val_accuracy: 0.3393\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.7055 - accuracy: 0.5270 - val_loss: 0.6469 - val_accuracy: 0.6607\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6891 - accuracy: 0.5405 - val_loss: 0.6611 - val_accuracy: 0.6429\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6728 - accuracy: 0.5676 - val_loss: 0.6863 - val_accuracy: 0.5536\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6530 - accuracy: 0.6216 - val_loss: 0.6648 - val_accuracy: 0.5714\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.7145 - accuracy: 0.5000 - val_loss: 0.6350 - val_accuracy: 0.6607\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.7211 - accuracy: 0.5180 - val_loss: 0.6753 - val_accuracy: 0.5536\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.7101 - accuracy: 0.4865 - val_loss: 0.6879 - val_accuracy: 0.5179\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6705 - accuracy: 0.5901 - val_loss: 0.6517 - val_accuracy: 0.6429\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.7377 - accuracy: 0.5135 - val_loss: 0.7471 - val_accuracy: 0.3393\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.7195 - accuracy: 0.5000 - val_loss: 0.6612 - val_accuracy: 0.6607\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6736 - accuracy: 0.6216 - val_loss: 0.6648 - val_accuracy: 0.6429\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6534 - accuracy: 0.6306 - val_loss: 0.6787 - val_accuracy: 0.5357\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6634 - accuracy: 0.5676 - val_loss: 0.6514 - val_accuracy: 0.6071\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6500 - accuracy: 0.6171 - val_loss: 0.6666 - val_accuracy: 0.5536\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6313 - accuracy: 0.6396 - val_loss: 0.6901 - val_accuracy: 0.5179\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6087 - accuracy: 0.6667 - val_loss: 0.6544 - val_accuracy: 0.5893\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.7425 - accuracy: 0.4685 - val_loss: 0.6475 - val_accuracy: 0.6607\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.6939 - accuracy: 0.5586 - val_loss: 0.6796 - val_accuracy: 0.6429\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6848 - accuracy: 0.5586 - val_loss: 0.6464 - val_accuracy: 0.6429\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6266 - accuracy: 0.6532 - val_loss: 0.6184 - val_accuracy: 0.6607\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6242 - accuracy: 0.7117 - val_loss: 0.6370 - val_accuracy: 0.6250\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.5985 - accuracy: 0.7477 - val_loss: 0.6259 - val_accuracy: 0.6786\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.5620 - accuracy: 0.7477 - val_loss: 0.5807 - val_accuracy: 0.6607\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.5353 - accuracy: 0.7387 - val_loss: 0.5798 - val_accuracy: 0.6964\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5045 - accuracy: 0.7883 - val_loss: 0.5603 - val_accuracy: 0.6964\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4802 - accuracy: 0.7838 - val_loss: 0.5630 - val_accuracy: 0.6786\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4494 - accuracy: 0.8288 - val_loss: 0.5352 - val_accuracy: 0.7143\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4096 - accuracy: 0.8468 - val_loss: 0.5399 - val_accuracy: 0.6786\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4003 - accuracy: 0.8333 - val_loss: 0.5260 - val_accuracy: 0.6964\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3680 - accuracy: 0.8559 - val_loss: 0.5374 - val_accuracy: 0.6786\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3363 - accuracy: 0.8874 - val_loss: 0.5167 - val_accuracy: 0.7143\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3372 - accuracy: 0.8604 - val_loss: 0.5247 - val_accuracy: 0.7143\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3388 - accuracy: 0.8468 - val_loss: 0.5366 - val_accuracy: 0.6964\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3184 - accuracy: 0.8784 - val_loss: 0.5214 - val_accuracy: 0.6964\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 1s 46ms/step - loss: 0.8695 - accuracy: 0.4673 - val_loss: 0.6897 - val_accuracy: 0.5556\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6896 - accuracy: 0.5701 - val_loss: 0.7679 - val_accuracy: 0.5556\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7870 - accuracy: 0.5234 - val_loss: 0.7416 - val_accuracy: 0.5556\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7181 - accuracy: 0.5514 - val_loss: 0.6843 - val_accuracy: 0.5556\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6743 - accuracy: 0.5701 - val_loss: 0.6848 - val_accuracy: 0.4815\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6776 - accuracy: 0.6355 - val_loss: 0.6964 - val_accuracy: 0.4815\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6772 - accuracy: 0.5794 - val_loss: 0.6834 - val_accuracy: 0.4444\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6841 - accuracy: 0.5421 - val_loss: 0.6691 - val_accuracy: 0.6296\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7058 - accuracy: 0.4860 - val_loss: 0.6655 - val_accuracy: 0.6296\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6569 - accuracy: 0.5794 - val_loss: 0.6625 - val_accuracy: 0.5926\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6907 - accuracy: 0.5607 - val_loss: 0.6608 - val_accuracy: 0.6667\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6866 - accuracy: 0.5514 - val_loss: 0.6614 - val_accuracy: 0.7037\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6930 - accuracy: 0.5701 - val_loss: 0.6578 - val_accuracy: 0.7407\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6465 - accuracy: 0.6075 - val_loss: 0.6512 - val_accuracy: 0.6667\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6144 - accuracy: 0.6636 - val_loss: 0.6473 - val_accuracy: 0.6296\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6413 - accuracy: 0.6075 - val_loss: 0.6432 - val_accuracy: 0.6667\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6769 - accuracy: 0.5701 - val_loss: 0.6413 - val_accuracy: 0.6296\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6529 - accuracy: 0.5981 - val_loss: 0.6382 - val_accuracy: 0.6667\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6392 - accuracy: 0.6262 - val_loss: 0.6364 - val_accuracy: 0.6667\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6302 - accuracy: 0.7290 - val_loss: 0.6337 - val_accuracy: 0.6296\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6246 - accuracy: 0.6729 - val_loss: 0.6358 - val_accuracy: 0.6667\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6409 - accuracy: 0.6262 - val_loss: 0.6321 - val_accuracy: 0.6667\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6395 - accuracy: 0.6729 - val_loss: 0.6318 - val_accuracy: 0.7037\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6273 - accuracy: 0.6449 - val_loss: 0.6289 - val_accuracy: 0.7037\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6091 - accuracy: 0.6822 - val_loss: 0.6256 - val_accuracy: 0.7037\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6061 - accuracy: 0.6822 - val_loss: 0.6234 - val_accuracy: 0.7407\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6160 - accuracy: 0.7009 - val_loss: 0.6201 - val_accuracy: 0.6667\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6473 - accuracy: 0.5981 - val_loss: 0.6212 - val_accuracy: 0.6296\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6091 - accuracy: 0.6542 - val_loss: 0.6169 - val_accuracy: 0.7037\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5832 - accuracy: 0.7290 - val_loss: 0.6161 - val_accuracy: 0.7407\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6071 - accuracy: 0.6822 - val_loss: 0.6147 - val_accuracy: 0.7037\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6049 - accuracy: 0.6822 - val_loss: 0.6158 - val_accuracy: 0.6667\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5772 - accuracy: 0.7196 - val_loss: 0.6168 - val_accuracy: 0.6667\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6270 - accuracy: 0.6355 - val_loss: 0.6160 - val_accuracy: 0.6667\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7610 - accuracy: 0.3738 - val_loss: 0.6921 - val_accuracy: 0.5556\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6847 - accuracy: 0.5234 - val_loss: 0.6804 - val_accuracy: 0.6296\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6865 - accuracy: 0.5047 - val_loss: 0.6828 - val_accuracy: 0.5556\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6711 - accuracy: 0.6355 - val_loss: 0.6724 - val_accuracy: 0.6296\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6497 - accuracy: 0.6168 - val_loss: 0.6698 - val_accuracy: 0.6296\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6945 - accuracy: 0.5140 - val_loss: 0.6699 - val_accuracy: 0.7037\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6535 - accuracy: 0.5514 - val_loss: 0.6722 - val_accuracy: 0.5556\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6558 - accuracy: 0.6075 - val_loss: 0.6614 - val_accuracy: 0.7037\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6289 - accuracy: 0.6262 - val_loss: 0.6617 - val_accuracy: 0.6296\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6549 - accuracy: 0.6262 - val_loss: 0.6545 - val_accuracy: 0.6667\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6352 - accuracy: 0.6542 - val_loss: 0.6552 - val_accuracy: 0.6667\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6756 - accuracy: 0.5514 - val_loss: 0.6591 - val_accuracy: 0.5556\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6151 - accuracy: 0.6542 - val_loss: 0.6477 - val_accuracy: 0.7407\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6438 - accuracy: 0.5514 - val_loss: 0.6429 - val_accuracy: 0.7407\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6082 - accuracy: 0.6729 - val_loss: 0.6430 - val_accuracy: 0.7407\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6006 - accuracy: 0.6916 - val_loss: 0.6429 - val_accuracy: 0.7037\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5945 - accuracy: 0.6636 - val_loss: 0.6401 - val_accuracy: 0.7407\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5748 - accuracy: 0.7477 - val_loss: 0.6373 - val_accuracy: 0.7407\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6084 - accuracy: 0.6636 - val_loss: 0.6369 - val_accuracy: 0.7037\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5896 - accuracy: 0.6636 - val_loss: 0.6386 - val_accuracy: 0.5926\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5892 - accuracy: 0.6916 - val_loss: 0.6336 - val_accuracy: 0.7037\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5847 - accuracy: 0.6636 - val_loss: 0.6302 - val_accuracy: 0.7407\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6087 - accuracy: 0.6449 - val_loss: 0.6296 - val_accuracy: 0.7407\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5955 - accuracy: 0.6449 - val_loss: 0.6266 - val_accuracy: 0.7407\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5434 - accuracy: 0.7383 - val_loss: 0.6252 - val_accuracy: 0.7037\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5653 - accuracy: 0.7103 - val_loss: 0.6248 - val_accuracy: 0.7037\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5608 - accuracy: 0.7290 - val_loss: 0.6241 - val_accuracy: 0.6667\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5640 - accuracy: 0.6822 - val_loss: 0.6232 - val_accuracy: 0.7037\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5676 - accuracy: 0.7009 - val_loss: 0.6237 - val_accuracy: 0.7037\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5535 - accuracy: 0.7103 - val_loss: 0.6268 - val_accuracy: 0.6296\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5199 - accuracy: 0.7570 - val_loss: 0.6289 - val_accuracy: 0.6296\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7395 - accuracy: 0.4766 - val_loss: 0.7011 - val_accuracy: 0.5556\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6840 - accuracy: 0.5607 - val_loss: 0.7075 - val_accuracy: 0.5556\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6663 - accuracy: 0.5607 - val_loss: 0.6795 - val_accuracy: 0.5926\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6990 - accuracy: 0.5421 - val_loss: 0.7136 - val_accuracy: 0.4444\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7120 - accuracy: 0.5140 - val_loss: 0.6897 - val_accuracy: 0.5185\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.6861 - accuracy: 0.5327 - val_loss: 0.6698 - val_accuracy: 0.5926\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6556 - accuracy: 0.5794 - val_loss: 0.6711 - val_accuracy: 0.5926\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6851 - accuracy: 0.5701 - val_loss: 0.6656 - val_accuracy: 0.5926\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6763 - accuracy: 0.5327 - val_loss: 0.6633 - val_accuracy: 0.6667\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6336 - accuracy: 0.6729 - val_loss: 0.6633 - val_accuracy: 0.5926\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6666 - accuracy: 0.5981 - val_loss: 0.6615 - val_accuracy: 0.5926\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6296 - accuracy: 0.6449 - val_loss: 0.6574 - val_accuracy: 0.7037\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6337 - accuracy: 0.5888 - val_loss: 0.6554 - val_accuracy: 0.6296\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6190 - accuracy: 0.6355 - val_loss: 0.6520 - val_accuracy: 0.6296\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6259 - accuracy: 0.5981 - val_loss: 0.6492 - val_accuracy: 0.6296\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6388 - accuracy: 0.6355 - val_loss: 0.6459 - val_accuracy: 0.6296\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6126 - accuracy: 0.6355 - val_loss: 0.6408 - val_accuracy: 0.6667\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6157 - accuracy: 0.6355 - val_loss: 0.6428 - val_accuracy: 0.6667\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5945 - accuracy: 0.6542 - val_loss: 0.6367 - val_accuracy: 0.7037\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5545 - accuracy: 0.7196 - val_loss: 0.6326 - val_accuracy: 0.7037\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.6182 - accuracy: 0.6075 - val_loss: 0.6415 - val_accuracy: 0.5556\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5708 - accuracy: 0.6916 - val_loss: 0.6289 - val_accuracy: 0.7037\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5537 - accuracy: 0.7290 - val_loss: 0.6300 - val_accuracy: 0.6667\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5856 - accuracy: 0.7009 - val_loss: 0.6341 - val_accuracy: 0.7037\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5574 - accuracy: 0.6822 - val_loss: 0.6235 - val_accuracy: 0.6667\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5461 - accuracy: 0.7570 - val_loss: 0.6212 - val_accuracy: 0.6667\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5658 - accuracy: 0.6729 - val_loss: 0.6245 - val_accuracy: 0.7407\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5128 - accuracy: 0.7664 - val_loss: 0.6230 - val_accuracy: 0.7407\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5103 - accuracy: 0.7477 - val_loss: 0.6205 - val_accuracy: 0.7037\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5298 - accuracy: 0.7383 - val_loss: 0.6311 - val_accuracy: 0.6667\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5079 - accuracy: 0.7850 - val_loss: 0.6287 - val_accuracy: 0.6667\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4977 - accuracy: 0.7664 - val_loss: 0.6255 - val_accuracy: 0.7037\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.7277 - accuracy: 0.4486 - val_loss: 0.6909 - val_accuracy: 0.5556\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6955 - accuracy: 0.5140 - val_loss: 0.6837 - val_accuracy: 0.5926\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7136 - accuracy: 0.4953 - val_loss: 0.6833 - val_accuracy: 0.5556\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6602 - accuracy: 0.5794 - val_loss: 0.6741 - val_accuracy: 0.5926\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6573 - accuracy: 0.6075 - val_loss: 0.6750 - val_accuracy: 0.5926\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6536 - accuracy: 0.5607 - val_loss: 0.6788 - val_accuracy: 0.5926\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.6784 - accuracy: 0.5234 - val_loss: 0.6700 - val_accuracy: 0.5556\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6421 - accuracy: 0.6262 - val_loss: 0.6840 - val_accuracy: 0.4815\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6322 - accuracy: 0.6449 - val_loss: 0.6763 - val_accuracy: 0.5185\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6308 - accuracy: 0.6449 - val_loss: 0.6706 - val_accuracy: 0.5556\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7106 - accuracy: 0.5421 - val_loss: 0.6857 - val_accuracy: 0.5556\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6981 - accuracy: 0.5607 - val_loss: 0.6927 - val_accuracy: 0.5556\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7068 - accuracy: 0.5140 - val_loss: 0.6865 - val_accuracy: 0.4444\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7053 - accuracy: 0.5047 - val_loss: 0.6895 - val_accuracy: 0.4815\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7034 - accuracy: 0.5607 - val_loss: 0.6801 - val_accuracy: 0.5926\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6973 - accuracy: 0.5234 - val_loss: 0.6770 - val_accuracy: 0.5926\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7226 - accuracy: 0.5514 - val_loss: 0.6781 - val_accuracy: 0.5556\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7096 - accuracy: 0.4953 - val_loss: 0.6728 - val_accuracy: 0.5556\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.6989 - accuracy: 0.5234 - val_loss: 0.6804 - val_accuracy: 0.4074\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6348 - accuracy: 0.6636 - val_loss: 0.6838 - val_accuracy: 0.4444\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6592 - accuracy: 0.5701 - val_loss: 0.6722 - val_accuracy: 0.5185\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6483 - accuracy: 0.6355 - val_loss: 0.6730 - val_accuracy: 0.5556\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6362 - accuracy: 0.6449 - val_loss: 0.6741 - val_accuracy: 0.5926\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.6469 - accuracy: 0.5794 - val_loss: 0.6759 - val_accuracy: 0.6667\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7245 - accuracy: 0.4766 - val_loss: 0.6893 - val_accuracy: 0.5556\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7026 - accuracy: 0.5140 - val_loss: 0.6989 - val_accuracy: 0.5556\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7004 - accuracy: 0.5234 - val_loss: 0.6743 - val_accuracy: 0.5185\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6661 - accuracy: 0.6075 - val_loss: 0.6835 - val_accuracy: 0.4815\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6379 - accuracy: 0.6168 - val_loss: 0.6747 - val_accuracy: 0.5185\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6360 - accuracy: 0.6449 - val_loss: 0.6710 - val_accuracy: 0.5926\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6397 - accuracy: 0.6262 - val_loss: 0.6712 - val_accuracy: 0.5185\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6623 - accuracy: 0.5701 - val_loss: 0.6728 - val_accuracy: 0.5185\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6321 - accuracy: 0.6262 - val_loss: 0.6731 - val_accuracy: 0.5556\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7730 - accuracy: 0.4393 - val_loss: 0.6924 - val_accuracy: 0.5556\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6975 - accuracy: 0.5327 - val_loss: 0.6961 - val_accuracy: 0.5556\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6728 - accuracy: 0.5981 - val_loss: 0.6834 - val_accuracy: 0.5556\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6695 - accuracy: 0.6355 - val_loss: 0.6880 - val_accuracy: 0.4444\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7078 - accuracy: 0.5047 - val_loss: 0.6948 - val_accuracy: 0.4815\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.6665 - accuracy: 0.5607 - val_loss: 0.6808 - val_accuracy: 0.4444\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6366 - accuracy: 0.6075 - val_loss: 0.6802 - val_accuracy: 0.5926\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6311 - accuracy: 0.6355 - val_loss: 0.6802 - val_accuracy: 0.5926\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6009 - accuracy: 0.7290 - val_loss: 0.6820 - val_accuracy: 0.4444\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.6345 - accuracy: 0.6075 - val_loss: 0.6819 - val_accuracy: 0.5556\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6203 - accuracy: 0.6075 - val_loss: 0.6850 - val_accuracy: 0.6296\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7066 - accuracy: 0.4953 - val_loss: 0.6896 - val_accuracy: 0.5556\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6922 - accuracy: 0.5701 - val_loss: 0.6870 - val_accuracy: 0.5926\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6949 - accuracy: 0.5421 - val_loss: 0.7004 - val_accuracy: 0.4444\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6753 - accuracy: 0.5888 - val_loss: 0.6934 - val_accuracy: 0.4815\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6542 - accuracy: 0.6449 - val_loss: 0.6891 - val_accuracy: 0.5556\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7610 - accuracy: 0.4206 - val_loss: 0.6828 - val_accuracy: 0.5556\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.6901 - accuracy: 0.5234 - val_loss: 0.6681 - val_accuracy: 0.5556\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6904 - accuracy: 0.5140 - val_loss: 0.6845 - val_accuracy: 0.4815\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.6704 - accuracy: 0.5327 - val_loss: 0.6800 - val_accuracy: 0.5185\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6552 - accuracy: 0.6168 - val_loss: 0.6544 - val_accuracy: 0.5556\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6338 - accuracy: 0.6168 - val_loss: 0.6544 - val_accuracy: 0.5556\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6241 - accuracy: 0.6262 - val_loss: 0.6517 - val_accuracy: 0.5926\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6303 - accuracy: 0.6262 - val_loss: 0.6361 - val_accuracy: 0.7037\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5790 - accuracy: 0.7477 - val_loss: 0.6314 - val_accuracy: 0.6296\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5464 - accuracy: 0.7477 - val_loss: 0.6304 - val_accuracy: 0.5926\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5324 - accuracy: 0.7850 - val_loss: 0.6255 - val_accuracy: 0.5556\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5462 - accuracy: 0.7103 - val_loss: 0.6111 - val_accuracy: 0.7037\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5074 - accuracy: 0.7944 - val_loss: 0.5995 - val_accuracy: 0.6667\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4856 - accuracy: 0.8037 - val_loss: 0.5879 - val_accuracy: 0.7407\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4794 - accuracy: 0.8411 - val_loss: 0.5770 - val_accuracy: 0.7037\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4512 - accuracy: 0.8505 - val_loss: 0.5690 - val_accuracy: 0.7037\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4374 - accuracy: 0.8411 - val_loss: 0.5582 - val_accuracy: 0.7037\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4259 - accuracy: 0.8411 - val_loss: 0.5490 - val_accuracy: 0.7037\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3977 - accuracy: 0.8598 - val_loss: 0.5412 - val_accuracy: 0.7037\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3730 - accuracy: 0.8692 - val_loss: 0.5360 - val_accuracy: 0.7407\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3860 - accuracy: 0.8411 - val_loss: 0.5287 - val_accuracy: 0.7037\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3432 - accuracy: 0.9065 - val_loss: 0.5235 - val_accuracy: 0.7407\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3298 - accuracy: 0.9159 - val_loss: 0.5200 - val_accuracy: 0.7407\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3213 - accuracy: 0.9159 - val_loss: 0.5154 - val_accuracy: 0.7407\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3082 - accuracy: 0.9252 - val_loss: 0.5104 - val_accuracy: 0.7778\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2966 - accuracy: 0.9159 - val_loss: 0.5058 - val_accuracy: 0.7407\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2901 - accuracy: 0.8879 - val_loss: 0.5052 - val_accuracy: 0.7778\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2932 - accuracy: 0.8972 - val_loss: 0.5040 - val_accuracy: 0.7778\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2561 - accuracy: 0.9159 - val_loss: 0.5026 - val_accuracy: 0.7778\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2855 - accuracy: 0.8692 - val_loss: 0.5038 - val_accuracy: 0.7778\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2563 - accuracy: 0.9065 - val_loss: 0.5038 - val_accuracy: 0.7778\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2334 - accuracy: 0.9439 - val_loss: 0.5000 - val_accuracy: 0.7778\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2341 - accuracy: 0.9346 - val_loss: 0.5017 - val_accuracy: 0.7407\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2339 - accuracy: 0.9159 - val_loss: 0.5128 - val_accuracy: 0.7407\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2209 - accuracy: 0.9252 - val_loss: 0.5254 - val_accuracy: 0.7407\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "Epoch 1/50\n",
      "57/57 [==============================] - 1s 8ms/step - loss: 0.7034 - accuracy: 0.5372 - val_loss: 0.6890 - val_accuracy: 0.5132\n",
      "Epoch 2/50\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.6803 - accuracy: 0.5614 - val_loss: 0.6614 - val_accuracy: 0.6256\n",
      "Epoch 3/50\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.6547 - accuracy: 0.6116 - val_loss: 0.6607 - val_accuracy: 0.6145\n",
      "Epoch 4/50\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.6379 - accuracy: 0.6441 - val_loss: 0.6545 - val_accuracy: 0.6278\n",
      "Epoch 5/50\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.6270 - accuracy: 0.6463 - val_loss: 0.6461 - val_accuracy: 0.6696\n",
      "Epoch 6/50\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.6184 - accuracy: 0.6518 - val_loss: 0.6447 - val_accuracy: 0.6828\n",
      "Epoch 7/50\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.6197 - accuracy: 0.6490 - val_loss: 0.6470 - val_accuracy: 0.6344\n",
      "Epoch 8/50\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.6074 - accuracy: 0.6661 - val_loss: 0.6630 - val_accuracy: 0.6123\n",
      "Epoch 9/50\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.6034 - accuracy: 0.6733 - val_loss: 0.6536 - val_accuracy: 0.6432\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "57/57 [==============================] - 1s 8ms/step - loss: 0.7126 - accuracy: 0.5085 - val_loss: 0.6814 - val_accuracy: 0.5374\n",
      "Epoch 2/50\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.6728 - accuracy: 0.5763 - val_loss: 0.6715 - val_accuracy: 0.5991\n",
      "Epoch 3/50\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.6415 - accuracy: 0.6353 - val_loss: 0.6683 - val_accuracy: 0.6256\n",
      "Epoch 4/50\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.6100 - accuracy: 0.6694 - val_loss: 0.6780 - val_accuracy: 0.6013\n",
      "Epoch 5/50\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.6097 - accuracy: 0.6656 - val_loss: 0.6761 - val_accuracy: 0.6388\n",
      "Epoch 6/50\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.5895 - accuracy: 0.6810 - val_loss: 0.6782 - val_accuracy: 0.6278\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7131 - accuracy: 0.5201 - val_loss: 0.7122 - val_accuracy: 0.5132\n",
      "Epoch 2/50\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.6797 - accuracy: 0.5719 - val_loss: 0.6710 - val_accuracy: 0.6256\n",
      "Epoch 3/50\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.6347 - accuracy: 0.6457 - val_loss: 0.6667 - val_accuracy: 0.6366\n",
      "Epoch 4/50\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.6114 - accuracy: 0.6700 - val_loss: 0.6821 - val_accuracy: 0.6388\n",
      "Epoch 5/50\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.5975 - accuracy: 0.6815 - val_loss: 0.6850 - val_accuracy: 0.6322\n",
      "Epoch 6/50\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.5823 - accuracy: 0.6826 - val_loss: 0.6901 - val_accuracy: 0.6366\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "57/57 [==============================] - 1s 8ms/step - loss: 0.7155 - accuracy: 0.5245 - val_loss: 0.6805 - val_accuracy: 0.5639\n",
      "Epoch 2/50\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.6605 - accuracy: 0.6000 - val_loss: 0.6685 - val_accuracy: 0.5815\n",
      "Epoch 3/50\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.6267 - accuracy: 0.6485 - val_loss: 0.6635 - val_accuracy: 0.6520\n",
      "Epoch 4/50\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.5920 - accuracy: 0.6810 - val_loss: 0.6779 - val_accuracy: 0.6079\n",
      "Epoch 5/50\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.5744 - accuracy: 0.6986 - val_loss: 0.6823 - val_accuracy: 0.6322\n",
      "Epoch 6/50\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.5532 - accuracy: 0.7245 - val_loss: 0.6864 - val_accuracy: 0.6652\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "57/57 [==============================] - 1s 8ms/step - loss: 0.6911 - accuracy: 0.5482 - val_loss: 0.6747 - val_accuracy: 0.5837\n",
      "Epoch 2/50\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.6578 - accuracy: 0.5994 - val_loss: 0.6623 - val_accuracy: 0.6256\n",
      "Epoch 3/50\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.6136 - accuracy: 0.6656 - val_loss: 0.6860 - val_accuracy: 0.6167\n",
      "Epoch 4/50\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.5700 - accuracy: 0.7052 - val_loss: 0.6853 - val_accuracy: 0.6256\n",
      "Epoch 5/50\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.5628 - accuracy: 0.7118 - val_loss: 0.6587 - val_accuracy: 0.6696\n",
      "Epoch 6/50\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.5348 - accuracy: 0.7333 - val_loss: 0.6778 - val_accuracy: 0.6608\n",
      "Epoch 7/50\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.5219 - accuracy: 0.7289 - val_loss: 0.6860 - val_accuracy: 0.6630\n",
      "Epoch 8/50\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.5102 - accuracy: 0.7421 - val_loss: 0.6882 - val_accuracy: 0.6630\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "57/57 [==============================] - 1s 8ms/step - loss: 0.7125 - accuracy: 0.5157 - val_loss: 0.6718 - val_accuracy: 0.6057\n",
      "Epoch 2/50\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.6483 - accuracy: 0.6242 - val_loss: 0.6776 - val_accuracy: 0.5683\n",
      "Epoch 3/50\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.6075 - accuracy: 0.6733 - val_loss: 0.6564 - val_accuracy: 0.6256\n",
      "Epoch 4/50\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.5735 - accuracy: 0.7019 - val_loss: 0.6752 - val_accuracy: 0.6300\n",
      "Epoch 5/50\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.5503 - accuracy: 0.7223 - val_loss: 0.6457 - val_accuracy: 0.6718\n",
      "Epoch 6/50\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.5288 - accuracy: 0.7405 - val_loss: 0.6592 - val_accuracy: 0.6828\n",
      "Epoch 7/50\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.5153 - accuracy: 0.7477 - val_loss: 0.6543 - val_accuracy: 0.6674\n",
      "Epoch 8/50\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.5019 - accuracy: 0.7570 - val_loss: 0.6595 - val_accuracy: 0.6938\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "57/57 [==============================] - 1s 8ms/step - loss: 0.7089 - accuracy: 0.5306 - val_loss: 0.6685 - val_accuracy: 0.6233\n",
      "Epoch 2/50\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.6251 - accuracy: 0.6523 - val_loss: 0.6362 - val_accuracy: 0.6586\n",
      "Epoch 3/50\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.5738 - accuracy: 0.7140 - val_loss: 0.6186 - val_accuracy: 0.6740\n",
      "Epoch 4/50\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.5556 - accuracy: 0.7157 - val_loss: 0.6149 - val_accuracy: 0.7004\n",
      "Epoch 5/50\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.5238 - accuracy: 0.7543 - val_loss: 0.6248 - val_accuracy: 0.6982\n",
      "Epoch 6/50\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.5048 - accuracy: 0.7653 - val_loss: 0.6476 - val_accuracy: 0.6608\n",
      "Epoch 7/50\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.4826 - accuracy: 0.7719 - val_loss: 0.6419 - val_accuracy: 0.6718\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "57/57 [==============================] - 1s 8ms/step - loss: 0.6939 - accuracy: 0.5614 - val_loss: 0.6519 - val_accuracy: 0.6454\n",
      "Epoch 2/50\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.6040 - accuracy: 0.6904 - val_loss: 0.6290 - val_accuracy: 0.6322\n",
      "Epoch 3/50\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.5317 - accuracy: 0.7399 - val_loss: 0.6053 - val_accuracy: 0.7181\n",
      "Epoch 4/50\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.4999 - accuracy: 0.7565 - val_loss: 0.6059 - val_accuracy: 0.7335\n",
      "Epoch 5/50\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.4932 - accuracy: 0.7642 - val_loss: 0.6151 - val_accuracy: 0.7181\n",
      "Epoch 6/50\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.4614 - accuracy: 0.7802 - val_loss: 0.6101 - val_accuracy: 0.7093\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "Epoch 1/50\n",
      "57/57 [==============================] - 1s 8ms/step - loss: 0.6774 - accuracy: 0.5736 - val_loss: 0.6280 - val_accuracy: 0.6608\n",
      "Epoch 2/50\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.5621 - accuracy: 0.7273 - val_loss: 0.5834 - val_accuracy: 0.6960\n",
      "Epoch 3/50\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.4901 - accuracy: 0.7813 - val_loss: 0.5786 - val_accuracy: 0.7401\n",
      "Epoch 4/50\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.4685 - accuracy: 0.7923 - val_loss: 0.5638 - val_accuracy: 0.7379\n",
      "Epoch 5/50\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.4420 - accuracy: 0.7989 - val_loss: 0.5555 - val_accuracy: 0.7445\n",
      "Epoch 6/50\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.4237 - accuracy: 0.8050 - val_loss: 0.5562 - val_accuracy: 0.7357\n",
      "Epoch 7/50\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.4056 - accuracy: 0.8303 - val_loss: 0.5548 - val_accuracy: 0.7511\n",
      "Epoch 8/50\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.3933 - accuracy: 0.8275 - val_loss: 0.5965 - val_accuracy: 0.7225\n",
      "Epoch 9/50\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.3927 - accuracy: 0.8242 - val_loss: 0.5736 - val_accuracy: 0.7269\n",
      "Epoch 10/50\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.3806 - accuracy: 0.8463 - val_loss: 0.5608 - val_accuracy: 0.7401\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "Epoch 1/50\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6457 - accuracy: 0.6248 - val_loss: 0.5261 - val_accuracy: 0.7885\n",
      "Epoch 2/50\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.4418 - accuracy: 0.8039 - val_loss: 0.4645 - val_accuracy: 0.8018\n",
      "Epoch 3/50\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.3734 - accuracy: 0.8408 - val_loss: 0.4362 - val_accuracy: 0.8392\n",
      "Epoch 4/50\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.3312 - accuracy: 0.8645 - val_loss: 0.4237 - val_accuracy: 0.8326\n",
      "Epoch 5/50\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.2962 - accuracy: 0.8771 - val_loss: 0.4078 - val_accuracy: 0.8304\n",
      "Epoch 6/50\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.2931 - accuracy: 0.8826 - val_loss: 0.4136 - val_accuracy: 0.8304\n",
      "Epoch 7/50\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.2855 - accuracy: 0.8826 - val_loss: 0.4121 - val_accuracy: 0.8282\n",
      "Epoch 8/50\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.2618 - accuracy: 0.8975 - val_loss: 0.4133 - val_accuracy: 0.8348\n",
      "18/18 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "# Assume 'files' is defined\n",
    "df_list = []\n",
    "\n",
    "for file in files:\n",
    "    data = pd.read_csv('../Processed Datasets/' + file)\n",
    "    data = data[data['Winner'].isin([1, 2])]\n",
    "    data['Winner'] = data['Winner'].replace(1, 0)\n",
    "    data['Winner'] = data['Winner'].replace(2, 1)\n",
    "\n",
    "    label_encoders = {}\n",
    "    for column in ['ReplayID', 'Player1_Race', 'Player2_Race', 'MapName']:\n",
    "        label_encoders[column] = LabelEncoder()\n",
    "        data[column] = label_encoders[column].fit_transform(data[column])\n",
    "\n",
    "    for per in range(1, 11):\n",
    "        percentile_80_grouped = data.groupby('ReplayID')['Frame'].quantile(per / 10)\n",
    "        def find_nearest_row(group):\n",
    "            nearest_index = (group['Frame'] - percentile_80_grouped[group.name]).abs().idxmin()\n",
    "            return group.loc[[nearest_index]]\n",
    "        nearest_rows = data.groupby('ReplayID', group_keys=False).apply(find_nearest_row)\n",
    "        nearest_rows.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(nearest_rows.drop('Winner', axis=1))\n",
    "        y = nearest_rows['Winner'].values\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "        # TensorFlow models within your existing loop\n",
    "        models = {\n",
    "            'NeuralNetwork': tf.keras.models.Sequential([\n",
    "                        tf.keras.layers.Dense(250, activation='sigmoid', input_shape=(X_train.shape[1],)),\n",
    "                        tf.keras.layers.Dropout(0.2),\n",
    "                        tf.keras.layers.Dense(125, activation='sigmoid'),\n",
    "                        tf.keras.layers.Dropout(0.2),\n",
    "                        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "            ]),\n",
    "        }\n",
    "\n",
    "        # Compile Keras models\n",
    "        models['NeuralNetwork'].compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        scores_dict = {'File': file, 'Percentile': per / 10}\n",
    "\n",
    "        # Training and evaluation loop for Keras models\n",
    "        for model_name, model in models.items():\n",
    "            model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1, callbacks=[EarlyStopping(monitor='val_loss', patience=3)])\n",
    "            predictions = model.predict(X_test)\n",
    "\n",
    "\n",
    "            # Post-processing for metrics calculation\n",
    "            predictions = (predictions > 0.5).astype(int)\n",
    "            accuracy = accuracy_score(y_test, predictions)\n",
    "            precision = precision_score(y_test, predictions)\n",
    "            recall = recall_score(y_test, predictions)\n",
    "            f1 = f1_score(y_test, predictions)\n",
    "            roc = roc_auc_score(y_test, predictions)\n",
    "\n",
    "            scores_dict[f'{model_name}_accuracy'] = accuracy\n",
    "            scores_dict[f'{model_name}_precision'] = precision\n",
    "            scores_dict[f'{model_name}_recall'] = recall\n",
    "            scores_dict[f'{model_name}_f1'] = f1\n",
    "            scores_dict[f'{model_name}_roc'] = roc\n",
    "\n",
    "            df_list.append(pd.DataFrame([scores_dict]))\n",
    "\n",
    "\n",
    "df2 = pd.concat(df_list, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Percentile</th>\n",
       "      <th>RandomForest_accuracy</th>\n",
       "      <th>RandomForest_precision</th>\n",
       "      <th>RandomForest_recall</th>\n",
       "      <th>RandomForest_f1</th>\n",
       "      <th>RandomForest_roc</th>\n",
       "      <th>LogisticRegression_accuracy</th>\n",
       "      <th>LogisticRegression_precision</th>\n",
       "      <th>LogisticRegression_recall</th>\n",
       "      <th>...</th>\n",
       "      <th>SVM_accuracy</th>\n",
       "      <th>SVM_precision</th>\n",
       "      <th>SVM_recall</th>\n",
       "      <th>SVM_f1</th>\n",
       "      <th>SVM_roc</th>\n",
       "      <th>KNN_accuracy</th>\n",
       "      <th>KNN_precision</th>\n",
       "      <th>KNN_recall</th>\n",
       "      <th>KNN_f1</th>\n",
       "      <th>KNN_roc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1D_All_ReplaysData_PvP.csv</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.767213</td>\n",
       "      <td>0.805746</td>\n",
       "      <td>0.709892</td>\n",
       "      <td>0.745969</td>\n",
       "      <td>0.848387</td>\n",
       "      <td>0.747541</td>\n",
       "      <td>0.739514</td>\n",
       "      <td>0.763441</td>\n",
       "      <td>...</td>\n",
       "      <td>0.754098</td>\n",
       "      <td>0.753870</td>\n",
       "      <td>0.756344</td>\n",
       "      <td>0.753981</td>\n",
       "      <td>0.803871</td>\n",
       "      <td>0.616393</td>\n",
       "      <td>0.614211</td>\n",
       "      <td>0.638280</td>\n",
       "      <td>0.623783</td>\n",
       "      <td>0.659355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1D_All_ReplaysData_PvT.csv</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.760720</td>\n",
       "      <td>0.753776</td>\n",
       "      <td>0.797494</td>\n",
       "      <td>0.773494</td>\n",
       "      <td>0.828082</td>\n",
       "      <td>0.793782</td>\n",
       "      <td>0.791385</td>\n",
       "      <td>0.818296</td>\n",
       "      <td>...</td>\n",
       "      <td>0.773479</td>\n",
       "      <td>0.770230</td>\n",
       "      <td>0.804073</td>\n",
       "      <td>0.785933</td>\n",
       "      <td>0.840720</td>\n",
       "      <td>0.556303</td>\n",
       "      <td>0.563469</td>\n",
       "      <td>0.630201</td>\n",
       "      <td>0.593883</td>\n",
       "      <td>0.573570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1D_All_ReplaysData_PvZ.csv</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.534781</td>\n",
       "      <td>0.541065</td>\n",
       "      <td>0.651652</td>\n",
       "      <td>0.580238</td>\n",
       "      <td>0.574765</td>\n",
       "      <td>0.540297</td>\n",
       "      <td>0.552144</td>\n",
       "      <td>0.597598</td>\n",
       "      <td>...</td>\n",
       "      <td>0.562598</td>\n",
       "      <td>0.568636</td>\n",
       "      <td>0.640841</td>\n",
       "      <td>0.593426</td>\n",
       "      <td>0.595273</td>\n",
       "      <td>0.504421</td>\n",
       "      <td>0.515632</td>\n",
       "      <td>0.514414</td>\n",
       "      <td>0.512377</td>\n",
       "      <td>0.487078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1D_All_ReplaysData_TvT.csv</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.717474</td>\n",
       "      <td>0.710619</td>\n",
       "      <td>0.732101</td>\n",
       "      <td>0.720431</td>\n",
       "      <td>0.790521</td>\n",
       "      <td>0.723354</td>\n",
       "      <td>0.726062</td>\n",
       "      <td>0.726050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.709110</td>\n",
       "      <td>0.704540</td>\n",
       "      <td>0.726387</td>\n",
       "      <td>0.712177</td>\n",
       "      <td>0.774953</td>\n",
       "      <td>0.484182</td>\n",
       "      <td>0.480759</td>\n",
       "      <td>0.534958</td>\n",
       "      <td>0.505873</td>\n",
       "      <td>0.481767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1D_All_ReplaysData_TvZ.csv</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.554645</td>\n",
       "      <td>0.668329</td>\n",
       "      <td>0.592803</td>\n",
       "      <td>0.530847</td>\n",
       "      <td>0.588706</td>\n",
       "      <td>0.557541</td>\n",
       "      <td>0.578049</td>\n",
       "      <td>0.702083</td>\n",
       "      <td>...</td>\n",
       "      <td>0.587322</td>\n",
       "      <td>0.604483</td>\n",
       "      <td>0.738826</td>\n",
       "      <td>0.658522</td>\n",
       "      <td>0.586793</td>\n",
       "      <td>0.557923</td>\n",
       "      <td>0.577941</td>\n",
       "      <td>0.689394</td>\n",
       "      <td>0.626311</td>\n",
       "      <td>0.566626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1D_All_ReplaysData_ZvZ.csv</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.621053</td>\n",
       "      <td>0.544444</td>\n",
       "      <td>0.510714</td>\n",
       "      <td>0.521066</td>\n",
       "      <td>0.708983</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.523889</td>\n",
       "      <td>0.510714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.642105</td>\n",
       "      <td>0.565202</td>\n",
       "      <td>0.532143</td>\n",
       "      <td>0.533998</td>\n",
       "      <td>0.669697</td>\n",
       "      <td>0.557895</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.103571</td>\n",
       "      <td>0.154141</td>\n",
       "      <td>0.565152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>StarCraft_Combined_Dataset.csv</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.655821</td>\n",
       "      <td>0.698126</td>\n",
       "      <td>0.572222</td>\n",
       "      <td>0.617250</td>\n",
       "      <td>0.742419</td>\n",
       "      <td>0.679703</td>\n",
       "      <td>0.696302</td>\n",
       "      <td>0.654762</td>\n",
       "      <td>...</td>\n",
       "      <td>0.681733</td>\n",
       "      <td>0.690418</td>\n",
       "      <td>0.680952</td>\n",
       "      <td>0.685424</td>\n",
       "      <td>0.745241</td>\n",
       "      <td>0.570562</td>\n",
       "      <td>0.579449</td>\n",
       "      <td>0.577778</td>\n",
       "      <td>0.578196</td>\n",
       "      <td>0.601475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             File  Percentile  RandomForest_accuracy  \\\n",
       "0      1D_All_ReplaysData_PvP.csv         0.5               0.767213   \n",
       "1      1D_All_ReplaysData_PvT.csv         0.5               0.760720   \n",
       "2      1D_All_ReplaysData_PvZ.csv         0.5               0.534781   \n",
       "3      1D_All_ReplaysData_TvT.csv         0.5               0.717474   \n",
       "4      1D_All_ReplaysData_TvZ.csv         0.5               0.554645   \n",
       "5      1D_All_ReplaysData_ZvZ.csv         0.5               0.621053   \n",
       "6  StarCraft_Combined_Dataset.csv         0.5               0.655821   \n",
       "\n",
       "   RandomForest_precision  RandomForest_recall  RandomForest_f1  \\\n",
       "0                0.805746             0.709892         0.745969   \n",
       "1                0.753776             0.797494         0.773494   \n",
       "2                0.541065             0.651652         0.580238   \n",
       "3                0.710619             0.732101         0.720431   \n",
       "4                0.668329             0.592803         0.530847   \n",
       "5                0.544444             0.510714         0.521066   \n",
       "6                0.698126             0.572222         0.617250   \n",
       "\n",
       "   RandomForest_roc  LogisticRegression_accuracy  \\\n",
       "0          0.848387                     0.747541   \n",
       "1          0.828082                     0.793782   \n",
       "2          0.574765                     0.540297   \n",
       "3          0.790521                     0.723354   \n",
       "4          0.588706                     0.557541   \n",
       "5          0.708983                     0.578947   \n",
       "6          0.742419                     0.679703   \n",
       "\n",
       "   LogisticRegression_precision  LogisticRegression_recall  ...  SVM_accuracy  \\\n",
       "0                      0.739514                   0.763441  ...      0.754098   \n",
       "1                      0.791385                   0.818296  ...      0.773479   \n",
       "2                      0.552144                   0.597598  ...      0.562598   \n",
       "3                      0.726062                   0.726050  ...      0.709110   \n",
       "4                      0.578049                   0.702083  ...      0.587322   \n",
       "5                      0.523889                   0.510714  ...      0.642105   \n",
       "6                      0.696302                   0.654762  ...      0.681733   \n",
       "\n",
       "   SVM_precision  SVM_recall    SVM_f1   SVM_roc  KNN_accuracy  KNN_precision  \\\n",
       "0       0.753870    0.756344  0.753981  0.803871      0.616393       0.614211   \n",
       "1       0.770230    0.804073  0.785933  0.840720      0.556303       0.563469   \n",
       "2       0.568636    0.640841  0.593426  0.595273      0.504421       0.515632   \n",
       "3       0.704540    0.726387  0.712177  0.774953      0.484182       0.480759   \n",
       "4       0.604483    0.738826  0.658522  0.586793      0.557923       0.577941   \n",
       "5       0.565202    0.532143  0.533998  0.669697      0.557895       0.383333   \n",
       "6       0.690418    0.680952  0.685424  0.745241      0.570562       0.579449   \n",
       "\n",
       "   KNN_recall    KNN_f1   KNN_roc  \n",
       "0    0.638280  0.623783  0.659355  \n",
       "1    0.630201  0.593883  0.573570  \n",
       "2    0.514414  0.512377  0.487078  \n",
       "3    0.534958  0.505873  0.481767  \n",
       "4    0.689394  0.626311  0.566626  \n",
       "5    0.103571  0.154141  0.565152  \n",
       "6    0.577778  0.578196  0.601475  \n",
       "\n",
       "[7 rows x 22 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhin\\AppData\\Local\\Temp\\ipykernel_31476\\338515508.py:13: FutureWarning: \n",
      "\n",
      "The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.\n",
      "\n",
      "  plot = sns.barplot(x='Metric', y='Score', hue='Model', data=df_long,  ci=None)\n",
      "c:\\Users\\abhin\\anaconda3\\envs\\DevelopmentEnv\\lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "c:\\Users\\abhin\\anaconda3\\envs\\DevelopmentEnv\\lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "c:\\Users\\abhin\\anaconda3\\envs\\DevelopmentEnv\\lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "c:\\Users\\abhin\\anaconda3\\envs\\DevelopmentEnv\\lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# add previous df and current df and combine it\n",
    "finalDf = pd.concat([df, df2])\n",
    "\n",
    "# Pivot the DataFrame for plotting\n",
    "df_long = pd.melt(finalDf, id_vars=['File', 'Percentile'], var_name='Model_Metric', value_name='Score')\n",
    "\n",
    "# Split the 'Model_Metric' into separate 'Model' and 'Metric' columns\n",
    "df_long[['Model', 'Metric']] = df_long['Model_Metric'].str.rsplit('_', n=1, expand=True)\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "plot = sns.barplot(x='Metric', y='Score', hue='Model', data=df_long,  ci=None)\n",
    "# Add labels on top of each bar\n",
    "for p in plot.patches:\n",
    "    plot.annotate(format(p.get_height(), '.2f'),  # format the value\n",
    "                (p.get_x() + p.get_width() / 2., p.get_height()),  # position\n",
    "                ha='center', va='center',\n",
    "                xytext=(0, 10),  # 10 points vertical offset\n",
    "                textcoords='offset points')\n",
    "plt.title('Performance Metrics for Different Models at 10 Minute Mark')\n",
    "plt.xlabel('Metric')\n",
    "plt.ylabel('Score')\n",
    "plt.legend(title='Model', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "# Manually setting the x-ticks\n",
    "plot.set_xticks(range(len(['Accuracy', 'Precision', 'Recall', 'F1 Score', 'AU-ROC'])))\n",
    "plot.set_xticklabels(['Accuracy', 'Precision', 'Recall', 'F1 Score', 'AU-ROC'])\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DevelopmentEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
