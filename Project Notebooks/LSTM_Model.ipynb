{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start by reading the full dataset to identify top correlating features with the 'Winner' column.\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhin\\anaconda3\\envs\\DevelopmentEnv\\lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\abhin\\anaconda3\\envs\\DevelopmentEnv\\lib\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "file_path = '../StarCraft_Combined_Dataset.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "# data.drop(columns=[\"Player1_Race\",\"Player2_Race\"],axis=1,inplace=True)\n",
    "# label encode player races\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoders = {}\n",
    "\n",
    "for column in ['ReplayID', 'Player1_Race', 'Player2_Race', 'MapName']:\n",
    "    label_encoders[column] = LabelEncoder()\n",
    "    data[column] = label_encoders[column].fit_transform(data[column])\n",
    "\n",
    "\n",
    "# Drop columns with non-numeric data (except for 'Player1_Race' and 'Player2_Race', which we'll one-hot encode)\n",
    "data_numeric = data.select_dtypes(include=[np.number])\n",
    "\n",
    "# Calculate correlations with the 'Winner' column\n",
    "correlations = data_numeric.corrwith(data_numeric['Winner']).sort_values(ascending=False)\n",
    "\n",
    "# Select top 5 correlating features (excluding 'Winner' itself)\n",
    "top_features = correlations.index[1:10]  # Excluding 'Winner' which is at the top\n",
    "\n",
    "# Function to filter groups with at least 120 rows\n",
    "def filter_groups(group):\n",
    "    if len(group) >= 120:\n",
    "        return group.iloc[:120]  # Return only the first 120 rows\n",
    "\n",
    "# Group by 'replayID', apply the filter function\n",
    "filtered_groups = data.groupby('ReplayID').apply(filter_groups).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add races back for one-hot encoding\n",
    "features_to_use = list(top_features) + [\"ReplayID\"]\n",
    "X = filtered_groups[features_to_use]\n",
    "y = filtered_groups['Winner']\n",
    "\n",
    "# Convert 1 to 0 and 2 to 1\n",
    "y_encoded = y.apply(lambda x: 0 if x == 1 else 1)\n",
    "y_encoded = y_encoded[X.index]\n",
    "\n",
    "# Preprocess the dataset\n",
    "numeric_features = top_features\n",
    "# categorical_features = ['Player1_Race', 'Player2_Race']\n",
    "\n",
    "# Assuming filtered_groups is your DataFrame from the previous step\n",
    "unique_replay_ids = filtered_groups['ReplayID'].unique()\n",
    "\n",
    "# Split the unique replay IDs into train and test sets\n",
    "train_replay_ids, test_replay_ids = train_test_split(unique_replay_ids, test_size=0.2, random_state=42)\n",
    "\n",
    "# Use the replay IDs to separate the original filtered_groups into train and test DataFrames\n",
    "train_X_data = X[X['ReplayID'].isin(train_replay_ids)]\n",
    "test_X_data = X[X['ReplayID'].isin(test_replay_ids)]\n",
    "train_y_data = y_encoded[X['ReplayID'].isin(train_replay_ids)]\n",
    "test_y_data = y_encoded[X['ReplayID'].isin(test_replay_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column transformer for preprocessing\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features)\n",
    "        ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the LSTM model\n",
    "def build_model(input_shape):\n",
    "    model = Sequential([\n",
    "        LSTM(60,return_sequences=True,input_shape=input_shape),\n",
    "        Dropout(0.2),\n",
    "        LSTM(50),\n",
    "        Dropout(0.2),\n",
    "        Dense(1, activation='sigmoid') \n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Preprocessing\n",
    "\n",
    "# Preprocess the data\n",
    "preprocessor.fit(filtered_groups)\n",
    "X_train_processed = preprocessor.transform(train_X_data)\n",
    "X_test_processed = preprocessor.transform(test_X_data)\n",
    "\n",
    "# Reshape data for LSTM input\n",
    "feature_columns = [col for col in train_X_data.columns if col not in ['ReplayID', 'Winner']]\n",
    "X_train_reshaped = X_train_processed.reshape(-1, 120, len(feature_columns))\n",
    "X_test_reshaped = X_test_processed.reshape(-1, 120, len(feature_columns))\n",
    "\n",
    "# Create a mapping from ReplayID to label\n",
    "replay_id_to_label_map = {replay_id: label for replay_id, label in zip(X['ReplayID'], y_encoded)}\n",
    "\n",
    "# Now, extract the labels for the training and testing ReplayIDs in the correct order\n",
    "train_y_data = np.array([replay_id_to_label_map[replay_id] for replay_id in train_replay_ids])\n",
    "test_y_data = np.array([replay_id_to_label_map[replay_id] for replay_id in test_replay_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "122/122 [==============================] - 6s 30ms/step - loss: 0.6735 - accuracy: 0.6071 - val_loss: 0.6874 - val_accuracy: 0.5806\n",
      "Epoch 2/100\n",
      "122/122 [==============================] - 3s 26ms/step - loss: 0.6680 - accuracy: 0.6178 - val_loss: 0.6949 - val_accuracy: 0.5806\n",
      "Epoch 3/100\n",
      "122/122 [==============================] - 3s 25ms/step - loss: 0.6621 - accuracy: 0.6240 - val_loss: 0.6834 - val_accuracy: 0.5945\n",
      "Epoch 4/100\n",
      "122/122 [==============================] - 3s 25ms/step - loss: 0.6618 - accuracy: 0.6224 - val_loss: 0.6800 - val_accuracy: 0.5991\n",
      "Epoch 5/100\n",
      "122/122 [==============================] - 3s 26ms/step - loss: 0.6577 - accuracy: 0.6219 - val_loss: 0.6978 - val_accuracy: 0.5899\n",
      "Epoch 6/100\n",
      "122/122 [==============================] - 3s 26ms/step - loss: 0.6584 - accuracy: 0.6189 - val_loss: 0.6882 - val_accuracy: 0.5760\n",
      "Epoch 7/100\n",
      "122/122 [==============================] - 3s 25ms/step - loss: 0.6585 - accuracy: 0.6347 - val_loss: 0.6905 - val_accuracy: 0.5853\n",
      "Epoch 8/100\n",
      "122/122 [==============================] - 3s 25ms/step - loss: 0.6534 - accuracy: 0.6296 - val_loss: 0.6941 - val_accuracy: 0.5806\n",
      "Epoch 9/100\n",
      "122/122 [==============================] - 3s 25ms/step - loss: 0.6539 - accuracy: 0.6317 - val_loss: 0.6885 - val_accuracy: 0.5853\n",
      "Epoch 10/100\n",
      "122/122 [==============================] - 3s 25ms/step - loss: 0.6546 - accuracy: 0.6291 - val_loss: 0.6820 - val_accuracy: 0.5991\n",
      "Epoch 11/100\n",
      "122/122 [==============================] - 3s 25ms/step - loss: 0.6459 - accuracy: 0.6388 - val_loss: 0.6947 - val_accuracy: 0.5853\n",
      "Epoch 12/100\n",
      "122/122 [==============================] - 3s 25ms/step - loss: 0.6446 - accuracy: 0.6322 - val_loss: 0.6935 - val_accuracy: 0.6083\n",
      "Epoch 13/100\n",
      "122/122 [==============================] - 3s 25ms/step - loss: 0.6403 - accuracy: 0.6327 - val_loss: 0.6888 - val_accuracy: 0.5668\n",
      "Epoch 14/100\n",
      "122/122 [==============================] - 3s 25ms/step - loss: 0.6411 - accuracy: 0.6409 - val_loss: 0.7068 - val_accuracy: 0.5576\n",
      "17/17 - 0s - loss: 0.6782 - accuracy: 0.6022 - 366ms/epoch - 22ms/step\n",
      "Test accuracy: 0.6022099256515503, Test loss: 0.6781631708145142\n"
     ]
    }
   ],
   "source": [
    "# Build and train the model\n",
    "model = build_model((X_train_reshaped.shape[1], X_train_reshaped.shape[2]))\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "history = model.fit(X_train_reshaped, train_y_data, epochs=100, batch_size=16, validation_split=0.1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test_reshaped, test_y_data, verbose=2)\n",
    "print(f'Test accuracy: {test_acc}, Test loss: {test_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save LSTM Model\n",
    "\n",
    "model.save(\"Combined_Replays_LSTM_Model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DevelopmentEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
